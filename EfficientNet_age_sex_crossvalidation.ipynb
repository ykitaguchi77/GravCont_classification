{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled71.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMqH/lR9taqGbgYjH58NGhH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/EfficientNet_age_sex_crossvalidation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XH0N7e0Y8Ou",
        "outputId": "391ffea6-5a55-4ff1-9ef7-ac57de84f33d"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnJHyFPBhEAN"
      },
      "source": [
        "#**Evaluator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTp1hx1bhCm4"
      },
      "source": [
        "import os\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import glob\r\n",
        "import torch\r\n",
        "from torch.utils.data import Dataset\r\n",
        "from PIL import Image\r\n",
        "from sklearn.metrics import roc_curve, auc\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "class Evaluator:\r\n",
        "    def __init__(self, model, classes, age_dict, sex_dict, val_folder_path, val_transform, device, print_round_num=2) -> None:\r\n",
        "        super().__init__()\r\n",
        "        self.model = model\r\n",
        "        self.val_folder_path = val_folder_path\r\n",
        "        self.val_transform = val_transform\r\n",
        "        self.device = device\r\n",
        "        self.print_round_num = print_round_num\r\n",
        "        \r\n",
        "        self.class_names = classes\r\n",
        "        self.age_dict = age_dict\r\n",
        "        self.sex_dict = sex_dict\r\n",
        "        self.image_paths = glob.glob(self.val_folder_path + \"/*/*\")\r\n",
        "        print('eval number of classes: ' +str(len(self.class_names)))\r\n",
        "        print('eval number of images: ' +str(len(self.image_paths)))\r\n",
        "        random.shuffle(self.image_paths) \r\n",
        "\r\n",
        "        self.max_accuracy = 0\r\n",
        "        # to update self.max_accuracy\r\n",
        "        self.evaluate()\r\n",
        "        print(\"initial accuracy: \" + str(self.max_accuracy))\r\n",
        "\r\n",
        "    def evaluate(self):\r\n",
        "        TP = FP = TN = FN = TP = FP = TN = FN = 0\r\n",
        "        image_name_list = []\r\n",
        "        label_list = []\r\n",
        "        model_pred_list = []\r\n",
        "\r\n",
        "        model_pred_class = []\r\n",
        "        model_pred_prob = []\r\n",
        "\r\n",
        "        for image_path in self.image_paths:\r\n",
        "            image_name, label, age, sex = self.get_label(image_path)\r\n",
        "            if np.isnan(age):\r\n",
        "                    continue\r\n",
        "            image_tensor = self.get_image_tensor(image_path)\r\n",
        "\r\n",
        "            is_training = self.model.training\r\n",
        "            self.model.eval()\r\n",
        "            with torch.no_grad():\r\n",
        "                output = self.model(image_tensor)\r\n",
        "            if is_training:\r\n",
        "                self.model.train()\r\n",
        "                \r\n",
        "            output = output.squeeze(0)\r\n",
        "            #model_pred:クラス名前、prob:確率、pred:クラス番号\r\n",
        "            prob = torch.clamp(output[0], 0, 1)\r\n",
        "            pred = int(torch.round(prob))\r\n",
        "            model_pred = self.class_names[pred]\r\n",
        "            \r\n",
        "            image_name_list.append(image_name)\r\n",
        "            label_list.append(label)\r\n",
        "            model_pred_list.append(model_pred)\r\n",
        "\r\n",
        "            model_pred_class.append(int(pred))\r\n",
        "            model_pred_prob.append(float(prob))\r\n",
        "\r\n",
        "            if label == self.class_names[0]:\r\n",
        "                if model_pred == self.class_names[0]:\r\n",
        "                    TN += 1\r\n",
        "                else:\r\n",
        "                    FP += 1\r\n",
        "            elif label == self.class_names[1]:\r\n",
        "                if model_pred == self.class_names[1]:\r\n",
        "                    TP += 1\r\n",
        "                else:\r\n",
        "                    FN += 1\r\n",
        "\r\n",
        "        accuracy, precision, recall, specificity, f_value = self.calculate_accuracy(TP, TN, FP, FN)\r\n",
        "        is_best = self.max_accuracy < accuracy\r\n",
        "        if is_best:\r\n",
        "            self.max_accuracy = accuracy\r\n",
        "\r\n",
        "        return is_best, (round(accuracy, self.print_round_num), \r\n",
        "            round(precision, self.print_round_num), \r\n",
        "            round(recall, self.print_round_num), \r\n",
        "            round(specificity, self.print_round_num), \r\n",
        "            round(f_value, self.print_round_num))\r\n",
        "        \r\n",
        "    def draw_roc(self, output_path):\r\n",
        "        label_list = []\r\n",
        "        model_pred_prob = []\r\n",
        "\r\n",
        "        for image_path in self.image_paths:\r\n",
        "            image_name, label, age, sex = self.get_label(image_path)\r\n",
        "            image_tensor = self.get_image_tensor(image_path)\r\n",
        "\r\n",
        "            is_training = self.model.training\r\n",
        "            self.model.eval()\r\n",
        "            with torch.no_grad():\r\n",
        "                output = self.model(image_tensor)\r\n",
        "            if is_training:\r\n",
        "                self.model.train()\r\n",
        "                \r\n",
        "            output = output.squeeze(0)\r\n",
        "            #model_pred:クラス名前、prob:確率、pred:クラス番号\r\n",
        "            prob = torch.clamp(output[0], 0, 1)\r\n",
        "\r\n",
        "            label_list.append(label)\r\n",
        "            model_pred_prob.append(float(prob))\r\n",
        "\r\n",
        "        y_score = []\r\n",
        "        y_true = []\r\n",
        "\r\n",
        "        k=0\r\n",
        "        for i in label_list:\r\n",
        "            if label_list[k] == 'cont':\r\n",
        "                y_true.append(0)\r\n",
        "            elif label_list[k] == 'grav':\r\n",
        "                y_true.append(1)\r\n",
        "            k+=1\r\n",
        "\r\n",
        "        #健康な状態を「0」、病気を「1」としてラベルよりリストを作成\r\n",
        "        y_true = y_true\r\n",
        "        #それぞれの画像における陽性の確率についてリストを作成\r\n",
        "        y_score = model_pred_prob\r\n",
        "        try:\r\n",
        "            fpr, tpr, thred = roc_curve(y_true, y_score)\r\n",
        "            roc_auc = auc(fpr, tpr)\r\n",
        "\r\n",
        "            plt.figure()\r\n",
        "            lw = 2\r\n",
        "            plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\r\n",
        "            plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\r\n",
        "            plt.xlabel('False Positive Rate')\r\n",
        "            plt.ylabel('True Positive Rate')\r\n",
        "            plt.title('Receiver operating characteristic example')\r\n",
        "            plt.legend(loc=\"lower right\")\r\n",
        "            plt.savefig(output_path)\r\n",
        "        except:\r\n",
        "            pass\r\n",
        "\r\n",
        "    #対象のパスからラベルを抜き出す\r\n",
        "    def get_label(self, image_path):\r\n",
        "        image_name = os.path.basename(image_path)\r\n",
        "        \r\n",
        "        base_name, ext = os.path.splitext(image_name)\r\n",
        "        age = float(self.age_dict[base_name]) / 100\r\n",
        "        sex = float(self.sex_dict[base_name])\r\n",
        "        \r\n",
        "        label = os.path.basename(os.path.dirname(image_path))\r\n",
        "        return(image_name, label, age, sex)\r\n",
        "        \r\n",
        "    def get_image_tensor(self, image_path):    \r\n",
        "        image = Image.open(image_path).convert(\"RGB\")\r\n",
        "        image_tensor = self.val_transform(image)\r\n",
        "        image_tensor.unsqueeze_(0)\r\n",
        "        image_tensor = image_tensor.to(self.device) \r\n",
        "        return(image_tensor)\r\n",
        "        \r\n",
        "    def calculate_accuracy(self, TP, TN, FP, FN):\r\n",
        "        try:\r\n",
        "            accuracy = (TP + TN)/ (TP + TN + FP + FN)\r\n",
        "            precision  = TP/(FP + TP)\r\n",
        "            recall = TP/(TP + FN)\r\n",
        "            specificity = TN/(FP + TN)\r\n",
        "            f_value = (2*recall*precision)/(recall+precision)\r\n",
        "        except:\r\n",
        "            accuracy = -1\r\n",
        "            precision  = -1\r\n",
        "            recall = -1\r\n",
        "            specificity = -1\r\n",
        "            f_value = -1\r\n",
        "        return(accuracy, precision, recall, specificity, f_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvbamPHehLtt"
      },
      "source": [
        "#**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6xJpBB5YnzM"
      },
      "source": [
        "##########\r\n",
        "# Usage\r\n",
        "#   python train_grav_multi.py\r\n",
        "##########\r\n",
        "# ├─gravcont_250px_cross\r\n",
        "# │   ├─train\r\n",
        "# │   │  ├─cont\r\n",
        "# │   │  └─grav\r\n",
        "# │   └─val\r\n",
        "# │       ├─cont\r\n",
        "# │       └─grav\r\n",
        "\r\n",
        "\r\n",
        "import os\r\n",
        "import random\r\n",
        "import json\r\n",
        "import tqdm\r\n",
        "import numpy as np\r\n",
        "from PIL import Image\r\n",
        "import torch\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torchvision.datasets import folder\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.datasets as datasets\r\n",
        "!pip install efficientnet_pytorch\r\n",
        "from efficientnet_pytorch import EfficientNet \r\n",
        "\r\n",
        "\r\n",
        "# change working directory\r\n",
        "path = '/content/drive/MyDrive/Deep_learning/666mai_dataset'\r\n",
        "os.chdir(path)\r\n",
        "\r\n",
        "# grav or cont, age, and sex\r\n",
        "NUM_CLASSES = 3\r\n",
        "# contains train, val\r\n",
        "DATASET_PATH = r\"./crossvalidation_250pxs/0/\"\r\n",
        "TEST_PATH = r\"./crossvalidation_250pxs/test/\"\r\n",
        "TRAIN_FOLDER_NAME = \"train\"\r\n",
        "VAL_FOLDER_NAME = \"val\"\r\n",
        "EFFICIENT_NET_NAME = \"efficientnet-b0\"\r\n",
        "MODEL_PATH = \"./model_multi.pth\"\r\n",
        "OPTIMIZER_PATH = \"./optimizer_multi.pth\"\r\n",
        "SEX_DICT_PATH = \"gender_json\"\r\n",
        "AGE_DICT_PATH = \"age_json\"\r\n",
        "LOG_PATH = \"./log_multi.txt\"\r\n",
        "ROC_PATH = \"./roc_multi.png\"\r\n",
        "CHECKPOINT_COUNT = 10\r\n",
        "EPOCH = 100\r\n",
        "BATCH_SIZE = 16\r\n",
        "\r\n",
        "# transforms param\r\n",
        "PX = 224\r\n",
        "TRAIN_NORMALIZE_PARAM = [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]\r\n",
        "TRAIN_CROP_SCALE =(0.75,1.0)\r\n",
        "TRAIN_BRIGHTNESS_PARAM = 0.2\r\n",
        "TRAIN_CONTRAST_PARAM = 0.1\r\n",
        "TRAIN_SATURATION_PARAM = 0.1\r\n",
        "TRAIN_RANDOM_ROTATION = 3\r\n",
        "TRAIN_HUE_PARAM = 0.02\r\n",
        "VAL_NORMALIZE_PARAM = [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]\r\n",
        "\r\n",
        "#######\r\n",
        "# Set random seem for reproducibility\r\n",
        "manualSeed = 1234\r\n",
        "# print(\"Random Seed: \", manualSeed)\r\n",
        "random.seed(manualSeed)\r\n",
        "torch.manual_seed(manualSeed)\r\n",
        "torch.cuda.manual_seed(manualSeed)\r\n",
        "#######\r\n",
        "\r\n",
        "torch.torch.backends.cudnn.benchmark = True\r\n",
        "torch.torch.backends.cudnn.enabled = True\r\n",
        "\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "age_dict = []\r\n",
        "with open(AGE_DICT_PATH, \"r\") as f:\r\n",
        "        age_dict = json.load(f)\r\n",
        "sex_dict = []\r\n",
        "with open(SEX_DICT_PATH, \"r\") as f:\r\n",
        "        sex_dict = json.load(f)\r\n",
        "        \r\n",
        "class SimpleImageDataset(Dataset):\r\n",
        "    def __init__(self, folder_path, age_dict, sex_dict, transform):\r\n",
        "        self.transform = transform\r\n",
        "        self.class_names = os.listdir(folder_path)\r\n",
        "        self.item_paths = []\r\n",
        "        self.item_dict = {}\r\n",
        "        for class_num in range(len(self.class_names)):\r\n",
        "                class_name = self.class_names[class_num]\r\n",
        "                class_path = os.path.join(folder_path, class_name)\r\n",
        "                for image_name in os.listdir(class_path):\r\n",
        "                        base_name, ext = os.path.splitext(image_name)\r\n",
        "                        if np.isnan(age_dict[base_name]):\r\n",
        "                                continue\r\n",
        "                        age = float(age_dict[base_name]) / 100\r\n",
        "                        sex = float(sex_dict[base_name])\r\n",
        "                        image_path = os.path.join(class_path, image_name)\r\n",
        "                        self.item_paths.append(image_path)\r\n",
        "                        self.item_dict[image_path] = (class_num, age, sex)\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.item_paths)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        image_path = self.item_paths[idx]\r\n",
        "        pilr_image = Image.open(image_path).convert(\"RGB\")\r\n",
        "        tensor_image = self.transform(pilr_image)\r\n",
        "        class_num, age, sex = self.item_dict[image_path]\r\n",
        "        class_num = torch.tensor(class_num)\r\n",
        "        age = torch.tensor(age)\r\n",
        "        sex = torch.tensor(sex)\r\n",
        "        label = torch.tensor([class_num, age, sex])\r\n",
        "        return tensor_image, label\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "        if os.path.exists(MODEL_PATH):\r\n",
        "                model = EfficientNet.from_pretrained(EFFICIENT_NET_NAME, MODEL_PATH, num_classes=NUM_CLASSES)\r\n",
        "        else:\r\n",
        "                model = EfficientNet.from_pretrained(EFFICIENT_NET_NAME, num_classes=NUM_CLASSES)\r\n",
        "        model.train()\r\n",
        "        model.to(device)\r\n",
        "\r\n",
        "        # transforms自体を定数として上に記述しても良いかもしれません\r\n",
        "        train_data_transforms = transforms.Compose([\r\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\r\n",
        "                transforms.RandomHorizontalFlip(),\r\n",
        "                transforms.ColorJitter(brightness=TRAIN_BRIGHTNESS_PARAM, contrast=TRAIN_CONTRAST_PARAM,\r\n",
        "                 saturation=TRAIN_SATURATION_PARAM, hue=TRAIN_HUE_PARAM),\r\n",
        "                # transforms.RandomRotation((-TRAIN_RANDOM_ROTATION, TRAIN_RANDOM_ROTATION)),\r\n",
        "                transforms.ToTensor(),\r\n",
        "                transforms.Normalize(TRAIN_NORMALIZE_PARAM[0], TRAIN_NORMALIZE_PARAM[1])])\r\n",
        "        val_data_transforms = transforms.Compose([\r\n",
        "                transforms.Resize(PX),\r\n",
        "                transforms.ToTensor(),\r\n",
        "                transforms.Normalize(VAL_NORMALIZE_PARAM[0], VAL_NORMALIZE_PARAM[1])])                \r\n",
        "                \r\n",
        "        train_dataset = SimpleImageDataset(os.path.join(DATASET_PATH, TRAIN_FOLDER_NAME), age_dict, sex_dict, train_data_transforms)\r\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\r\n",
        "        print(TRAIN_FOLDER_NAME + \"_dataset_size：\" + str(len(train_dataset)))\r\n",
        "\r\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), 0.0002)\r\n",
        "        if os.path.exists(OPTIMIZER_PATH):\r\n",
        "                optimizer.load_state_dict(torch.load(OPTIMIZER_PATH))\r\n",
        "\r\n",
        "        loss_func = torch.nn.MSELoss()\r\n",
        "        \r\n",
        "        val_folder_path = os.path.join(DATASET_PATH, VAL_FOLDER_NAME)\r\n",
        "        evaluator = Evaluator(model, train_dataset.class_names, age_dict, sex_dict, val_folder_path, val_data_transforms, device)\r\n",
        "        evaluator.draw_roc(ROC_PATH)\r\n",
        "\r\n",
        "        for epoch in tqdm.tqdm(range(EPOCH)):\r\n",
        "                for (i, batch) in enumerate(train_dataloader):\r\n",
        "                        optimizer.zero_grad()\r\n",
        "\r\n",
        "                        inputs, labels = batch\r\n",
        "                        inputs = inputs.to(device)\r\n",
        "                        labels = labels.to(device)\r\n",
        "                        \r\n",
        "                        outputs = model(inputs)\r\n",
        "\r\n",
        "                        loss = loss_func(outputs, labels)\r\n",
        "                        loss.backward()\r\n",
        "                        optimizer.step()\r\n",
        "\r\n",
        "                        if i % CHECKPOINT_COUNT == 0:\r\n",
        "                                is_best, score = evaluator.evaluate()\r\n",
        "                                if is_best:\r\n",
        "                                        evaluator.draw_roc(ROC_PATH)\r\n",
        "                                        torch.save(model.state_dict(), MODEL_PATH)\r\n",
        "                                        torch.save(optimizer.state_dict(), OPTIMIZER_PATH)\r\n",
        "\r\n",
        "                                # write log to file\r\n",
        "                                with open(LOG_PATH, 'a') as f:\r\n",
        "                                        f.write(\"-----\")\r\n",
        "                                        f.write(\"\\n\")\r\n",
        "                                        f.write(\"batch_size: \" + str(BATCH_SIZE))\r\n",
        "                                        f.write(\"\\n\")\r\n",
        "                                        f.write(\"iter: \" + str(epoch * len(train_dataloader) + i))\r\n",
        "                                        f.write(str(score))\r\n",
        "                                        f.write(\"\\n\")\r\n",
        "                                \r\n",
        "                                # print log\r\n",
        "                                print(\"-----\")\r\n",
        "                                print(score)\r\n",
        "                                print(\"max_accuracy: \" + str(evaluator.max_accuracy))\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUMMe6H86fM7"
      },
      "source": [
        "        #ここからevalation                        \r\n",
        "        model.eval()\r\n",
        "\r\n",
        "        test_dataset = SimpleImageDataset(os.path(TEST_PATH), age_dict, sex_dict, train_data_transforms)\r\n",
        "        test_dataloader = DataLoader(test_dataset, batch_size = 1, shuffle = FALSE)\r\n",
        "        print(TRAIN_FOLDER_NAME + \"_dataset_size：\" + str(len(train_dataset))) \r\n",
        "\r\n",
        "        val_folder_path = os.path(DATASET_PATH)\r\n",
        "        evaluator = Evaluator(model, train_dataset.class_names, age_dict, sex_dict, val_folder_path, val_data_transforms, device)\r\n",
        "        evaluator.draw_roc(ROC_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}