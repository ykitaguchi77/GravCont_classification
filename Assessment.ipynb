{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled35.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPWMsifGC+gLhRu1claWkHB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/Assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpC0Fk9lUn2",
        "colab_type": "text"
      },
      "source": [
        "#**Assessment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9B59fSXlT5f",
        "colab_type": "code",
        "outputId": "aad2b8b6-4ec9-4b4c-b339-09ffab5be0e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "#Advanced Pytorchから\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set random seem for reproducibility\n",
        "manualSeed = 1234\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.cuda.manual_seed(manualSeed)\n",
        "\n",
        "torch.torch.backends.cudnn.benchmark = True\n",
        "torch.torch.backends.cudnn.enabled = True\n",
        "\n",
        "\n",
        "'''\n",
        "grav: 甲状腺眼症\n",
        "cont: コントロール\n",
        "黒の空白を挿入することにより225px*225pxの画像を生成、EfficientNetを用いて転移学習\n",
        "－－－－－－－－－－－－－－\n",
        "データの構造\n",
        "gravcont.zip ------grav\n",
        "               |---cont\n",
        "'''                                     \n",
        "\n",
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed:  1234\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHO1RjNom0Pr",
        "colab_type": "text"
      },
      "source": [
        "#**モジュール群**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-yVbbvSm3Ay",
        "colab_type": "code",
        "outputId": "65bfdf62-9612-4942-d5b6-a6333b674c16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# 入力画像の前処理をするクラス\n",
        "# 訓練時と推論時で処理が異なる\n",
        "\n",
        "\"\"\"\n",
        "    画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "    画像のサイズをリサイズし、色を標準化する。\n",
        "    訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n",
        "\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    resize : int\n",
        "        リサイズ先の画像の大きさ。\n",
        "    mean : (R, G, B)\n",
        "        各色チャネルの平均値。\n",
        "    std : (R, G, B)\n",
        "        各色チャネルの標準偏差。\n",
        "\"\"\"\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224, scale=(0.75,1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/drive/My Drive/Deep_learning/gravcont_seed_1234'\n",
        "n_samples = len(data_dir)\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=20,\n",
        "                                             shuffle=True, num_workers=0)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "print(class_names)\n",
        "k=0\n",
        "for i in class_names:\n",
        "    print(class_names[k]+\"_train:\"+str(len(os.listdir(path='/content/drive/My Drive/Deep_learning/gravcont_seed_1234/train/'+class_names[k]))))\n",
        "    k+=1\n",
        "k=0\n",
        "for i in class_names:\n",
        "    print(class_names[k]+\"_val:\"+str(len(os.listdir(path='/content/drive/My Drive/Deep_learning/gravcont_seed_1234/val/'+class_names[k]))))\n",
        "    k+=1\n",
        "\n",
        "print(\"training data set_total：\"+ str(len(image_datasets['train'])))\n",
        "print(\"validating data set_total：\"+str(len(image_datasets['val'])))\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cont', 'grav']\n",
            "cont_train:256\n",
            "grav_train:252\n",
            "cont_val:65\n",
            "grav_val:63\n",
            "training data set_total：508\n",
            "validating data set_total：128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk-s71bSlLMJ",
        "colab_type": "text"
      },
      "source": [
        "#**ResNet50_VGGFace2のネットワーク**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twcn29TKk7kM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Resnet50_ft_dag(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Resnet50_ft_dag, self).__init__()\n",
        "        self.meta = {'mean': [131.0912, 103.8827, 91.4953],\n",
        "                     'std': [1, 1, 1],\n",
        "                     'imageSize': [224, 224, 3]}\n",
        "        self.conv1_7x7_s2 = nn.Conv2d(3, 64, kernel_size=[7, 7], stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        self.conv1_7x7_s2_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv1_relu_7x7_s2 = nn.ReLU()\n",
        "        self.pool1_3x3_s2 = nn.MaxPool2d(kernel_size=[3, 3], stride=[2, 2], padding=(0, 0), dilation=1, ceil_mode=True)\n",
        "        self.conv2_1_1x1_reduce = nn.Conv2d(64, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_1_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_1_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_3x3_relu = nn.ReLU()\n",
        "        self.conv2_1_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_1x1_proj = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_proj_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_relu = nn.ReLU()\n",
        "        self.conv2_2_1x1_reduce = nn.Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_2_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_2_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_2_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_3x3_relu = nn.ReLU()\n",
        "        self.conv2_2_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_2_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_relu = nn.ReLU()\n",
        "        self.conv2_3_1x1_reduce = nn.Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_3_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_3_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_3_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_3x3_relu = nn.ReLU()\n",
        "        self.conv2_3_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_3_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_relu = nn.ReLU()\n",
        "        self.conv3_1_1x1_reduce = nn.Conv2d(256, 128, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv3_1_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_1_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_1_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_3x3_relu = nn.ReLU()\n",
        "        self.conv3_1_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_1_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_1x1_proj = nn.Conv2d(256, 512, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv3_1_1x1_proj_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_relu = nn.ReLU()\n",
        "        self.conv3_2_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_2_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_2_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_2_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_3x3_relu = nn.ReLU()\n",
        "        self.conv3_2_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_2_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_relu = nn.ReLU()\n",
        "        self.conv3_3_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_3_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_3_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_3_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_3x3_relu = nn.ReLU()\n",
        "        self.conv3_3_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_3_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_relu = nn.ReLU()\n",
        "        self.conv3_4_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_4_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_4_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_4_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_3x3_relu = nn.ReLU()\n",
        "        self.conv3_4_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_4_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_relu = nn.ReLU()\n",
        "        self.conv4_1_1x1_reduce = nn.Conv2d(512, 256, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv4_1_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_1_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_1_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_3x3_relu = nn.ReLU()\n",
        "        self.conv4_1_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_1_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_1x1_proj = nn.Conv2d(512, 1024, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv4_1_1x1_proj_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_relu = nn.ReLU()\n",
        "        self.conv4_2_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_2_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_2_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_2_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_3x3_relu = nn.ReLU()\n",
        "        self.conv4_2_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_2_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_relu = nn.ReLU()\n",
        "        self.conv4_3_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_3_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_3_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_3_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_3x3_relu = nn.ReLU()\n",
        "        self.conv4_3_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_3_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_relu = nn.ReLU()\n",
        "        self.conv4_4_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_4_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_4_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_4_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_3x3_relu = nn.ReLU()\n",
        "        self.conv4_4_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_4_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_relu = nn.ReLU()\n",
        "        self.conv4_5_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_5_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_5_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_5_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_3x3_relu = nn.ReLU()\n",
        "        self.conv4_5_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_5_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_relu = nn.ReLU()\n",
        "        self.conv4_6_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_6_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_6_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_6_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_3x3_relu = nn.ReLU()\n",
        "        self.conv4_6_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_6_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_relu = nn.ReLU()\n",
        "        self.conv5_1_1x1_reduce = nn.Conv2d(1024, 512, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv5_1_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_1_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_1_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_3x3_relu = nn.ReLU()\n",
        "        self.conv5_1_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_1_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_1x1_proj = nn.Conv2d(1024, 2048, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv5_1_1x1_proj_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_relu = nn.ReLU()\n",
        "        self.conv5_2_1x1_reduce = nn.Conv2d(2048, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_2_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_2_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_2_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_3x3_relu = nn.ReLU()\n",
        "        self.conv5_2_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_2_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_relu = nn.ReLU()\n",
        "        self.conv5_3_1x1_reduce = nn.Conv2d(2048, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_3_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_3_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_3_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_3x3_relu = nn.ReLU()\n",
        "        self.conv5_3_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_3_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_relu = nn.ReLU()\n",
        "        self.pool5_7x7_s1 = nn.AvgPool2d(kernel_size=[7, 7], stride=[1, 1], padding=0)\n",
        "        self.classifier = nn.Conv2d(2048, 8631, kernel_size=[1, 1], stride=(1, 1))\n",
        "\n",
        "    def forward(self, data):\n",
        "        conv1_7x7_s2 = self.conv1_7x7_s2(data)\n",
        "        conv1_7x7_s2_bn = self.conv1_7x7_s2_bn(conv1_7x7_s2)\n",
        "        conv1_7x7_s2_bnxx = self.conv1_relu_7x7_s2(conv1_7x7_s2_bn)\n",
        "        pool1_3x3_s2 = self.pool1_3x3_s2(conv1_7x7_s2_bnxx)\n",
        "        conv2_1_1x1_reduce = self.conv2_1_1x1_reduce(pool1_3x3_s2)\n",
        "        conv2_1_1x1_reduce_bn = self.conv2_1_1x1_reduce_bn(conv2_1_1x1_reduce)\n",
        "        conv2_1_1x1_reduce_bnxx = self.conv2_1_1x1_reduce_relu(conv2_1_1x1_reduce_bn)\n",
        "        conv2_1_3x3 = self.conv2_1_3x3(conv2_1_1x1_reduce_bnxx)\n",
        "        conv2_1_3x3_bn = self.conv2_1_3x3_bn(conv2_1_3x3)\n",
        "        conv2_1_3x3_bnxx = self.conv2_1_3x3_relu(conv2_1_3x3_bn)\n",
        "        conv2_1_1x1_increase = self.conv2_1_1x1_increase(conv2_1_3x3_bnxx)\n",
        "        conv2_1_1x1_increase_bn = self.conv2_1_1x1_increase_bn(conv2_1_1x1_increase)\n",
        "        conv2_1_1x1_proj = self.conv2_1_1x1_proj(pool1_3x3_s2)\n",
        "        conv2_1_1x1_proj_bn = self.conv2_1_1x1_proj_bn(conv2_1_1x1_proj)\n",
        "        conv2_1 = torch.add(conv2_1_1x1_proj_bn, 1, conv2_1_1x1_increase_bn)\n",
        "        conv2_1x = self.conv2_1_relu(conv2_1)\n",
        "        conv2_2_1x1_reduce = self.conv2_2_1x1_reduce(conv2_1x)\n",
        "        conv2_2_1x1_reduce_bn = self.conv2_2_1x1_reduce_bn(conv2_2_1x1_reduce)\n",
        "        conv2_2_1x1_reduce_bnxx = self.conv2_2_1x1_reduce_relu(conv2_2_1x1_reduce_bn)\n",
        "        conv2_2_3x3 = self.conv2_2_3x3(conv2_2_1x1_reduce_bnxx)\n",
        "        conv2_2_3x3_bn = self.conv2_2_3x3_bn(conv2_2_3x3)\n",
        "        conv2_2_3x3_bnxx = self.conv2_2_3x3_relu(conv2_2_3x3_bn)\n",
        "        conv2_2_1x1_increase = self.conv2_2_1x1_increase(conv2_2_3x3_bnxx)\n",
        "        conv2_2_1x1_increase_bn = self.conv2_2_1x1_increase_bn(conv2_2_1x1_increase)\n",
        "        conv2_2 = torch.add(conv2_1x, 1, conv2_2_1x1_increase_bn)\n",
        "        conv2_2x = self.conv2_2_relu(conv2_2)\n",
        "        conv2_3_1x1_reduce = self.conv2_3_1x1_reduce(conv2_2x)\n",
        "        conv2_3_1x1_reduce_bn = self.conv2_3_1x1_reduce_bn(conv2_3_1x1_reduce)\n",
        "        conv2_3_1x1_reduce_bnxx = self.conv2_3_1x1_reduce_relu(conv2_3_1x1_reduce_bn)\n",
        "        conv2_3_3x3 = self.conv2_3_3x3(conv2_3_1x1_reduce_bnxx)\n",
        "        conv2_3_3x3_bn = self.conv2_3_3x3_bn(conv2_3_3x3)\n",
        "        conv2_3_3x3_bnxx = self.conv2_3_3x3_relu(conv2_3_3x3_bn)\n",
        "        conv2_3_1x1_increase = self.conv2_3_1x1_increase(conv2_3_3x3_bnxx)\n",
        "        conv2_3_1x1_increase_bn = self.conv2_3_1x1_increase_bn(conv2_3_1x1_increase)\n",
        "        conv2_3 = torch.add(conv2_2x, 1, conv2_3_1x1_increase_bn)\n",
        "        conv2_3x = self.conv2_3_relu(conv2_3)\n",
        "        conv3_1_1x1_reduce = self.conv3_1_1x1_reduce(conv2_3x)\n",
        "        conv3_1_1x1_reduce_bn = self.conv3_1_1x1_reduce_bn(conv3_1_1x1_reduce)\n",
        "        conv3_1_1x1_reduce_bnxx = self.conv3_1_1x1_reduce_relu(conv3_1_1x1_reduce_bn)\n",
        "        conv3_1_3x3 = self.conv3_1_3x3(conv3_1_1x1_reduce_bnxx)\n",
        "        conv3_1_3x3_bn = self.conv3_1_3x3_bn(conv3_1_3x3)\n",
        "        conv3_1_3x3_bnxx = self.conv3_1_3x3_relu(conv3_1_3x3_bn)\n",
        "        conv3_1_1x1_increase = self.conv3_1_1x1_increase(conv3_1_3x3_bnxx)\n",
        "        conv3_1_1x1_increase_bn = self.conv3_1_1x1_increase_bn(conv3_1_1x1_increase)\n",
        "        conv3_1_1x1_proj = self.conv3_1_1x1_proj(conv2_3x)\n",
        "        conv3_1_1x1_proj_bn = self.conv3_1_1x1_proj_bn(conv3_1_1x1_proj)\n",
        "        conv3_1 = torch.add(conv3_1_1x1_proj_bn, 1, conv3_1_1x1_increase_bn)\n",
        "        conv3_1x = self.conv3_1_relu(conv3_1)\n",
        "        conv3_2_1x1_reduce = self.conv3_2_1x1_reduce(conv3_1x)\n",
        "        conv3_2_1x1_reduce_bn = self.conv3_2_1x1_reduce_bn(conv3_2_1x1_reduce)\n",
        "        conv3_2_1x1_reduce_bnxx = self.conv3_2_1x1_reduce_relu(conv3_2_1x1_reduce_bn)\n",
        "        conv3_2_3x3 = self.conv3_2_3x3(conv3_2_1x1_reduce_bnxx)\n",
        "        conv3_2_3x3_bn = self.conv3_2_3x3_bn(conv3_2_3x3)\n",
        "        conv3_2_3x3_bnxx = self.conv3_2_3x3_relu(conv3_2_3x3_bn)\n",
        "        conv3_2_1x1_increase = self.conv3_2_1x1_increase(conv3_2_3x3_bnxx)\n",
        "        conv3_2_1x1_increase_bn = self.conv3_2_1x1_increase_bn(conv3_2_1x1_increase)\n",
        "        conv3_2 = torch.add(conv3_1x, 1, conv3_2_1x1_increase_bn)\n",
        "        conv3_2x = self.conv3_2_relu(conv3_2)\n",
        "        conv3_3_1x1_reduce = self.conv3_3_1x1_reduce(conv3_2x)\n",
        "        conv3_3_1x1_reduce_bn = self.conv3_3_1x1_reduce_bn(conv3_3_1x1_reduce)\n",
        "        conv3_3_1x1_reduce_bnxx = self.conv3_3_1x1_reduce_relu(conv3_3_1x1_reduce_bn)\n",
        "        conv3_3_3x3 = self.conv3_3_3x3(conv3_3_1x1_reduce_bnxx)\n",
        "        conv3_3_3x3_bn = self.conv3_3_3x3_bn(conv3_3_3x3)\n",
        "        conv3_3_3x3_bnxx = self.conv3_3_3x3_relu(conv3_3_3x3_bn)\n",
        "        conv3_3_1x1_increase = self.conv3_3_1x1_increase(conv3_3_3x3_bnxx)\n",
        "        conv3_3_1x1_increase_bn = self.conv3_3_1x1_increase_bn(conv3_3_1x1_increase)\n",
        "        conv3_3 = torch.add(conv3_2x, 1, conv3_3_1x1_increase_bn)\n",
        "        conv3_3x = self.conv3_3_relu(conv3_3)\n",
        "        conv3_4_1x1_reduce = self.conv3_4_1x1_reduce(conv3_3x)\n",
        "        conv3_4_1x1_reduce_bn = self.conv3_4_1x1_reduce_bn(conv3_4_1x1_reduce)\n",
        "        conv3_4_1x1_reduce_bnxx = self.conv3_4_1x1_reduce_relu(conv3_4_1x1_reduce_bn)\n",
        "        conv3_4_3x3 = self.conv3_4_3x3(conv3_4_1x1_reduce_bnxx)\n",
        "        conv3_4_3x3_bn = self.conv3_4_3x3_bn(conv3_4_3x3)\n",
        "        conv3_4_3x3_bnxx = self.conv3_4_3x3_relu(conv3_4_3x3_bn)\n",
        "        conv3_4_1x1_increase = self.conv3_4_1x1_increase(conv3_4_3x3_bnxx)\n",
        "        conv3_4_1x1_increase_bn = self.conv3_4_1x1_increase_bn(conv3_4_1x1_increase)\n",
        "        conv3_4 = torch.add(conv3_3x, 1, conv3_4_1x1_increase_bn)\n",
        "        conv3_4x = self.conv3_4_relu(conv3_4)\n",
        "        conv4_1_1x1_reduce = self.conv4_1_1x1_reduce(conv3_4x)\n",
        "        conv4_1_1x1_reduce_bn = self.conv4_1_1x1_reduce_bn(conv4_1_1x1_reduce)\n",
        "        conv4_1_1x1_reduce_bnxx = self.conv4_1_1x1_reduce_relu(conv4_1_1x1_reduce_bn)\n",
        "        conv4_1_3x3 = self.conv4_1_3x3(conv4_1_1x1_reduce_bnxx)\n",
        "        conv4_1_3x3_bn = self.conv4_1_3x3_bn(conv4_1_3x3)\n",
        "        conv4_1_3x3_bnxx = self.conv4_1_3x3_relu(conv4_1_3x3_bn)\n",
        "        conv4_1_1x1_increase = self.conv4_1_1x1_increase(conv4_1_3x3_bnxx)\n",
        "        conv4_1_1x1_increase_bn = self.conv4_1_1x1_increase_bn(conv4_1_1x1_increase)\n",
        "        conv4_1_1x1_proj = self.conv4_1_1x1_proj(conv3_4x)\n",
        "        conv4_1_1x1_proj_bn = self.conv4_1_1x1_proj_bn(conv4_1_1x1_proj)\n",
        "        conv4_1 = torch.add(conv4_1_1x1_proj_bn, 1, conv4_1_1x1_increase_bn)\n",
        "        conv4_1x = self.conv4_1_relu(conv4_1)\n",
        "        conv4_2_1x1_reduce = self.conv4_2_1x1_reduce(conv4_1x)\n",
        "        conv4_2_1x1_reduce_bn = self.conv4_2_1x1_reduce_bn(conv4_2_1x1_reduce)\n",
        "        conv4_2_1x1_reduce_bnxx = self.conv4_2_1x1_reduce_relu(conv4_2_1x1_reduce_bn)\n",
        "        conv4_2_3x3 = self.conv4_2_3x3(conv4_2_1x1_reduce_bnxx)\n",
        "        conv4_2_3x3_bn = self.conv4_2_3x3_bn(conv4_2_3x3)\n",
        "        conv4_2_3x3_bnxx = self.conv4_2_3x3_relu(conv4_2_3x3_bn)\n",
        "        conv4_2_1x1_increase = self.conv4_2_1x1_increase(conv4_2_3x3_bnxx)\n",
        "        conv4_2_1x1_increase_bn = self.conv4_2_1x1_increase_bn(conv4_2_1x1_increase)\n",
        "        conv4_2 = torch.add(conv4_1x, 1, conv4_2_1x1_increase_bn)\n",
        "        conv4_2x = self.conv4_2_relu(conv4_2)\n",
        "        conv4_3_1x1_reduce = self.conv4_3_1x1_reduce(conv4_2x)\n",
        "        conv4_3_1x1_reduce_bn = self.conv4_3_1x1_reduce_bn(conv4_3_1x1_reduce)\n",
        "        conv4_3_1x1_reduce_bnxx = self.conv4_3_1x1_reduce_relu(conv4_3_1x1_reduce_bn)\n",
        "        conv4_3_3x3 = self.conv4_3_3x3(conv4_3_1x1_reduce_bnxx)\n",
        "        conv4_3_3x3_bn = self.conv4_3_3x3_bn(conv4_3_3x3)\n",
        "        conv4_3_3x3_bnxx = self.conv4_3_3x3_relu(conv4_3_3x3_bn)\n",
        "        conv4_3_1x1_increase = self.conv4_3_1x1_increase(conv4_3_3x3_bnxx)\n",
        "        conv4_3_1x1_increase_bn = self.conv4_3_1x1_increase_bn(conv4_3_1x1_increase)\n",
        "        conv4_3 = torch.add(conv4_2x, 1, conv4_3_1x1_increase_bn)\n",
        "        conv4_3x = self.conv4_3_relu(conv4_3)\n",
        "        conv4_4_1x1_reduce = self.conv4_4_1x1_reduce(conv4_3x)\n",
        "        conv4_4_1x1_reduce_bn = self.conv4_4_1x1_reduce_bn(conv4_4_1x1_reduce)\n",
        "        conv4_4_1x1_reduce_bnxx = self.conv4_4_1x1_reduce_relu(conv4_4_1x1_reduce_bn)\n",
        "        conv4_4_3x3 = self.conv4_4_3x3(conv4_4_1x1_reduce_bnxx)\n",
        "        conv4_4_3x3_bn = self.conv4_4_3x3_bn(conv4_4_3x3)\n",
        "        conv4_4_3x3_bnxx = self.conv4_4_3x3_relu(conv4_4_3x3_bn)\n",
        "        conv4_4_1x1_increase = self.conv4_4_1x1_increase(conv4_4_3x3_bnxx)\n",
        "        conv4_4_1x1_increase_bn = self.conv4_4_1x1_increase_bn(conv4_4_1x1_increase)\n",
        "        conv4_4 = torch.add(conv4_3x, 1, conv4_4_1x1_increase_bn)\n",
        "        conv4_4x = self.conv4_4_relu(conv4_4)\n",
        "        conv4_5_1x1_reduce = self.conv4_5_1x1_reduce(conv4_4x)\n",
        "        conv4_5_1x1_reduce_bn = self.conv4_5_1x1_reduce_bn(conv4_5_1x1_reduce)\n",
        "        conv4_5_1x1_reduce_bnxx = self.conv4_5_1x1_reduce_relu(conv4_5_1x1_reduce_bn)\n",
        "        conv4_5_3x3 = self.conv4_5_3x3(conv4_5_1x1_reduce_bnxx)\n",
        "        conv4_5_3x3_bn = self.conv4_5_3x3_bn(conv4_5_3x3)\n",
        "        conv4_5_3x3_bnxx = self.conv4_5_3x3_relu(conv4_5_3x3_bn)\n",
        "        conv4_5_1x1_increase = self.conv4_5_1x1_increase(conv4_5_3x3_bnxx)\n",
        "        conv4_5_1x1_increase_bn = self.conv4_5_1x1_increase_bn(conv4_5_1x1_increase)\n",
        "        conv4_5 = torch.add(conv4_4x, 1, conv4_5_1x1_increase_bn)\n",
        "        conv4_5x = self.conv4_5_relu(conv4_5)\n",
        "        conv4_6_1x1_reduce = self.conv4_6_1x1_reduce(conv4_5x)\n",
        "        conv4_6_1x1_reduce_bn = self.conv4_6_1x1_reduce_bn(conv4_6_1x1_reduce)\n",
        "        conv4_6_1x1_reduce_bnxx = self.conv4_6_1x1_reduce_relu(conv4_6_1x1_reduce_bn)\n",
        "        conv4_6_3x3 = self.conv4_6_3x3(conv4_6_1x1_reduce_bnxx)\n",
        "        conv4_6_3x3_bn = self.conv4_6_3x3_bn(conv4_6_3x3)\n",
        "        conv4_6_3x3_bnxx = self.conv4_6_3x3_relu(conv4_6_3x3_bn)\n",
        "        conv4_6_1x1_increase = self.conv4_6_1x1_increase(conv4_6_3x3_bnxx)\n",
        "        conv4_6_1x1_increase_bn = self.conv4_6_1x1_increase_bn(conv4_6_1x1_increase)\n",
        "        conv4_6 = torch.add(conv4_5x, 1, conv4_6_1x1_increase_bn)\n",
        "        conv4_6x = self.conv4_6_relu(conv4_6)\n",
        "        conv5_1_1x1_reduce = self.conv5_1_1x1_reduce(conv4_6x)\n",
        "        conv5_1_1x1_reduce_bn = self.conv5_1_1x1_reduce_bn(conv5_1_1x1_reduce)\n",
        "        conv5_1_1x1_reduce_bnxx = self.conv5_1_1x1_reduce_relu(conv5_1_1x1_reduce_bn)\n",
        "        conv5_1_3x3 = self.conv5_1_3x3(conv5_1_1x1_reduce_bnxx)\n",
        "        conv5_1_3x3_bn = self.conv5_1_3x3_bn(conv5_1_3x3)\n",
        "        conv5_1_3x3_bnxx = self.conv5_1_3x3_relu(conv5_1_3x3_bn)\n",
        "        conv5_1_1x1_increase = self.conv5_1_1x1_increase(conv5_1_3x3_bnxx)\n",
        "        conv5_1_1x1_increase_bn = self.conv5_1_1x1_increase_bn(conv5_1_1x1_increase)\n",
        "        conv5_1_1x1_proj = self.conv5_1_1x1_proj(conv4_6x)\n",
        "        conv5_1_1x1_proj_bn = self.conv5_1_1x1_proj_bn(conv5_1_1x1_proj)\n",
        "        conv5_1 = torch.add(conv5_1_1x1_proj_bn, 1, conv5_1_1x1_increase_bn)\n",
        "        conv5_1x = self.conv5_1_relu(conv5_1)\n",
        "        conv5_2_1x1_reduce = self.conv5_2_1x1_reduce(conv5_1x)\n",
        "        conv5_2_1x1_reduce_bn = self.conv5_2_1x1_reduce_bn(conv5_2_1x1_reduce)\n",
        "        conv5_2_1x1_reduce_bnxx = self.conv5_2_1x1_reduce_relu(conv5_2_1x1_reduce_bn)\n",
        "        conv5_2_3x3 = self.conv5_2_3x3(conv5_2_1x1_reduce_bnxx)\n",
        "        conv5_2_3x3_bn = self.conv5_2_3x3_bn(conv5_2_3x3)\n",
        "        conv5_2_3x3_bnxx = self.conv5_2_3x3_relu(conv5_2_3x3_bn)\n",
        "        conv5_2_1x1_increase = self.conv5_2_1x1_increase(conv5_2_3x3_bnxx)\n",
        "        conv5_2_1x1_increase_bn = self.conv5_2_1x1_increase_bn(conv5_2_1x1_increase)\n",
        "        conv5_2 = torch.add(conv5_1x, 1, conv5_2_1x1_increase_bn)\n",
        "        conv5_2x = self.conv5_2_relu(conv5_2)\n",
        "        conv5_3_1x1_reduce = self.conv5_3_1x1_reduce(conv5_2x)\n",
        "        conv5_3_1x1_reduce_bn = self.conv5_3_1x1_reduce_bn(conv5_3_1x1_reduce)\n",
        "        conv5_3_1x1_reduce_bnxx = self.conv5_3_1x1_reduce_relu(conv5_3_1x1_reduce_bn)\n",
        "        conv5_3_3x3 = self.conv5_3_3x3(conv5_3_1x1_reduce_bnxx)\n",
        "        conv5_3_3x3_bn = self.conv5_3_3x3_bn(conv5_3_3x3)\n",
        "        conv5_3_3x3_bnxx = self.conv5_3_3x3_relu(conv5_3_3x3_bn)\n",
        "        conv5_3_1x1_increase = self.conv5_3_1x1_increase(conv5_3_3x3_bnxx)\n",
        "        conv5_3_1x1_increase_bn = self.conv5_3_1x1_increase_bn(conv5_3_1x1_increase)\n",
        "        conv5_3 = torch.add(conv5_2x, 1, conv5_3_1x1_increase_bn)\n",
        "        conv5_3x = self.conv5_3_relu(conv5_3)\n",
        "        pool5_7x7_s1 = self.pool5_7x7_s1(conv5_3x)\n",
        "        classifier_preflatten = self.classifier(pool5_7x7_s1)\n",
        "        classifier = classifier_preflatten.view(classifier_preflatten.size(0), -1)\n",
        "        #return classifier, pool5_7x7_s1 　出力を変更しておかないと次元が合わないと言われる\n",
        "        return classifier\n",
        "\n",
        "def resnet50_ft_dag(weights_path=None, **kwargs):\n",
        "    \"\"\"\n",
        "    load imported model instance\n",
        "\n",
        "    Args:\n",
        "        weights_path (str): If set, loads model weights from the given path\n",
        "    \"\"\"\n",
        "    model = Resnet50_ft_dag()\n",
        "    if weights_path:\n",
        "        state_dict = torch.load(weights_path)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "#モデルのロード\n",
        "model_ft = Resnet50_ft_dag()\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#最終結合層のリセットと付け替え(全結合層を2つに)\n",
        "model_ft.classifier = nn.Linear(2048, 2)\n",
        "model_ft.classifier = nn.Sequential(*([Flatten()] + list(model_ft.children())[-1:])) #Flattenを挿入\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72UkHpANnFjw",
        "colab_type": "text"
      },
      "source": [
        "#**ResNet50_ImageNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNwSFAOfnEtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = models.resnet50(pretrained=False)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# 重みロード\n",
        "PATH = '/content/drive/My Drive/Deep_learning/GravCont_Resnet50_ImageNet_seed_'+str(manualSeed)+'.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H64GGa2JmT9D",
        "colab_type": "text"
      },
      "source": [
        "#**ResNet50_nonPretrained**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVKpRFdAmUDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = models.resnet50(pretrained=False)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# 重みロード\n",
        "PATH = '/content/drive/My Drive/Deep_learning/GravCont_Resnet50_ImageNet_seed_'+str(manualSeed)+'.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zLnknjNnqNU",
        "colab_type": "text"
      },
      "source": [
        "#**Calculate Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doQbOyGHpJYU",
        "colab_type": "code",
        "outputId": "993ab20a-eac1-411c-9ee3-f504e7123ddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "##########Calculate Accuracy#############\n",
        "#valフォルダ内のファイル名を取得\n",
        "image_path = glob.glob(\"/content/drive/My Drive/Deep_learning/gravcont_seed_1234/val/*/*\")\n",
        "random.shuffle(image_path)  #表示順をランダムにする\n",
        "print('number of images: ' +str(len(image_path)))\n",
        "#print(image_path) \n",
        "\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      return(image_name, label)\n",
        "\n",
        "'''\n",
        "#変形後の画像を表示\n",
        "def image_transform(image_path):\n",
        "\n",
        "    image=Image.open(image_path)\n",
        "\n",
        "    \n",
        "    #変形した画像を表示する\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224)])\n",
        "    image_transformed = transform(image)\n",
        "    plt.imshow(np.array(image_transformed))\n",
        "'''\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を表示\n",
        "def image_eval(image_tensor, label):\n",
        "    output = model_ft(image_tensor)\n",
        "    #print(output.size())  # torch.Size([1, 1000])\n",
        "    #print(output)\n",
        "\n",
        "    #model_pred:クラス名前、prob:確率、pred:クラス番号\n",
        "    prob, pred = torch.topk(nn.Softmax(dim=1)(output), 1)\n",
        "    model_pred = class_names[pred]\n",
        "    \n",
        "    #甲状腺眼症のprobabilityを計算（classが0なら1から減算、classが1ならそのまま）\n",
        "    prob = abs(1-float(prob)-float(pred))\n",
        " \n",
        "    return model_pred, prob, pred\n",
        "\n",
        " \n",
        "\n",
        "def showImage(image_path):\n",
        "    #画像のインポート\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    #画像のリサイズ\n",
        "    height = img.shape[0]\n",
        "    width = img.shape[1]\n",
        "    resized_img = cv2.resize(img, (int(width*300/height), 300))\n",
        "    cv2_imshow(resized_img)\n",
        "\n",
        "def calculateAccuracy (TP, TN, FP, FN):\n",
        "    accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "    precision  = TP/(FP + TP)\n",
        "    recall = TP/(TP + FN)\n",
        "    specificity = TN/(FP + TN)\n",
        "    f_value = (2*recall*precision)/(recall+precision)\n",
        "    return(accuracy, precision, recall, specificity, f_value)\n",
        "\n",
        "\n",
        "#ここからがメイン\n",
        "TP, FP, TN, FN, TP, FP, TN, FN = [0,0,0,0,0,0,0,0]\n",
        "image_name_list = []\n",
        "label_list = []\n",
        "model_pred_list = []\n",
        "hum_pred_list = []\n",
        "\n",
        "model_pred_class = []\n",
        "model_pred_prob = []\n",
        "\n",
        "\n",
        "for i in image_path:\n",
        "      image_name, label = getlabel(i)  #画像の名前とラベルを取得\n",
        "      image_tensor = image_transform(i)  #予測のための画像下処理\n",
        "      model_pred, prob, pred = image_eval(image_tensor, label)  #予測結果を出力   \n",
        "      #print('Image: '+ image_name)\n",
        "      #print('Label: '+ label)\n",
        "      #print('Pred: '+ model_pred)\n",
        "      #showImage(i)  #画像を表示\n",
        "      #print() #空白行を入れる\n",
        "      time.sleep(0.1)\n",
        "\n",
        "      image_name_list.append(image_name)\n",
        "      label_list.append(label)\n",
        "      model_pred_list.append(model_pred)\n",
        "\n",
        "      model_pred_class.append(int(pred))\n",
        "      model_pred_prob.append(float(prob))\n",
        "\n",
        "      if label == class_names[0]:\n",
        "          if model_pred == class_names[0]:\n",
        "              TP += 1\n",
        "          else:\n",
        "              FN += 1\n",
        "      elif label == class_names[1]:\n",
        "          if model_pred == class_names[1]:\n",
        "              TN += 1\n",
        "          else:\n",
        "              FP += 1\n",
        "      \n",
        "\n",
        "print(TP, FN, TN, FP)\n",
        "\n",
        "#Accuracyを計算\n",
        "accuracy, precision, recall, specificity, f_value = calculateAccuracy (TP, TN, FP, FN)\n",
        "print('Accuracy: ' + str(accuracy))\n",
        "print('Precision (positive predictive value): ' + str(precision))\n",
        "print('Recall (sensitivity): ' + str(recall))\n",
        "print('Specificity: ' + str(specificity))\n",
        "print('F_value: ' + str(f_value))\n",
        "\n",
        "print(model_pred_class)\n",
        "print(model_pred_prob)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of images: 128\n",
            "47 18 36 27\n",
            "Accuracy: 0.6484375\n",
            "Precision (positive predictive value): 0.6351351351351351\n",
            "Recall (sensitivity): 0.7230769230769231\n",
            "Specificity: 0.5714285714285714\n",
            "F_value: 0.6762589928057553\n",
            "[1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0]\n",
            "[0.9902614951133728, 0.486394464969635, 0.8997153043746948, 0.47137463092803955, 0.4625154137611389, 0.6834436058998108, 0.45255887508392334, 0.37468409538269043, 0.5098046064376831, 0.523269772529602, 0.6175581812858582, 0.4366557002067566, 0.6300921440124512, 0.6661463379859924, 0.44945383071899414, 0.5043448209762573, 0.4367274045944214, 0.6650607585906982, 0.4601612091064453, 0.4452695846557617, 0.4337611198425293, 0.4443066120147705, 0.477481484413147, 0.4819785952568054, 0.6348122358322144, 0.4913640022277832, 0.447370707988739, 0.4261605143547058, 0.4005424380302429, 0.9800602197647095, 0.4392452836036682, 0.9007282257080078, 0.5009387731552124, 0.7793660759925842, 0.3950539231300354, 0.4883279800415039, 0.4445747137069702, 0.5527889132499695, 0.6131135821342468, 0.457197904586792, 0.3400474786758423, 0.4514177441596985, 0.45511138439178467, 0.8911247253417969, 0.6279265284538269, 0.4416743516921997, 0.472176730632782, 0.46048790216445923, 0.5045126080513, 0.8418664932250977, 0.9778621196746826, 0.457591712474823, 0.5129293203353882, 0.4673294425010681, 0.4444500803947449, 0.6959050893783569, 0.4547216296195984, 0.45748597383499146, 0.6278179883956909, 0.8563628792762756, 0.4510357975959778, 0.45215898752212524, 0.45760560035705566, 0.5550155639648438, 0.46860694885253906, 0.6010584831237793, 0.6890971064567566, 0.46317386627197266, 0.5978227853775024, 0.7772384881973267, 0.4455602765083313, 0.4600644111633301, 0.8560894131660461, 0.5486435294151306, 0.4470701813697815, 0.4700145721435547, 0.4580063819885254, 0.26214832067489624, 0.5030667781829834, 0.7328001260757446, 0.46735960245132446, 0.4345622658729553, 0.5330690741539001, 0.49674248695373535, 0.44677770137786865, 0.44307589530944824, 0.8785753846168518, 0.4445977210998535, 0.4485820531845093, 0.4540392756462097, 0.46268218755722046, 0.8883811235427856, 0.4404844045639038, 0.4872545003890991, 0.5119511485099792, 0.448797345161438, 0.44690996408462524, 0.4575575590133667, 0.9579796195030212, 0.7105836868286133, 0.43959057331085205, 0.46496206521987915, 0.6545974016189575, 0.6342640519142151, 0.5167866945266724, 0.5889669060707092, 0.9676823616027832, 0.4513765573501587, 0.4723024368286133, 0.9977260231971741, 0.26147449016571045, 0.4386497735977173, 0.9863038659095764, 0.4963163137435913, 0.44409239292144775, 0.6061873435974121, 0.45038676261901855, 0.49471426010131836, 0.6870983242988586, 0.9984369874000549, 0.4485463500022888, 0.6509571671485901, 0.4797086715698242, 0.5729544162750244, 0.5756432414054871, 0.45731836557388306, 0.45561647415161133, 0.44579291343688965]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVay7Id8oIPK",
        "colab_type": "text"
      },
      "source": [
        "#**Drawing ROC curve** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_c2zVMKoIVK",
        "colab_type": "code",
        "outputId": "c8592f20-16ad-48aa-a50c-40383f95f0b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_score = []\n",
        "y_true = []\n",
        "\n",
        "k=0\n",
        "for i in label_list:\n",
        "    if label_list[k] == 'cont':\n",
        "          y_true.append(0)\n",
        "    elif label_list[k] == 'grav':\n",
        "          y_true.append(1)\n",
        "    k+=1\n",
        "\n",
        "\n",
        "#健康な状態を「0」、病気を「1」としてラベルよりリストを作成\n",
        "y_true = y_true\n",
        "#それぞれの画像における陽性の確率についてリストを作成\n",
        "y_score = model_pred_prob\n",
        "\n",
        "#print(y_true)\n",
        "#print(y_score)\n",
        "\n",
        "fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "#print(fpr)\n",
        "#print(tpr)\n",
        "\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}