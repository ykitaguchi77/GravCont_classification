{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled35.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmHQIC57tl8XBS9iSlZO1V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8f33666e2e974bd19ddc8ccd027d949b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_99814f6bb2434761be4d21835cbd3f18",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_90bfe50e19ed45149ef3769230e9c7f3",
              "IPY_MODEL_cd21201333c449c9b6c444e5c8afc407"
            ]
          }
        },
        "99814f6bb2434761be4d21835cbd3f18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90bfe50e19ed45149ef3769230e9c7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e9d03291836f48f3a0c180d086a35e9d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 77999237,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 77999237,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa625f2017ab4128a383f07d8cd99868"
          }
        },
        "cd21201333c449c9b6c444e5c8afc407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f360ce3aa3c46f885b0d45d5a53a036",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 74.4M/74.4M [00:14&lt;00:00, 5.40MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6028d9469e747e6baae6aa8cfcf3de7"
          }
        },
        "e9d03291836f48f3a0c180d086a35e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa625f2017ab4128a383f07d8cd99868": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f360ce3aa3c46f885b0d45d5a53a036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6028d9469e747e6baae6aa8cfcf3de7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/Assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpC0Fk9lUn2",
        "colab_type": "text"
      },
      "source": [
        "#**Assessment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9B59fSXlT5f",
        "colab_type": "code",
        "outputId": "359209bb-4eac-4d29-97ca-efb4d738bd38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "#Advanced Pytorchから\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set random seem for reproducibility\n",
        "manualSeed = 1234\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.cuda.manual_seed(manualSeed)\n",
        "\n",
        "torch.torch.backends.cudnn.benchmark = True\n",
        "torch.torch.backends.cudnn.enabled = True\n",
        "\n",
        "\n",
        "'''\n",
        "grav: 甲状腺眼症\n",
        "cont: コントロール\n",
        "黒の空白を挿入することにより225px*225pxの画像を生成、EfficientNetを用いて転移学習\n",
        "－－－－－－－－－－－－－－\n",
        "データの構造\n",
        "gravcont.zip ------grav\n",
        "               |---cont\n",
        "'''                                     \n",
        "\n",
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed:  1234\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHO1RjNom0Pr",
        "colab_type": "text"
      },
      "source": [
        "#**モジュール群**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-yVbbvSm3Ay",
        "colab_type": "code",
        "outputId": "71088a6c-ee53-4d48-8da7-188b4661c94b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# 入力画像の前処理をするクラス\n",
        "# 訓練時と推論時で処理が異なる\n",
        "\n",
        "\"\"\"\n",
        "    画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "    画像のサイズをリサイズし、色を標準化する。\n",
        "    訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n",
        "\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    resize : int\n",
        "        リサイズ先の画像の大きさ。\n",
        "    mean : (R, G, B)\n",
        "        各色チャネルの平均値。\n",
        "    std : (R, G, B)\n",
        "        各色チャネルの標準偏差。\n",
        "\"\"\"\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224, scale=(0.75,1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/drive/My Drive/Deep_learning/gravcont_seed_1234'\n",
        "n_samples = len(data_dir)\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=20,\n",
        "                                             shuffle=True, num_workers=0)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "print(class_names)\n",
        "k=0\n",
        "for i in class_names:\n",
        "    print(class_names[k]+\"_train:\"+str(len(os.listdir(path='/content/drive/My Drive/Deep_learning/gravcont_seed_1234/train/'+class_names[k]))))\n",
        "    k+=1\n",
        "k=0\n",
        "for i in class_names:\n",
        "    print(class_names[k]+\"_val:\"+str(len(os.listdir(path='/content/drive/My Drive/Deep_learning/gravcont_seed_1234/val/'+class_names[k]))))\n",
        "    k+=1\n",
        "\n",
        "print(\"training data set_total：\"+ str(len(image_datasets['train'])))\n",
        "print(\"validating data set_total：\"+str(len(image_datasets['val'])))\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cont', 'grav']\n",
            "cont_train:256\n",
            "grav_train:252\n",
            "cont_val:65\n",
            "grav_val:63\n",
            "training data set_total：508\n",
            "validating data set_total：128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk-s71bSlLMJ",
        "colab_type": "text"
      },
      "source": [
        "#**ResNet50_VGGFace2のネットワーク**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twcn29TKk7kM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Resnet50_ft_dag(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Resnet50_ft_dag, self).__init__()\n",
        "        self.meta = {'mean': [131.0912, 103.8827, 91.4953],\n",
        "                     'std': [1, 1, 1],\n",
        "                     'imageSize': [224, 224, 3]}\n",
        "        self.conv1_7x7_s2 = nn.Conv2d(3, 64, kernel_size=[7, 7], stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        self.conv1_7x7_s2_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv1_relu_7x7_s2 = nn.ReLU()\n",
        "        self.pool1_3x3_s2 = nn.MaxPool2d(kernel_size=[3, 3], stride=[2, 2], padding=(0, 0), dilation=1, ceil_mode=True)\n",
        "        self.conv2_1_1x1_reduce = nn.Conv2d(64, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_1_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_1_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_3x3_relu = nn.ReLU()\n",
        "        self.conv2_1_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_1x1_proj = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_proj_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_relu = nn.ReLU()\n",
        "        self.conv2_2_1x1_reduce = nn.Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_2_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_2_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_2_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_3x3_relu = nn.ReLU()\n",
        "        self.conv2_2_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_2_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_relu = nn.ReLU()\n",
        "        self.conv2_3_1x1_reduce = nn.Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_3_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_3_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_3_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_3x3_relu = nn.ReLU()\n",
        "        self.conv2_3_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_3_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_relu = nn.ReLU()\n",
        "        self.conv3_1_1x1_reduce = nn.Conv2d(256, 128, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv3_1_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_1_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_1_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_3x3_relu = nn.ReLU()\n",
        "        self.conv3_1_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_1_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_1x1_proj = nn.Conv2d(256, 512, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv3_1_1x1_proj_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_relu = nn.ReLU()\n",
        "        self.conv3_2_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_2_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_2_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_2_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_3x3_relu = nn.ReLU()\n",
        "        self.conv3_2_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_2_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_relu = nn.ReLU()\n",
        "        self.conv3_3_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_3_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_3_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_3_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_3x3_relu = nn.ReLU()\n",
        "        self.conv3_3_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_3_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_relu = nn.ReLU()\n",
        "        self.conv3_4_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_4_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_4_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_4_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_3x3_relu = nn.ReLU()\n",
        "        self.conv3_4_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_4_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_relu = nn.ReLU()\n",
        "        self.conv4_1_1x1_reduce = nn.Conv2d(512, 256, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv4_1_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_1_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_1_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_3x3_relu = nn.ReLU()\n",
        "        self.conv4_1_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_1_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_1x1_proj = nn.Conv2d(512, 1024, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv4_1_1x1_proj_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_relu = nn.ReLU()\n",
        "        self.conv4_2_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_2_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_2_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_2_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_3x3_relu = nn.ReLU()\n",
        "        self.conv4_2_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_2_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_relu = nn.ReLU()\n",
        "        self.conv4_3_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_3_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_3_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_3_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_3x3_relu = nn.ReLU()\n",
        "        self.conv4_3_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_3_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_relu = nn.ReLU()\n",
        "        self.conv4_4_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_4_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_4_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_4_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_3x3_relu = nn.ReLU()\n",
        "        self.conv4_4_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_4_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_relu = nn.ReLU()\n",
        "        self.conv4_5_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_5_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_5_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_5_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_3x3_relu = nn.ReLU()\n",
        "        self.conv4_5_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_5_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_relu = nn.ReLU()\n",
        "        self.conv4_6_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_6_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_6_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_6_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_3x3_relu = nn.ReLU()\n",
        "        self.conv4_6_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_6_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_relu = nn.ReLU()\n",
        "        self.conv5_1_1x1_reduce = nn.Conv2d(1024, 512, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv5_1_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_1_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_1_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_3x3_relu = nn.ReLU()\n",
        "        self.conv5_1_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_1_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_1x1_proj = nn.Conv2d(1024, 2048, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv5_1_1x1_proj_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_relu = nn.ReLU()\n",
        "        self.conv5_2_1x1_reduce = nn.Conv2d(2048, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_2_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_2_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_2_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_3x3_relu = nn.ReLU()\n",
        "        self.conv5_2_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_2_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_relu = nn.ReLU()\n",
        "        self.conv5_3_1x1_reduce = nn.Conv2d(2048, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_3_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_3_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_3_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_3x3_relu = nn.ReLU()\n",
        "        self.conv5_3_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_3_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_relu = nn.ReLU()\n",
        "        self.pool5_7x7_s1 = nn.AvgPool2d(kernel_size=[7, 7], stride=[1, 1], padding=0)\n",
        "        self.classifier = nn.Conv2d(2048, 8631, kernel_size=[1, 1], stride=(1, 1))\n",
        "\n",
        "    def forward(self, data):\n",
        "        conv1_7x7_s2 = self.conv1_7x7_s2(data)\n",
        "        conv1_7x7_s2_bn = self.conv1_7x7_s2_bn(conv1_7x7_s2)\n",
        "        conv1_7x7_s2_bnxx = self.conv1_relu_7x7_s2(conv1_7x7_s2_bn)\n",
        "        pool1_3x3_s2 = self.pool1_3x3_s2(conv1_7x7_s2_bnxx)\n",
        "        conv2_1_1x1_reduce = self.conv2_1_1x1_reduce(pool1_3x3_s2)\n",
        "        conv2_1_1x1_reduce_bn = self.conv2_1_1x1_reduce_bn(conv2_1_1x1_reduce)\n",
        "        conv2_1_1x1_reduce_bnxx = self.conv2_1_1x1_reduce_relu(conv2_1_1x1_reduce_bn)\n",
        "        conv2_1_3x3 = self.conv2_1_3x3(conv2_1_1x1_reduce_bnxx)\n",
        "        conv2_1_3x3_bn = self.conv2_1_3x3_bn(conv2_1_3x3)\n",
        "        conv2_1_3x3_bnxx = self.conv2_1_3x3_relu(conv2_1_3x3_bn)\n",
        "        conv2_1_1x1_increase = self.conv2_1_1x1_increase(conv2_1_3x3_bnxx)\n",
        "        conv2_1_1x1_increase_bn = self.conv2_1_1x1_increase_bn(conv2_1_1x1_increase)\n",
        "        conv2_1_1x1_proj = self.conv2_1_1x1_proj(pool1_3x3_s2)\n",
        "        conv2_1_1x1_proj_bn = self.conv2_1_1x1_proj_bn(conv2_1_1x1_proj)\n",
        "        conv2_1 = torch.add(conv2_1_1x1_proj_bn, 1, conv2_1_1x1_increase_bn)\n",
        "        conv2_1x = self.conv2_1_relu(conv2_1)\n",
        "        conv2_2_1x1_reduce = self.conv2_2_1x1_reduce(conv2_1x)\n",
        "        conv2_2_1x1_reduce_bn = self.conv2_2_1x1_reduce_bn(conv2_2_1x1_reduce)\n",
        "        conv2_2_1x1_reduce_bnxx = self.conv2_2_1x1_reduce_relu(conv2_2_1x1_reduce_bn)\n",
        "        conv2_2_3x3 = self.conv2_2_3x3(conv2_2_1x1_reduce_bnxx)\n",
        "        conv2_2_3x3_bn = self.conv2_2_3x3_bn(conv2_2_3x3)\n",
        "        conv2_2_3x3_bnxx = self.conv2_2_3x3_relu(conv2_2_3x3_bn)\n",
        "        conv2_2_1x1_increase = self.conv2_2_1x1_increase(conv2_2_3x3_bnxx)\n",
        "        conv2_2_1x1_increase_bn = self.conv2_2_1x1_increase_bn(conv2_2_1x1_increase)\n",
        "        conv2_2 = torch.add(conv2_1x, 1, conv2_2_1x1_increase_bn)\n",
        "        conv2_2x = self.conv2_2_relu(conv2_2)\n",
        "        conv2_3_1x1_reduce = self.conv2_3_1x1_reduce(conv2_2x)\n",
        "        conv2_3_1x1_reduce_bn = self.conv2_3_1x1_reduce_bn(conv2_3_1x1_reduce)\n",
        "        conv2_3_1x1_reduce_bnxx = self.conv2_3_1x1_reduce_relu(conv2_3_1x1_reduce_bn)\n",
        "        conv2_3_3x3 = self.conv2_3_3x3(conv2_3_1x1_reduce_bnxx)\n",
        "        conv2_3_3x3_bn = self.conv2_3_3x3_bn(conv2_3_3x3)\n",
        "        conv2_3_3x3_bnxx = self.conv2_3_3x3_relu(conv2_3_3x3_bn)\n",
        "        conv2_3_1x1_increase = self.conv2_3_1x1_increase(conv2_3_3x3_bnxx)\n",
        "        conv2_3_1x1_increase_bn = self.conv2_3_1x1_increase_bn(conv2_3_1x1_increase)\n",
        "        conv2_3 = torch.add(conv2_2x, 1, conv2_3_1x1_increase_bn)\n",
        "        conv2_3x = self.conv2_3_relu(conv2_3)\n",
        "        conv3_1_1x1_reduce = self.conv3_1_1x1_reduce(conv2_3x)\n",
        "        conv3_1_1x1_reduce_bn = self.conv3_1_1x1_reduce_bn(conv3_1_1x1_reduce)\n",
        "        conv3_1_1x1_reduce_bnxx = self.conv3_1_1x1_reduce_relu(conv3_1_1x1_reduce_bn)\n",
        "        conv3_1_3x3 = self.conv3_1_3x3(conv3_1_1x1_reduce_bnxx)\n",
        "        conv3_1_3x3_bn = self.conv3_1_3x3_bn(conv3_1_3x3)\n",
        "        conv3_1_3x3_bnxx = self.conv3_1_3x3_relu(conv3_1_3x3_bn)\n",
        "        conv3_1_1x1_increase = self.conv3_1_1x1_increase(conv3_1_3x3_bnxx)\n",
        "        conv3_1_1x1_increase_bn = self.conv3_1_1x1_increase_bn(conv3_1_1x1_increase)\n",
        "        conv3_1_1x1_proj = self.conv3_1_1x1_proj(conv2_3x)\n",
        "        conv3_1_1x1_proj_bn = self.conv3_1_1x1_proj_bn(conv3_1_1x1_proj)\n",
        "        conv3_1 = torch.add(conv3_1_1x1_proj_bn, 1, conv3_1_1x1_increase_bn)\n",
        "        conv3_1x = self.conv3_1_relu(conv3_1)\n",
        "        conv3_2_1x1_reduce = self.conv3_2_1x1_reduce(conv3_1x)\n",
        "        conv3_2_1x1_reduce_bn = self.conv3_2_1x1_reduce_bn(conv3_2_1x1_reduce)\n",
        "        conv3_2_1x1_reduce_bnxx = self.conv3_2_1x1_reduce_relu(conv3_2_1x1_reduce_bn)\n",
        "        conv3_2_3x3 = self.conv3_2_3x3(conv3_2_1x1_reduce_bnxx)\n",
        "        conv3_2_3x3_bn = self.conv3_2_3x3_bn(conv3_2_3x3)\n",
        "        conv3_2_3x3_bnxx = self.conv3_2_3x3_relu(conv3_2_3x3_bn)\n",
        "        conv3_2_1x1_increase = self.conv3_2_1x1_increase(conv3_2_3x3_bnxx)\n",
        "        conv3_2_1x1_increase_bn = self.conv3_2_1x1_increase_bn(conv3_2_1x1_increase)\n",
        "        conv3_2 = torch.add(conv3_1x, 1, conv3_2_1x1_increase_bn)\n",
        "        conv3_2x = self.conv3_2_relu(conv3_2)\n",
        "        conv3_3_1x1_reduce = self.conv3_3_1x1_reduce(conv3_2x)\n",
        "        conv3_3_1x1_reduce_bn = self.conv3_3_1x1_reduce_bn(conv3_3_1x1_reduce)\n",
        "        conv3_3_1x1_reduce_bnxx = self.conv3_3_1x1_reduce_relu(conv3_3_1x1_reduce_bn)\n",
        "        conv3_3_3x3 = self.conv3_3_3x3(conv3_3_1x1_reduce_bnxx)\n",
        "        conv3_3_3x3_bn = self.conv3_3_3x3_bn(conv3_3_3x3)\n",
        "        conv3_3_3x3_bnxx = self.conv3_3_3x3_relu(conv3_3_3x3_bn)\n",
        "        conv3_3_1x1_increase = self.conv3_3_1x1_increase(conv3_3_3x3_bnxx)\n",
        "        conv3_3_1x1_increase_bn = self.conv3_3_1x1_increase_bn(conv3_3_1x1_increase)\n",
        "        conv3_3 = torch.add(conv3_2x, 1, conv3_3_1x1_increase_bn)\n",
        "        conv3_3x = self.conv3_3_relu(conv3_3)\n",
        "        conv3_4_1x1_reduce = self.conv3_4_1x1_reduce(conv3_3x)\n",
        "        conv3_4_1x1_reduce_bn = self.conv3_4_1x1_reduce_bn(conv3_4_1x1_reduce)\n",
        "        conv3_4_1x1_reduce_bnxx = self.conv3_4_1x1_reduce_relu(conv3_4_1x1_reduce_bn)\n",
        "        conv3_4_3x3 = self.conv3_4_3x3(conv3_4_1x1_reduce_bnxx)\n",
        "        conv3_4_3x3_bn = self.conv3_4_3x3_bn(conv3_4_3x3)\n",
        "        conv3_4_3x3_bnxx = self.conv3_4_3x3_relu(conv3_4_3x3_bn)\n",
        "        conv3_4_1x1_increase = self.conv3_4_1x1_increase(conv3_4_3x3_bnxx)\n",
        "        conv3_4_1x1_increase_bn = self.conv3_4_1x1_increase_bn(conv3_4_1x1_increase)\n",
        "        conv3_4 = torch.add(conv3_3x, 1, conv3_4_1x1_increase_bn)\n",
        "        conv3_4x = self.conv3_4_relu(conv3_4)\n",
        "        conv4_1_1x1_reduce = self.conv4_1_1x1_reduce(conv3_4x)\n",
        "        conv4_1_1x1_reduce_bn = self.conv4_1_1x1_reduce_bn(conv4_1_1x1_reduce)\n",
        "        conv4_1_1x1_reduce_bnxx = self.conv4_1_1x1_reduce_relu(conv4_1_1x1_reduce_bn)\n",
        "        conv4_1_3x3 = self.conv4_1_3x3(conv4_1_1x1_reduce_bnxx)\n",
        "        conv4_1_3x3_bn = self.conv4_1_3x3_bn(conv4_1_3x3)\n",
        "        conv4_1_3x3_bnxx = self.conv4_1_3x3_relu(conv4_1_3x3_bn)\n",
        "        conv4_1_1x1_increase = self.conv4_1_1x1_increase(conv4_1_3x3_bnxx)\n",
        "        conv4_1_1x1_increase_bn = self.conv4_1_1x1_increase_bn(conv4_1_1x1_increase)\n",
        "        conv4_1_1x1_proj = self.conv4_1_1x1_proj(conv3_4x)\n",
        "        conv4_1_1x1_proj_bn = self.conv4_1_1x1_proj_bn(conv4_1_1x1_proj)\n",
        "        conv4_1 = torch.add(conv4_1_1x1_proj_bn, 1, conv4_1_1x1_increase_bn)\n",
        "        conv4_1x = self.conv4_1_relu(conv4_1)\n",
        "        conv4_2_1x1_reduce = self.conv4_2_1x1_reduce(conv4_1x)\n",
        "        conv4_2_1x1_reduce_bn = self.conv4_2_1x1_reduce_bn(conv4_2_1x1_reduce)\n",
        "        conv4_2_1x1_reduce_bnxx = self.conv4_2_1x1_reduce_relu(conv4_2_1x1_reduce_bn)\n",
        "        conv4_2_3x3 = self.conv4_2_3x3(conv4_2_1x1_reduce_bnxx)\n",
        "        conv4_2_3x3_bn = self.conv4_2_3x3_bn(conv4_2_3x3)\n",
        "        conv4_2_3x3_bnxx = self.conv4_2_3x3_relu(conv4_2_3x3_bn)\n",
        "        conv4_2_1x1_increase = self.conv4_2_1x1_increase(conv4_2_3x3_bnxx)\n",
        "        conv4_2_1x1_increase_bn = self.conv4_2_1x1_increase_bn(conv4_2_1x1_increase)\n",
        "        conv4_2 = torch.add(conv4_1x, 1, conv4_2_1x1_increase_bn)\n",
        "        conv4_2x = self.conv4_2_relu(conv4_2)\n",
        "        conv4_3_1x1_reduce = self.conv4_3_1x1_reduce(conv4_2x)\n",
        "        conv4_3_1x1_reduce_bn = self.conv4_3_1x1_reduce_bn(conv4_3_1x1_reduce)\n",
        "        conv4_3_1x1_reduce_bnxx = self.conv4_3_1x1_reduce_relu(conv4_3_1x1_reduce_bn)\n",
        "        conv4_3_3x3 = self.conv4_3_3x3(conv4_3_1x1_reduce_bnxx)\n",
        "        conv4_3_3x3_bn = self.conv4_3_3x3_bn(conv4_3_3x3)\n",
        "        conv4_3_3x3_bnxx = self.conv4_3_3x3_relu(conv4_3_3x3_bn)\n",
        "        conv4_3_1x1_increase = self.conv4_3_1x1_increase(conv4_3_3x3_bnxx)\n",
        "        conv4_3_1x1_increase_bn = self.conv4_3_1x1_increase_bn(conv4_3_1x1_increase)\n",
        "        conv4_3 = torch.add(conv4_2x, 1, conv4_3_1x1_increase_bn)\n",
        "        conv4_3x = self.conv4_3_relu(conv4_3)\n",
        "        conv4_4_1x1_reduce = self.conv4_4_1x1_reduce(conv4_3x)\n",
        "        conv4_4_1x1_reduce_bn = self.conv4_4_1x1_reduce_bn(conv4_4_1x1_reduce)\n",
        "        conv4_4_1x1_reduce_bnxx = self.conv4_4_1x1_reduce_relu(conv4_4_1x1_reduce_bn)\n",
        "        conv4_4_3x3 = self.conv4_4_3x3(conv4_4_1x1_reduce_bnxx)\n",
        "        conv4_4_3x3_bn = self.conv4_4_3x3_bn(conv4_4_3x3)\n",
        "        conv4_4_3x3_bnxx = self.conv4_4_3x3_relu(conv4_4_3x3_bn)\n",
        "        conv4_4_1x1_increase = self.conv4_4_1x1_increase(conv4_4_3x3_bnxx)\n",
        "        conv4_4_1x1_increase_bn = self.conv4_4_1x1_increase_bn(conv4_4_1x1_increase)\n",
        "        conv4_4 = torch.add(conv4_3x, 1, conv4_4_1x1_increase_bn)\n",
        "        conv4_4x = self.conv4_4_relu(conv4_4)\n",
        "        conv4_5_1x1_reduce = self.conv4_5_1x1_reduce(conv4_4x)\n",
        "        conv4_5_1x1_reduce_bn = self.conv4_5_1x1_reduce_bn(conv4_5_1x1_reduce)\n",
        "        conv4_5_1x1_reduce_bnxx = self.conv4_5_1x1_reduce_relu(conv4_5_1x1_reduce_bn)\n",
        "        conv4_5_3x3 = self.conv4_5_3x3(conv4_5_1x1_reduce_bnxx)\n",
        "        conv4_5_3x3_bn = self.conv4_5_3x3_bn(conv4_5_3x3)\n",
        "        conv4_5_3x3_bnxx = self.conv4_5_3x3_relu(conv4_5_3x3_bn)\n",
        "        conv4_5_1x1_increase = self.conv4_5_1x1_increase(conv4_5_3x3_bnxx)\n",
        "        conv4_5_1x1_increase_bn = self.conv4_5_1x1_increase_bn(conv4_5_1x1_increase)\n",
        "        conv4_5 = torch.add(conv4_4x, 1, conv4_5_1x1_increase_bn)\n",
        "        conv4_5x = self.conv4_5_relu(conv4_5)\n",
        "        conv4_6_1x1_reduce = self.conv4_6_1x1_reduce(conv4_5x)\n",
        "        conv4_6_1x1_reduce_bn = self.conv4_6_1x1_reduce_bn(conv4_6_1x1_reduce)\n",
        "        conv4_6_1x1_reduce_bnxx = self.conv4_6_1x1_reduce_relu(conv4_6_1x1_reduce_bn)\n",
        "        conv4_6_3x3 = self.conv4_6_3x3(conv4_6_1x1_reduce_bnxx)\n",
        "        conv4_6_3x3_bn = self.conv4_6_3x3_bn(conv4_6_3x3)\n",
        "        conv4_6_3x3_bnxx = self.conv4_6_3x3_relu(conv4_6_3x3_bn)\n",
        "        conv4_6_1x1_increase = self.conv4_6_1x1_increase(conv4_6_3x3_bnxx)\n",
        "        conv4_6_1x1_increase_bn = self.conv4_6_1x1_increase_bn(conv4_6_1x1_increase)\n",
        "        conv4_6 = torch.add(conv4_5x, 1, conv4_6_1x1_increase_bn)\n",
        "        conv4_6x = self.conv4_6_relu(conv4_6)\n",
        "        conv5_1_1x1_reduce = self.conv5_1_1x1_reduce(conv4_6x)\n",
        "        conv5_1_1x1_reduce_bn = self.conv5_1_1x1_reduce_bn(conv5_1_1x1_reduce)\n",
        "        conv5_1_1x1_reduce_bnxx = self.conv5_1_1x1_reduce_relu(conv5_1_1x1_reduce_bn)\n",
        "        conv5_1_3x3 = self.conv5_1_3x3(conv5_1_1x1_reduce_bnxx)\n",
        "        conv5_1_3x3_bn = self.conv5_1_3x3_bn(conv5_1_3x3)\n",
        "        conv5_1_3x3_bnxx = self.conv5_1_3x3_relu(conv5_1_3x3_bn)\n",
        "        conv5_1_1x1_increase = self.conv5_1_1x1_increase(conv5_1_3x3_bnxx)\n",
        "        conv5_1_1x1_increase_bn = self.conv5_1_1x1_increase_bn(conv5_1_1x1_increase)\n",
        "        conv5_1_1x1_proj = self.conv5_1_1x1_proj(conv4_6x)\n",
        "        conv5_1_1x1_proj_bn = self.conv5_1_1x1_proj_bn(conv5_1_1x1_proj)\n",
        "        conv5_1 = torch.add(conv5_1_1x1_proj_bn, 1, conv5_1_1x1_increase_bn)\n",
        "        conv5_1x = self.conv5_1_relu(conv5_1)\n",
        "        conv5_2_1x1_reduce = self.conv5_2_1x1_reduce(conv5_1x)\n",
        "        conv5_2_1x1_reduce_bn = self.conv5_2_1x1_reduce_bn(conv5_2_1x1_reduce)\n",
        "        conv5_2_1x1_reduce_bnxx = self.conv5_2_1x1_reduce_relu(conv5_2_1x1_reduce_bn)\n",
        "        conv5_2_3x3 = self.conv5_2_3x3(conv5_2_1x1_reduce_bnxx)\n",
        "        conv5_2_3x3_bn = self.conv5_2_3x3_bn(conv5_2_3x3)\n",
        "        conv5_2_3x3_bnxx = self.conv5_2_3x3_relu(conv5_2_3x3_bn)\n",
        "        conv5_2_1x1_increase = self.conv5_2_1x1_increase(conv5_2_3x3_bnxx)\n",
        "        conv5_2_1x1_increase_bn = self.conv5_2_1x1_increase_bn(conv5_2_1x1_increase)\n",
        "        conv5_2 = torch.add(conv5_1x, 1, conv5_2_1x1_increase_bn)\n",
        "        conv5_2x = self.conv5_2_relu(conv5_2)\n",
        "        conv5_3_1x1_reduce = self.conv5_3_1x1_reduce(conv5_2x)\n",
        "        conv5_3_1x1_reduce_bn = self.conv5_3_1x1_reduce_bn(conv5_3_1x1_reduce)\n",
        "        conv5_3_1x1_reduce_bnxx = self.conv5_3_1x1_reduce_relu(conv5_3_1x1_reduce_bn)\n",
        "        conv5_3_3x3 = self.conv5_3_3x3(conv5_3_1x1_reduce_bnxx)\n",
        "        conv5_3_3x3_bn = self.conv5_3_3x3_bn(conv5_3_3x3)\n",
        "        conv5_3_3x3_bnxx = self.conv5_3_3x3_relu(conv5_3_3x3_bn)\n",
        "        conv5_3_1x1_increase = self.conv5_3_1x1_increase(conv5_3_3x3_bnxx)\n",
        "        conv5_3_1x1_increase_bn = self.conv5_3_1x1_increase_bn(conv5_3_1x1_increase)\n",
        "        conv5_3 = torch.add(conv5_2x, 1, conv5_3_1x1_increase_bn)\n",
        "        conv5_3x = self.conv5_3_relu(conv5_3)\n",
        "        pool5_7x7_s1 = self.pool5_7x7_s1(conv5_3x)\n",
        "        classifier_preflatten = self.classifier(pool5_7x7_s1)\n",
        "        classifier = classifier_preflatten.view(classifier_preflatten.size(0), -1)\n",
        "        #return classifier, pool5_7x7_s1 　出力を変更しておかないと次元が合わないと言われる\n",
        "        return classifier\n",
        "\n",
        "def resnet50_ft_dag(weights_path=None, **kwargs):\n",
        "    \"\"\"\n",
        "    load imported model instance\n",
        "\n",
        "    Args:\n",
        "        weights_path (str): If set, loads model weights from the given path\n",
        "    \"\"\"\n",
        "    model = Resnet50_ft_dag()\n",
        "    if weights_path:\n",
        "        state_dict = torch.load(weights_path)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "#モデルのロード\n",
        "model_ft = Resnet50_ft_dag()\n",
        "\n",
        "#最終結合層のリセットと付け替え(全結合層を2つに)\n",
        "model_ft.classifier = nn.Linear(2048, 2)\n",
        "model_ft.classifier = nn.Sequential(*([Flatten()] + list(model_ft.children())[-1:])) #Flattenを挿入\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72UkHpANnFjw",
        "colab_type": "text"
      },
      "source": [
        "#**ResNet50_ImageNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNwSFAOfnEtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = models.resnet50(pretrained=False)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# 重みロード\n",
        "PATH = '/content/drive/My Drive/Deep_learning/GravCont_Resnet50_ImageNet_seed_'+str(manualSeed)+'.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H64GGa2JmT9D",
        "colab_type": "text"
      },
      "source": [
        "#**ResNet50_nonPretrained**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVKpRFdAmUDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = models.resnet50(pretrained=False)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# 重みロード\n",
        "PATH = '/content/drive/My Drive/Deep_learning/GravCont_Resnet50_ImageNet_seed_'+str(manualSeed)+'.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWhxHmDPns3R",
        "colab_type": "text"
      },
      "source": [
        "#**EfficientNet_b4_ImageNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syACduJCntAB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8f33666e2e974bd19ddc8ccd027d949b",
            "99814f6bb2434761be4d21835cbd3f18",
            "90bfe50e19ed45149ef3769230e9c7f3",
            "cd21201333c449c9b6c444e5c8afc407",
            "e9d03291836f48f3a0c180d086a35e9d",
            "aa625f2017ab4128a383f07d8cd99868",
            "3f360ce3aa3c46f885b0d45d5a53a036",
            "a6028d9469e747e6baae6aa8cfcf3de7"
          ]
        },
        "outputId": "de59e853-ef7d-4dd1-bad0-8eac007286f8"
      },
      "source": [
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet \n",
        "\n",
        "model_ft = EfficientNet.from_pretrained('efficientnet-b4')\n",
        "num_ftrs = model_ft._fc.in_features\n",
        "model_ft._fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#ネットワークの読み込み\n",
        "PATH = '/content/drive/My Drive/Deep_learning/GravCont_EfficientNet-b4_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.5.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.4)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-cp36-none-any.whl size=12422 sha256=b6b87db99a57469ffcd05cdc4b486d95f5aaaf4e7371cffa7aaf10992fe3ed92\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/1e/a9/2a578ba9ad04e776e80bf0f70d8a7f4c29ec0718b92d8f6ccd\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /root/.cache/torch/checkpoints/efficientnet-b4-6ed6700e.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f33666e2e974bd19ddc8ccd027d949b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=77999237.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded pretrained weights for efficientnet-b4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (_conv_stem): Conv2dStaticSamePadding(\n",
              "    3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "  )\n",
              "  (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_blocks): ModuleList(\n",
              "    (0): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (1): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (2): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (3): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (4): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (5): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (6): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (7): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (8): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (9): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (10): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (11): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (12): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (13): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (14): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (15): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (16): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (17): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (18): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (19): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (20): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (21): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (22): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=[2, 2], groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (23): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (24): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (25): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (26): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (27): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (28): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (29): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (30): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(3, 3), stride=[1, 1], groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (31): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        2688, 2688, kernel_size=(3, 3), stride=(1, 1), groups=2688, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        2688, 112, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        112, 2688, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "  )\n",
              "  (_conv_head): Conv2dStaticSamePadding(\n",
              "    448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "    (static_padding): Identity()\n",
              "  )\n",
              "  (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "  (_dropout): Dropout(p=0.4, inplace=False)\n",
              "  (_fc): Linear(in_features=1792, out_features=2, bias=True)\n",
              "  (_swish): MemoryEfficientSwish()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymGrWxHfntKI",
        "colab_type": "text"
      },
      "source": [
        "#**Attention_branch_Network_ImageNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gESMORA2ntRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
        "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
        "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
        "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "\n",
        "class ResNet_ARN(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet_ARN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], down_size=True)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, down_size=True)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, down_size=True)\n",
        "\n",
        "        self.att_layer4 = self._make_layer(block, 512, layers[3], stride=1, down_size=False)\n",
        "        self.bn_att = nn.BatchNorm2d(512 * block.expansion)\n",
        "        self.att_conv   = nn.Conv2d(512 * block.expansion, num_classes, kernel_size=1, padding=0,\n",
        "                               bias=False)\n",
        "        self.bn_att2 = nn.BatchNorm2d(num_classes)\n",
        "        self.att_conv2  = nn.Conv2d(num_classes, num_classes, kernel_size=1, padding=0,\n",
        "                               bias=False)\n",
        "        self.att_conv3  = nn.Conv2d(num_classes, 1, kernel_size=3, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn_att3 = nn.BatchNorm2d(1)\n",
        "        self.att_gap = nn.AvgPool2d(14)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, down_size=True)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, down_size=True):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "\n",
        "        if down_size:\n",
        "            self.inplanes = planes * block.expansion\n",
        "            for i in range(1, blocks):\n",
        "                layers.append(block(self.inplanes, planes))\n",
        "\n",
        "            return nn.Sequential(*layers)\n",
        "        else:\n",
        "            inplanes = planes * block.expansion\n",
        "            for i in range(1, blocks):\n",
        "                layers.append(block(inplanes, planes))\n",
        "\n",
        "            return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        fe = x\n",
        "\n",
        "        ax = self.bn_att(self.att_layer4(x))\n",
        "        ax = self.relu(self.bn_att2(self.att_conv(ax)))\n",
        "        bs, cs, ys, xs = ax.shape\n",
        "        self.att = self.sigmoid(self.bn_att3(self.att_conv3(ax)))        \n",
        "        # self.att = self.att.view(bs, 1, ys, xs)\n",
        "        ax = self.att_conv2(ax)\n",
        "        ax = self.att_gap(ax)\n",
        "        ax = ax.view(ax.size(0), -1)\n",
        "\n",
        "        rx = x * self.att\n",
        "        rx = rx + x\n",
        "        per = rx\n",
        "        rx = self.layer4(rx)\n",
        "        rx = self.avgpool(rx)\n",
        "        rx = rx.view(rx.size(0), -1)\n",
        "        rx = self.fc(rx)\n",
        "\n",
        "        return ax, rx, [self.att, fe, per]\n",
        "\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "def resnetARN50(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet_ARN(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "#モデルのロード\n",
        "model_ft = resnetARN50().to(device)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#attention branch networkの最終出力を2つにする\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#ネットワークの読み込み\n",
        "PATH = '/content/drive/My Drive/Deep_learning/gravcont_att_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#ネットワークの読み込み\n",
        "PATH = '/content/drive/My Drive/Deep_learning/gravcont_att_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zLnknjNnqNU",
        "colab_type": "text"
      },
      "source": [
        "#**Calculate Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doQbOyGHpJYU",
        "colab_type": "code",
        "outputId": "c33e74f0-af0d-468d-a811-de439a74e68d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "#評価モードにする\n",
        "model_ft.eval()\n",
        "\n",
        "##########Calculate Accuracy#############\n",
        "#valフォルダ内のファイル名を取得\n",
        "image_path = glob.glob(\"/content/drive/My Drive/Deep_learning/gravcont_seed_1234/val/*/*\")\n",
        "random.shuffle(image_path)  #表示順をランダムにする\n",
        "print('number of images: ' +str(len(image_path)))\n",
        "#print(image_path) \n",
        "\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      return(image_name, label)\n",
        "\n",
        "'''\n",
        "#変形後の画像を表示\n",
        "def image_transform(image_path):\n",
        "\n",
        "    image=Image.open(image_path)\n",
        "\n",
        "    \n",
        "    #変形した画像を表示する\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224)])\n",
        "    image_transformed = transform(image)\n",
        "    plt.imshow(np.array(image_transformed))\n",
        "'''\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を表示\n",
        "def image_eval(image_tensor, label):\n",
        "    output = model_ft(image_tensor)\n",
        "    #print(output.size())  # torch.Size([1, 1000])\n",
        "    #print(output)\n",
        "\n",
        "    #model_pred:クラス名前、prob:確率、pred:クラス番号\n",
        "    prob, pred = torch.topk(nn.Softmax(dim=1)(output), 1)\n",
        "    model_pred = class_names[pred]\n",
        "    \n",
        "    #甲状腺眼症のprobabilityを計算（classが0なら1から減算、classが1ならそのまま）\n",
        "    prob = abs(1-float(prob)-float(pred))\n",
        " \n",
        "    return model_pred, prob, pred\n",
        "\n",
        " \n",
        "\n",
        "def showImage(image_path):\n",
        "    #画像のインポート\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    #画像のリサイズ\n",
        "    height = img.shape[0]\n",
        "    width = img.shape[1]\n",
        "    resized_img = cv2.resize(img, (int(width*300/height), 300))\n",
        "    cv2_imshow(resized_img)\n",
        "\n",
        "def calculateAccuracy (TP, TN, FP, FN):\n",
        "    accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "    precision  = TP/(FP + TP)\n",
        "    recall = TP/(TP + FN)\n",
        "    specificity = TN/(FP + TN)\n",
        "    f_value = (2*recall*precision)/(recall+precision)\n",
        "    return(accuracy, precision, recall, specificity, f_value)\n",
        "\n",
        "\n",
        "#ここからがメイン\n",
        "TP, FP, TN, FN, TP, FP, TN, FN = [0,0,0,0,0,0,0,0]\n",
        "image_name_list = []\n",
        "label_list = []\n",
        "model_pred_list = []\n",
        "hum_pred_list = []\n",
        "\n",
        "model_pred_class = []\n",
        "model_pred_prob = []\n",
        "\n",
        "\n",
        "for i in image_path:\n",
        "      image_name, label = getlabel(i)  #画像の名前とラベルを取得\n",
        "      image_tensor = image_transform(i)  #予測のための画像下処理\n",
        "      model_pred, prob, pred = image_eval(image_tensor, label)  #予測結果を出力   \n",
        "      #print('Image: '+ image_name)\n",
        "      #print('Label: '+ label)\n",
        "      #print('Pred: '+ model_pred)\n",
        "      #showImage(i)  #画像を表示\n",
        "      #print() #空白行を入れる\n",
        "      time.sleep(0.1)\n",
        "\n",
        "      image_name_list.append(image_name)\n",
        "      label_list.append(label)\n",
        "      model_pred_list.append(model_pred)\n",
        "\n",
        "      model_pred_class.append(int(pred))\n",
        "      model_pred_prob.append(float(prob))\n",
        "\n",
        "      if label == class_names[0]:\n",
        "          if model_pred == class_names[0]:\n",
        "              TP += 1\n",
        "          else:\n",
        "              FN += 1\n",
        "      elif label == class_names[1]:\n",
        "          if model_pred == class_names[1]:\n",
        "              TN += 1\n",
        "          else:\n",
        "              FP += 1\n",
        "      \n",
        "\n",
        "print(TP, FN, TN, FP)\n",
        "\n",
        "#Accuracyを計算\n",
        "accuracy, precision, recall, specificity, f_value = calculateAccuracy (TP, TN, FP, FN)\n",
        "print('Accuracy: ' + str(accuracy))\n",
        "print('Precision (positive predictive value): ' + str(precision))\n",
        "print('Recall (sensitivity): ' + str(recall))\n",
        "print('Specificity: ' + str(specificity))\n",
        "print('F_value: ' + str(f_value))\n",
        "\n",
        "print(model_pred_class)\n",
        "print(model_pred_prob)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of images: 128\n",
            "55 10 52 11\n",
            "Accuracy: 0.8359375\n",
            "Precision (positive predictive value): 0.8333333333333334\n",
            "Recall (sensitivity): 0.8461538461538461\n",
            "Specificity: 0.8253968253968254\n",
            "F_value: 0.8396946564885497\n",
            "[1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0]\n",
            "[0.9996860027313232, 0.19384342432022095, 0.9682963490486145, 0.05026644468307495, 0.9997363686561584, 0.9948262572288513, 0.8373451232910156, 0.9949856996536255, 0.0016132593154907227, 0.6909021735191345, 0.9187161326408386, 0.9654382467269897, 0.9996063113212585, 0.264887273311615, 0.002390146255493164, 0.03855407238006592, 0.03431934118270874, 0.999996542930603, 0.9275049567222595, 0.01568394899368286, 0.9999167919158936, 0.25570911169052124, 0.9989601373672485, 0.5837364196777344, 0.9974523186683655, 0.23202413320541382, 0.5740213394165039, 0.9992615580558777, 0.0017742514610290527, 0.0781937837600708, 0.001295924186706543, 0.999346911907196, 0.3965498208999634, 0.9918732047080994, 0.00048291683197021484, 0.01166313886642456, 0.01883256435394287, 0.9608086347579956, 0.9997565150260925, 0.03918254375457764, 0.9933193922042847, 0.0006622672080993652, 0.9958206415176392, 0.0006186962127685547, 0.9987878203392029, 0.006403803825378418, 0.6457246541976929, 0.8137943744659424, 0.9997701048851013, 0.893115222454071, 0.6945501565933228, 0.4798583388328552, 0.14230114221572876, 0.13252699375152588, 0.9479318261146545, 0.9998812675476074, 0.0011022090911865234, 0.00047969818115234375, 6.365776062011719e-05, 0.9919238686561584, 0.09144806861877441, 0.1640034317970276, 0.0001442432403564453, 0.9876694083213806, 0.9947071671485901, 0.9999672174453735, 0.9994410872459412, 0.3774157762527466, 0.9999662637710571, 0.001439511775970459, 0.796005129814148, 0.05754077434539795, 0.9990183115005493, 0.05251777172088623, 0.0002949833869934082, 0.00044339895248413086, 0.0007756948471069336, 0.026497840881347656, 0.9884399175643921, 0.8968398571014404, 0.0034273862838745117, 0.9756994247436523, 0.005273997783660889, 0.02578216791152954, 0.00036978721618652344, 4.947185516357422e-05, 0.030348539352416992, 0.007214009761810303, 0.987168550491333, 0.0036216378211975098, 0.8732224702835083, 0.9999723434448242, 0.006132781505584717, 0.939141035079956, 0.03599947690963745, 0.5668220520019531, 0.009379982948303223, 0.0562778115272522, 0.7031485438346863, 0.0007329583168029785, 0.7866513729095459, 0.9996297359466553, 0.00605165958404541, 0.9996174573898315, 0.8678984045982361, 0.020458638668060303, 0.9714308977127075, 4.3392181396484375e-05, 0.23124438524246216, 0.6500134468078613, 0.9857271313667297, 0.2549120783805847, 0.9994408488273621, 0.021691620349884033, 0.9679014086723328, 0.9942470788955688, 0.006535828113555908, 0.003927350044250488, 0.9590821266174316, 0.14627480506896973, 0.00014698505401611328, 0.005148470401763916, 0.05095946788787842, 0.037167251110076904, 0.25779902935028076, 0.9984018206596375, 0.9928105473518372, 0.10499632358551025]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVay7Id8oIPK",
        "colab_type": "text"
      },
      "source": [
        "#**Drawing ROC curve** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_c2zVMKoIVK",
        "colab_type": "code",
        "outputId": "b5903442-d25c-4058-d185-7f86d2e4928f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_score = []\n",
        "y_true = []\n",
        "\n",
        "k=0\n",
        "for i in label_list:\n",
        "    if label_list[k] == 'cont':\n",
        "          y_true.append(0)\n",
        "    elif label_list[k] == 'grav':\n",
        "          y_true.append(1)\n",
        "    k+=1\n",
        "\n",
        "\n",
        "#健康な状態を「0」、病気を「1」としてラベルよりリストを作成\n",
        "y_true = y_true\n",
        "#それぞれの画像における陽性の確率についてリストを作成\n",
        "y_score = model_pred_prob\n",
        "\n",
        "#print(y_true)\n",
        "#print(y_score)\n",
        "\n",
        "fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "#print(fpr)\n",
        "#print(tpr)\n",
        "\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}