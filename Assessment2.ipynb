{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled35.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO2tYRppTX/v5g6U79+qWaz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "257dd1df1bc047cdb106d16b83120c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9c34f073cd8b4829a1d8dada7b403ad3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2dd26a665da34b8c9e1df818852f2903",
              "IPY_MODEL_00224a91fc8d4e1fbf3aa24dc3b72e79"
            ]
          }
        },
        "9c34f073cd8b4829a1d8dada7b403ad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2dd26a665da34b8c9e1df818852f2903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a8ea6ebe16764b5b8c76b9ada35596a6",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 77999237,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 77999237,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5bcae66d5ff547d0b096f976c5f1cd6c"
          }
        },
        "00224a91fc8d4e1fbf3aa24dc3b72e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eed2a602181543f388550239fddc62d4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 74.4M/74.4M [00:02&lt;00:00, 27.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22470e6ed8214e47a66a31d693dece15"
          }
        },
        "a8ea6ebe16764b5b8c76b9ada35596a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5bcae66d5ff547d0b096f976c5f1cd6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eed2a602181543f388550239fddc62d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22470e6ed8214e47a66a31d693dece15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/Assessment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpC0Fk9lUn2",
        "colab_type": "text"
      },
      "source": [
        "#**Assessment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9B59fSXlT5f",
        "colab_type": "code",
        "outputId": "01090198-91f8-4ca5-c2cc-f6ece884c972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "#Advanced Pytorchから\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set random seem for reproducibility\n",
        "manualSeed = 1234\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.cuda.manual_seed(manualSeed)\n",
        "\n",
        "torch.torch.backends.cudnn.benchmark = True\n",
        "torch.torch.backends.cudnn.enabled = True\n",
        "\n",
        "\n",
        "'''\n",
        "grav: 甲状腺眼症\n",
        "cont: コントロール\n",
        "黒の空白を挿入することにより225px*225pxの画像を生成、EfficientNetを用いて転移学習\n",
        "－－－－－－－－－－－－－－\n",
        "データの構造\n",
        "gravcont.zip ------grav\n",
        "               |---cont\n",
        "'''                                     \n",
        "\n",
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed:  1234\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHO1RjNom0Pr",
        "colab_type": "text"
      },
      "source": [
        "#**モジュール群**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-yVbbvSm3Ay",
        "colab_type": "code",
        "outputId": "59055e0f-d599-4b0f-d48e-8ee07f1d133d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "#ModelNameをリストにする\n",
        "ModelName_list = []\n",
        "ModelName = ''\n",
        "model_pred_prob = []\n",
        "\n",
        "def checkModelName(ModelName, ModelName_list):\n",
        "    if ModelName in ModelName_list:\n",
        "        raise Exception(\"This model has been already loaded\")\n",
        "    else:\n",
        "        ModelName_list.append(ModelName)\n",
        "\n",
        "\n",
        "# 入力画像の前処理をするクラス\n",
        "# 訓練時と推論時で処理が異なる\n",
        "\n",
        "\"\"\"\n",
        "    画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "    画像のサイズをリサイズし、色を標準化する。\n",
        "    訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n",
        "\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    resize : int\n",
        "        リサイズ先の画像の大きさ。\n",
        "    mean : (R, G, B)\n",
        "        各色チャネルの平均値。\n",
        "    std : (R, G, B)\n",
        "        各色チャネルの標準偏差。\n",
        "\"\"\"\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224, scale=(0.75,1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/drive/My Drive/Deep_learning/gravcont_seed_1234'\n",
        "n_samples = len(data_dir)\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=20,\n",
        "                                             shuffle=True, num_workers=0)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "print(class_names)\n",
        "k=0\n",
        "for i in class_names:\n",
        "    print(class_names[k]+\"_train:\"+str(len(os.listdir(path='/content/drive/My Drive/Deep_learning/gravcont_seed_1234/train/'+class_names[k]))))\n",
        "    k+=1\n",
        "k=0\n",
        "for i in class_names:\n",
        "    print(class_names[k]+\"_val:\"+str(len(os.listdir(path='/content/drive/My Drive/Deep_learning/gravcont_seed_1234/val/'+class_names[k]))))\n",
        "    k+=1\n",
        "\n",
        "print(\"training data set_total：\"+ str(len(image_datasets['train'])))\n",
        "print(\"validating data set_total：\"+str(len(image_datasets['val'])))\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cont', 'grav']\n",
            "cont_train:256\n",
            "grav_train:252\n",
            "cont_val:65\n",
            "grav_val:63\n",
            "training data set_total：508\n",
            "validating data set_total：128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zLnknjNnqNU",
        "colab_type": "text"
      },
      "source": [
        "#**Calculate Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doQbOyGHpJYU",
        "colab_type": "code",
        "outputId": "efaddfd3-feef-45c4-b780-367a9c25f69b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "##########Calculate Accuracy#############\n",
        "#valフォルダ内のファイル名を取得\n",
        "image_path = glob.glob(\"/content/drive/My Drive/Deep_learning/gravcont_seed_1234/val/*/*\")\n",
        "random.shuffle(image_path)  #表示順をランダムにする\n",
        "print('number of images: ' +str(len(image_path)))\n",
        "#print(image_path) \n",
        "\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      return(image_name, label)\n",
        "\n",
        "'''\n",
        "#変形後の画像を表示\n",
        "def image_transform(image_path):\n",
        "\n",
        "    image=Image.open(image_path)\n",
        "\n",
        "    \n",
        "    #変形した画像を表示する\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224)])\n",
        "    image_transformed = transform(image)\n",
        "    plt.imshow(np.array(image_transformed))\n",
        "'''\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を表示\n",
        "def image_eval(image_tensor, label):\n",
        "    \n",
        "    if ModelName == 'Attention_branch_Network_ImageNet':\n",
        "        _, output, _ = model_ft(image_tensor)\n",
        "    else:\n",
        "        output = model_ft(image_tensor)\n",
        "    #print(output.size())  # torch.Size([1, 1000])\n",
        "    #print(output)\n",
        "\n",
        "    #評価モードにする\n",
        "    model_ft.eval()\n",
        "\n",
        "    #model_pred:クラス名前、prob:確率、pred:クラス番号\n",
        "    prob, pred = torch.topk(nn.Softmax(dim=1)(output), 1)\n",
        "    model_pred = class_names[pred]\n",
        "    \n",
        "    #甲状腺眼症のprobabilityを計算（classが0なら1から減算、classが1ならそのまま）\n",
        "    prob = abs(1-float(prob)-float(pred))\n",
        " \n",
        "    return model_pred, prob, pred\n",
        "\n",
        "\n",
        "def showImage(image_path):\n",
        "    #画像のインポート\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    #画像のリサイズ\n",
        "    height = img.shape[0]\n",
        "    width = img.shape[1]\n",
        "    resized_img = cv2.resize(img, (int(width*300/height), 300))\n",
        "    cv2_imshow(resized_img)\n",
        "\n",
        "def calculateAccuracy (image_path):\n",
        "\n",
        "    #ここからがメイン\n",
        "    TP, FP, TN, FN, TP, FP, TN, FN = [0,0,0,0,0,0,0,0]\n",
        "    image_name_list = []\n",
        "    label_list = []\n",
        "    model_pred_list = []\n",
        "    hum_pred_list = []\n",
        "\n",
        "    model_pred_class = []\n",
        "    model_pred_prob = []\n",
        "\n",
        "    for i in image_path:\n",
        "          image_name, label = getlabel(i)  #画像の名前とラベルを取得\n",
        "          image_tensor = image_transform(i)  #予測のための画像下処理\n",
        "          model_pred, prob, pred = image_eval(image_tensor, label)  #予測結果を出力 \n",
        "\n",
        "          #print('Image: '+ image_name)\n",
        "          #print('Label: '+ label)\n",
        "          #print('Pred: '+ model_pred)\n",
        "          #showImage(i)  #画像を表示\n",
        "          #print() #空白行を入れる\n",
        "          time.sleep(0.1)\n",
        "\n",
        "          image_name_list.append(image_name)\n",
        "          label_list.append(label)\n",
        "          model_pred_list.append(model_pred)\n",
        "\n",
        "          model_pred_class.append(int(pred))\n",
        "          model_pred_prob.append(float(prob))\n",
        "\n",
        "          if label == class_names[0]:\n",
        "              if model_pred == class_names[0]:\n",
        "                  TP += 1\n",
        "              else:\n",
        "                  FN += 1\n",
        "          elif label == class_names[1]:\n",
        "              if model_pred == class_names[1]:\n",
        "                  TN += 1\n",
        "              else:\n",
        "                  FP += 1\n",
        "          \n",
        "\n",
        "    print(TP, FN, TN, FP)\n",
        "\n",
        "    #Accuracyを計算\n",
        "    accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "    precision  = TP/(FP + TP)\n",
        "    recall = TP/(TP + FN)\n",
        "    specificity = TN/(FP + TN)\n",
        "    f_value = (2*recall*precision)/(recall+precision)\n",
        "    \n",
        "    print('Accuracy: ' + str(accuracy))\n",
        "    print('Precision (positive predictive value): ' + str(precision))\n",
        "    print('Recall (sensitivity): ' + str(recall))\n",
        "    print('Specificity: ' + str(specificity))\n",
        "    print('F_value: ' + str(f_value))\n",
        "\n",
        "    #print(model_pred_class)\n",
        "    #print(model_pred_prob)\n",
        "\n",
        "    #return(accuracy, precision, recall, specificity, f_value)\n",
        "    return model_pred_prob, label_list\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of images: 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk-s71bSlLMJ",
        "colab_type": "text"
      },
      "source": [
        "#**ResNet50_VGGFace2のネットワーク**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twcn29TKk7kM",
        "colab_type": "code",
        "outputId": "1933d419-d21e-41b0-d4ad-f747d671dd50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "ModelName = 'ResNet50_VGGFace2'\n",
        "checkModelName(ModelName, ModelName_list)\n",
        "\n",
        "class Resnet50_ft_dag(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Resnet50_ft_dag, self).__init__()\n",
        "        self.meta = {'mean': [131.0912, 103.8827, 91.4953],\n",
        "                     'std': [1, 1, 1],\n",
        "                     'imageSize': [224, 224, 3]}\n",
        "        self.conv1_7x7_s2 = nn.Conv2d(3, 64, kernel_size=[7, 7], stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        self.conv1_7x7_s2_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv1_relu_7x7_s2 = nn.ReLU()\n",
        "        self.pool1_3x3_s2 = nn.MaxPool2d(kernel_size=[3, 3], stride=[2, 2], padding=(0, 0), dilation=1, ceil_mode=True)\n",
        "        self.conv2_1_1x1_reduce = nn.Conv2d(64, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_1_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_1_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_3x3_relu = nn.ReLU()\n",
        "        self.conv2_1_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_1x1_proj = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_proj_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_relu = nn.ReLU()\n",
        "        self.conv2_2_1x1_reduce = nn.Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_2_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_2_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_2_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_3x3_relu = nn.ReLU()\n",
        "        self.conv2_2_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_2_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_relu = nn.ReLU()\n",
        "        self.conv2_3_1x1_reduce = nn.Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_3_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_3_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_3_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_3x3_relu = nn.ReLU()\n",
        "        self.conv2_3_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_3_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_relu = nn.ReLU()\n",
        "        self.conv3_1_1x1_reduce = nn.Conv2d(256, 128, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv3_1_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_1_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_1_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_3x3_relu = nn.ReLU()\n",
        "        self.conv3_1_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_1_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_1x1_proj = nn.Conv2d(256, 512, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv3_1_1x1_proj_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_relu = nn.ReLU()\n",
        "        self.conv3_2_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_2_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_2_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_2_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_3x3_relu = nn.ReLU()\n",
        "        self.conv3_2_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_2_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_relu = nn.ReLU()\n",
        "        self.conv3_3_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_3_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_3_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_3_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_3x3_relu = nn.ReLU()\n",
        "        self.conv3_3_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_3_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_relu = nn.ReLU()\n",
        "        self.conv3_4_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_4_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_4_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_4_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_3x3_relu = nn.ReLU()\n",
        "        self.conv3_4_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_4_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_relu = nn.ReLU()\n",
        "        self.conv4_1_1x1_reduce = nn.Conv2d(512, 256, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv4_1_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_1_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_1_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_3x3_relu = nn.ReLU()\n",
        "        self.conv4_1_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_1_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_1x1_proj = nn.Conv2d(512, 1024, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv4_1_1x1_proj_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_relu = nn.ReLU()\n",
        "        self.conv4_2_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_2_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_2_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_2_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_3x3_relu = nn.ReLU()\n",
        "        self.conv4_2_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_2_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_relu = nn.ReLU()\n",
        "        self.conv4_3_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_3_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_3_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_3_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_3x3_relu = nn.ReLU()\n",
        "        self.conv4_3_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_3_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_relu = nn.ReLU()\n",
        "        self.conv4_4_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_4_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_4_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_4_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_3x3_relu = nn.ReLU()\n",
        "        self.conv4_4_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_4_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_relu = nn.ReLU()\n",
        "        self.conv4_5_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_5_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_5_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_5_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_3x3_relu = nn.ReLU()\n",
        "        self.conv4_5_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_5_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_relu = nn.ReLU()\n",
        "        self.conv4_6_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_6_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_6_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_6_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_3x3_relu = nn.ReLU()\n",
        "        self.conv4_6_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_6_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_relu = nn.ReLU()\n",
        "        self.conv5_1_1x1_reduce = nn.Conv2d(1024, 512, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv5_1_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_1_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_1_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_3x3_relu = nn.ReLU()\n",
        "        self.conv5_1_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_1_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_1x1_proj = nn.Conv2d(1024, 2048, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv5_1_1x1_proj_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_relu = nn.ReLU()\n",
        "        self.conv5_2_1x1_reduce = nn.Conv2d(2048, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_2_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_2_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_2_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_3x3_relu = nn.ReLU()\n",
        "        self.conv5_2_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_2_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_relu = nn.ReLU()\n",
        "        self.conv5_3_1x1_reduce = nn.Conv2d(2048, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_3_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_3_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_3_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_3x3_relu = nn.ReLU()\n",
        "        self.conv5_3_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_3_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_relu = nn.ReLU()\n",
        "        self.pool5_7x7_s1 = nn.AvgPool2d(kernel_size=[7, 7], stride=[1, 1], padding=0)\n",
        "        self.classifier = nn.Conv2d(2048, 8631, kernel_size=[1, 1], stride=(1, 1))\n",
        "\n",
        "    def forward(self, data):\n",
        "        conv1_7x7_s2 = self.conv1_7x7_s2(data)\n",
        "        conv1_7x7_s2_bn = self.conv1_7x7_s2_bn(conv1_7x7_s2)\n",
        "        conv1_7x7_s2_bnxx = self.conv1_relu_7x7_s2(conv1_7x7_s2_bn)\n",
        "        pool1_3x3_s2 = self.pool1_3x3_s2(conv1_7x7_s2_bnxx)\n",
        "        conv2_1_1x1_reduce = self.conv2_1_1x1_reduce(pool1_3x3_s2)\n",
        "        conv2_1_1x1_reduce_bn = self.conv2_1_1x1_reduce_bn(conv2_1_1x1_reduce)\n",
        "        conv2_1_1x1_reduce_bnxx = self.conv2_1_1x1_reduce_relu(conv2_1_1x1_reduce_bn)\n",
        "        conv2_1_3x3 = self.conv2_1_3x3(conv2_1_1x1_reduce_bnxx)\n",
        "        conv2_1_3x3_bn = self.conv2_1_3x3_bn(conv2_1_3x3)\n",
        "        conv2_1_3x3_bnxx = self.conv2_1_3x3_relu(conv2_1_3x3_bn)\n",
        "        conv2_1_1x1_increase = self.conv2_1_1x1_increase(conv2_1_3x3_bnxx)\n",
        "        conv2_1_1x1_increase_bn = self.conv2_1_1x1_increase_bn(conv2_1_1x1_increase)\n",
        "        conv2_1_1x1_proj = self.conv2_1_1x1_proj(pool1_3x3_s2)\n",
        "        conv2_1_1x1_proj_bn = self.conv2_1_1x1_proj_bn(conv2_1_1x1_proj)\n",
        "        conv2_1 = torch.add(conv2_1_1x1_proj_bn, 1, conv2_1_1x1_increase_bn)\n",
        "        conv2_1x = self.conv2_1_relu(conv2_1)\n",
        "        conv2_2_1x1_reduce = self.conv2_2_1x1_reduce(conv2_1x)\n",
        "        conv2_2_1x1_reduce_bn = self.conv2_2_1x1_reduce_bn(conv2_2_1x1_reduce)\n",
        "        conv2_2_1x1_reduce_bnxx = self.conv2_2_1x1_reduce_relu(conv2_2_1x1_reduce_bn)\n",
        "        conv2_2_3x3 = self.conv2_2_3x3(conv2_2_1x1_reduce_bnxx)\n",
        "        conv2_2_3x3_bn = self.conv2_2_3x3_bn(conv2_2_3x3)\n",
        "        conv2_2_3x3_bnxx = self.conv2_2_3x3_relu(conv2_2_3x3_bn)\n",
        "        conv2_2_1x1_increase = self.conv2_2_1x1_increase(conv2_2_3x3_bnxx)\n",
        "        conv2_2_1x1_increase_bn = self.conv2_2_1x1_increase_bn(conv2_2_1x1_increase)\n",
        "        conv2_2 = torch.add(conv2_1x, 1, conv2_2_1x1_increase_bn)\n",
        "        conv2_2x = self.conv2_2_relu(conv2_2)\n",
        "        conv2_3_1x1_reduce = self.conv2_3_1x1_reduce(conv2_2x)\n",
        "        conv2_3_1x1_reduce_bn = self.conv2_3_1x1_reduce_bn(conv2_3_1x1_reduce)\n",
        "        conv2_3_1x1_reduce_bnxx = self.conv2_3_1x1_reduce_relu(conv2_3_1x1_reduce_bn)\n",
        "        conv2_3_3x3 = self.conv2_3_3x3(conv2_3_1x1_reduce_bnxx)\n",
        "        conv2_3_3x3_bn = self.conv2_3_3x3_bn(conv2_3_3x3)\n",
        "        conv2_3_3x3_bnxx = self.conv2_3_3x3_relu(conv2_3_3x3_bn)\n",
        "        conv2_3_1x1_increase = self.conv2_3_1x1_increase(conv2_3_3x3_bnxx)\n",
        "        conv2_3_1x1_increase_bn = self.conv2_3_1x1_increase_bn(conv2_3_1x1_increase)\n",
        "        conv2_3 = torch.add(conv2_2x, 1, conv2_3_1x1_increase_bn)\n",
        "        conv2_3x = self.conv2_3_relu(conv2_3)\n",
        "        conv3_1_1x1_reduce = self.conv3_1_1x1_reduce(conv2_3x)\n",
        "        conv3_1_1x1_reduce_bn = self.conv3_1_1x1_reduce_bn(conv3_1_1x1_reduce)\n",
        "        conv3_1_1x1_reduce_bnxx = self.conv3_1_1x1_reduce_relu(conv3_1_1x1_reduce_bn)\n",
        "        conv3_1_3x3 = self.conv3_1_3x3(conv3_1_1x1_reduce_bnxx)\n",
        "        conv3_1_3x3_bn = self.conv3_1_3x3_bn(conv3_1_3x3)\n",
        "        conv3_1_3x3_bnxx = self.conv3_1_3x3_relu(conv3_1_3x3_bn)\n",
        "        conv3_1_1x1_increase = self.conv3_1_1x1_increase(conv3_1_3x3_bnxx)\n",
        "        conv3_1_1x1_increase_bn = self.conv3_1_1x1_increase_bn(conv3_1_1x1_increase)\n",
        "        conv3_1_1x1_proj = self.conv3_1_1x1_proj(conv2_3x)\n",
        "        conv3_1_1x1_proj_bn = self.conv3_1_1x1_proj_bn(conv3_1_1x1_proj)\n",
        "        conv3_1 = torch.add(conv3_1_1x1_proj_bn, 1, conv3_1_1x1_increase_bn)\n",
        "        conv3_1x = self.conv3_1_relu(conv3_1)\n",
        "        conv3_2_1x1_reduce = self.conv3_2_1x1_reduce(conv3_1x)\n",
        "        conv3_2_1x1_reduce_bn = self.conv3_2_1x1_reduce_bn(conv3_2_1x1_reduce)\n",
        "        conv3_2_1x1_reduce_bnxx = self.conv3_2_1x1_reduce_relu(conv3_2_1x1_reduce_bn)\n",
        "        conv3_2_3x3 = self.conv3_2_3x3(conv3_2_1x1_reduce_bnxx)\n",
        "        conv3_2_3x3_bn = self.conv3_2_3x3_bn(conv3_2_3x3)\n",
        "        conv3_2_3x3_bnxx = self.conv3_2_3x3_relu(conv3_2_3x3_bn)\n",
        "        conv3_2_1x1_increase = self.conv3_2_1x1_increase(conv3_2_3x3_bnxx)\n",
        "        conv3_2_1x1_increase_bn = self.conv3_2_1x1_increase_bn(conv3_2_1x1_increase)\n",
        "        conv3_2 = torch.add(conv3_1x, 1, conv3_2_1x1_increase_bn)\n",
        "        conv3_2x = self.conv3_2_relu(conv3_2)\n",
        "        conv3_3_1x1_reduce = self.conv3_3_1x1_reduce(conv3_2x)\n",
        "        conv3_3_1x1_reduce_bn = self.conv3_3_1x1_reduce_bn(conv3_3_1x1_reduce)\n",
        "        conv3_3_1x1_reduce_bnxx = self.conv3_3_1x1_reduce_relu(conv3_3_1x1_reduce_bn)\n",
        "        conv3_3_3x3 = self.conv3_3_3x3(conv3_3_1x1_reduce_bnxx)\n",
        "        conv3_3_3x3_bn = self.conv3_3_3x3_bn(conv3_3_3x3)\n",
        "        conv3_3_3x3_bnxx = self.conv3_3_3x3_relu(conv3_3_3x3_bn)\n",
        "        conv3_3_1x1_increase = self.conv3_3_1x1_increase(conv3_3_3x3_bnxx)\n",
        "        conv3_3_1x1_increase_bn = self.conv3_3_1x1_increase_bn(conv3_3_1x1_increase)\n",
        "        conv3_3 = torch.add(conv3_2x, 1, conv3_3_1x1_increase_bn)\n",
        "        conv3_3x = self.conv3_3_relu(conv3_3)\n",
        "        conv3_4_1x1_reduce = self.conv3_4_1x1_reduce(conv3_3x)\n",
        "        conv3_4_1x1_reduce_bn = self.conv3_4_1x1_reduce_bn(conv3_4_1x1_reduce)\n",
        "        conv3_4_1x1_reduce_bnxx = self.conv3_4_1x1_reduce_relu(conv3_4_1x1_reduce_bn)\n",
        "        conv3_4_3x3 = self.conv3_4_3x3(conv3_4_1x1_reduce_bnxx)\n",
        "        conv3_4_3x3_bn = self.conv3_4_3x3_bn(conv3_4_3x3)\n",
        "        conv3_4_3x3_bnxx = self.conv3_4_3x3_relu(conv3_4_3x3_bn)\n",
        "        conv3_4_1x1_increase = self.conv3_4_1x1_increase(conv3_4_3x3_bnxx)\n",
        "        conv3_4_1x1_increase_bn = self.conv3_4_1x1_increase_bn(conv3_4_1x1_increase)\n",
        "        conv3_4 = torch.add(conv3_3x, 1, conv3_4_1x1_increase_bn)\n",
        "        conv3_4x = self.conv3_4_relu(conv3_4)\n",
        "        conv4_1_1x1_reduce = self.conv4_1_1x1_reduce(conv3_4x)\n",
        "        conv4_1_1x1_reduce_bn = self.conv4_1_1x1_reduce_bn(conv4_1_1x1_reduce)\n",
        "        conv4_1_1x1_reduce_bnxx = self.conv4_1_1x1_reduce_relu(conv4_1_1x1_reduce_bn)\n",
        "        conv4_1_3x3 = self.conv4_1_3x3(conv4_1_1x1_reduce_bnxx)\n",
        "        conv4_1_3x3_bn = self.conv4_1_3x3_bn(conv4_1_3x3)\n",
        "        conv4_1_3x3_bnxx = self.conv4_1_3x3_relu(conv4_1_3x3_bn)\n",
        "        conv4_1_1x1_increase = self.conv4_1_1x1_increase(conv4_1_3x3_bnxx)\n",
        "        conv4_1_1x1_increase_bn = self.conv4_1_1x1_increase_bn(conv4_1_1x1_increase)\n",
        "        conv4_1_1x1_proj = self.conv4_1_1x1_proj(conv3_4x)\n",
        "        conv4_1_1x1_proj_bn = self.conv4_1_1x1_proj_bn(conv4_1_1x1_proj)\n",
        "        conv4_1 = torch.add(conv4_1_1x1_proj_bn, 1, conv4_1_1x1_increase_bn)\n",
        "        conv4_1x = self.conv4_1_relu(conv4_1)\n",
        "        conv4_2_1x1_reduce = self.conv4_2_1x1_reduce(conv4_1x)\n",
        "        conv4_2_1x1_reduce_bn = self.conv4_2_1x1_reduce_bn(conv4_2_1x1_reduce)\n",
        "        conv4_2_1x1_reduce_bnxx = self.conv4_2_1x1_reduce_relu(conv4_2_1x1_reduce_bn)\n",
        "        conv4_2_3x3 = self.conv4_2_3x3(conv4_2_1x1_reduce_bnxx)\n",
        "        conv4_2_3x3_bn = self.conv4_2_3x3_bn(conv4_2_3x3)\n",
        "        conv4_2_3x3_bnxx = self.conv4_2_3x3_relu(conv4_2_3x3_bn)\n",
        "        conv4_2_1x1_increase = self.conv4_2_1x1_increase(conv4_2_3x3_bnxx)\n",
        "        conv4_2_1x1_increase_bn = self.conv4_2_1x1_increase_bn(conv4_2_1x1_increase)\n",
        "        conv4_2 = torch.add(conv4_1x, 1, conv4_2_1x1_increase_bn)\n",
        "        conv4_2x = self.conv4_2_relu(conv4_2)\n",
        "        conv4_3_1x1_reduce = self.conv4_3_1x1_reduce(conv4_2x)\n",
        "        conv4_3_1x1_reduce_bn = self.conv4_3_1x1_reduce_bn(conv4_3_1x1_reduce)\n",
        "        conv4_3_1x1_reduce_bnxx = self.conv4_3_1x1_reduce_relu(conv4_3_1x1_reduce_bn)\n",
        "        conv4_3_3x3 = self.conv4_3_3x3(conv4_3_1x1_reduce_bnxx)\n",
        "        conv4_3_3x3_bn = self.conv4_3_3x3_bn(conv4_3_3x3)\n",
        "        conv4_3_3x3_bnxx = self.conv4_3_3x3_relu(conv4_3_3x3_bn)\n",
        "        conv4_3_1x1_increase = self.conv4_3_1x1_increase(conv4_3_3x3_bnxx)\n",
        "        conv4_3_1x1_increase_bn = self.conv4_3_1x1_increase_bn(conv4_3_1x1_increase)\n",
        "        conv4_3 = torch.add(conv4_2x, 1, conv4_3_1x1_increase_bn)\n",
        "        conv4_3x = self.conv4_3_relu(conv4_3)\n",
        "        conv4_4_1x1_reduce = self.conv4_4_1x1_reduce(conv4_3x)\n",
        "        conv4_4_1x1_reduce_bn = self.conv4_4_1x1_reduce_bn(conv4_4_1x1_reduce)\n",
        "        conv4_4_1x1_reduce_bnxx = self.conv4_4_1x1_reduce_relu(conv4_4_1x1_reduce_bn)\n",
        "        conv4_4_3x3 = self.conv4_4_3x3(conv4_4_1x1_reduce_bnxx)\n",
        "        conv4_4_3x3_bn = self.conv4_4_3x3_bn(conv4_4_3x3)\n",
        "        conv4_4_3x3_bnxx = self.conv4_4_3x3_relu(conv4_4_3x3_bn)\n",
        "        conv4_4_1x1_increase = self.conv4_4_1x1_increase(conv4_4_3x3_bnxx)\n",
        "        conv4_4_1x1_increase_bn = self.conv4_4_1x1_increase_bn(conv4_4_1x1_increase)\n",
        "        conv4_4 = torch.add(conv4_3x, 1, conv4_4_1x1_increase_bn)\n",
        "        conv4_4x = self.conv4_4_relu(conv4_4)\n",
        "        conv4_5_1x1_reduce = self.conv4_5_1x1_reduce(conv4_4x)\n",
        "        conv4_5_1x1_reduce_bn = self.conv4_5_1x1_reduce_bn(conv4_5_1x1_reduce)\n",
        "        conv4_5_1x1_reduce_bnxx = self.conv4_5_1x1_reduce_relu(conv4_5_1x1_reduce_bn)\n",
        "        conv4_5_3x3 = self.conv4_5_3x3(conv4_5_1x1_reduce_bnxx)\n",
        "        conv4_5_3x3_bn = self.conv4_5_3x3_bn(conv4_5_3x3)\n",
        "        conv4_5_3x3_bnxx = self.conv4_5_3x3_relu(conv4_5_3x3_bn)\n",
        "        conv4_5_1x1_increase = self.conv4_5_1x1_increase(conv4_5_3x3_bnxx)\n",
        "        conv4_5_1x1_increase_bn = self.conv4_5_1x1_increase_bn(conv4_5_1x1_increase)\n",
        "        conv4_5 = torch.add(conv4_4x, 1, conv4_5_1x1_increase_bn)\n",
        "        conv4_5x = self.conv4_5_relu(conv4_5)\n",
        "        conv4_6_1x1_reduce = self.conv4_6_1x1_reduce(conv4_5x)\n",
        "        conv4_6_1x1_reduce_bn = self.conv4_6_1x1_reduce_bn(conv4_6_1x1_reduce)\n",
        "        conv4_6_1x1_reduce_bnxx = self.conv4_6_1x1_reduce_relu(conv4_6_1x1_reduce_bn)\n",
        "        conv4_6_3x3 = self.conv4_6_3x3(conv4_6_1x1_reduce_bnxx)\n",
        "        conv4_6_3x3_bn = self.conv4_6_3x3_bn(conv4_6_3x3)\n",
        "        conv4_6_3x3_bnxx = self.conv4_6_3x3_relu(conv4_6_3x3_bn)\n",
        "        conv4_6_1x1_increase = self.conv4_6_1x1_increase(conv4_6_3x3_bnxx)\n",
        "        conv4_6_1x1_increase_bn = self.conv4_6_1x1_increase_bn(conv4_6_1x1_increase)\n",
        "        conv4_6 = torch.add(conv4_5x, 1, conv4_6_1x1_increase_bn)\n",
        "        conv4_6x = self.conv4_6_relu(conv4_6)\n",
        "        conv5_1_1x1_reduce = self.conv5_1_1x1_reduce(conv4_6x)\n",
        "        conv5_1_1x1_reduce_bn = self.conv5_1_1x1_reduce_bn(conv5_1_1x1_reduce)\n",
        "        conv5_1_1x1_reduce_bnxx = self.conv5_1_1x1_reduce_relu(conv5_1_1x1_reduce_bn)\n",
        "        conv5_1_3x3 = self.conv5_1_3x3(conv5_1_1x1_reduce_bnxx)\n",
        "        conv5_1_3x3_bn = self.conv5_1_3x3_bn(conv5_1_3x3)\n",
        "        conv5_1_3x3_bnxx = self.conv5_1_3x3_relu(conv5_1_3x3_bn)\n",
        "        conv5_1_1x1_increase = self.conv5_1_1x1_increase(conv5_1_3x3_bnxx)\n",
        "        conv5_1_1x1_increase_bn = self.conv5_1_1x1_increase_bn(conv5_1_1x1_increase)\n",
        "        conv5_1_1x1_proj = self.conv5_1_1x1_proj(conv4_6x)\n",
        "        conv5_1_1x1_proj_bn = self.conv5_1_1x1_proj_bn(conv5_1_1x1_proj)\n",
        "        conv5_1 = torch.add(conv5_1_1x1_proj_bn, 1, conv5_1_1x1_increase_bn)\n",
        "        conv5_1x = self.conv5_1_relu(conv5_1)\n",
        "        conv5_2_1x1_reduce = self.conv5_2_1x1_reduce(conv5_1x)\n",
        "        conv5_2_1x1_reduce_bn = self.conv5_2_1x1_reduce_bn(conv5_2_1x1_reduce)\n",
        "        conv5_2_1x1_reduce_bnxx = self.conv5_2_1x1_reduce_relu(conv5_2_1x1_reduce_bn)\n",
        "        conv5_2_3x3 = self.conv5_2_3x3(conv5_2_1x1_reduce_bnxx)\n",
        "        conv5_2_3x3_bn = self.conv5_2_3x3_bn(conv5_2_3x3)\n",
        "        conv5_2_3x3_bnxx = self.conv5_2_3x3_relu(conv5_2_3x3_bn)\n",
        "        conv5_2_1x1_increase = self.conv5_2_1x1_increase(conv5_2_3x3_bnxx)\n",
        "        conv5_2_1x1_increase_bn = self.conv5_2_1x1_increase_bn(conv5_2_1x1_increase)\n",
        "        conv5_2 = torch.add(conv5_1x, 1, conv5_2_1x1_increase_bn)\n",
        "        conv5_2x = self.conv5_2_relu(conv5_2)\n",
        "        conv5_3_1x1_reduce = self.conv5_3_1x1_reduce(conv5_2x)\n",
        "        conv5_3_1x1_reduce_bn = self.conv5_3_1x1_reduce_bn(conv5_3_1x1_reduce)\n",
        "        conv5_3_1x1_reduce_bnxx = self.conv5_3_1x1_reduce_relu(conv5_3_1x1_reduce_bn)\n",
        "        conv5_3_3x3 = self.conv5_3_3x3(conv5_3_1x1_reduce_bnxx)\n",
        "        conv5_3_3x3_bn = self.conv5_3_3x3_bn(conv5_3_3x3)\n",
        "        conv5_3_3x3_bnxx = self.conv5_3_3x3_relu(conv5_3_3x3_bn)\n",
        "        conv5_3_1x1_increase = self.conv5_3_1x1_increase(conv5_3_3x3_bnxx)\n",
        "        conv5_3_1x1_increase_bn = self.conv5_3_1x1_increase_bn(conv5_3_1x1_increase)\n",
        "        conv5_3 = torch.add(conv5_2x, 1, conv5_3_1x1_increase_bn)\n",
        "        conv5_3x = self.conv5_3_relu(conv5_3)\n",
        "        pool5_7x7_s1 = self.pool5_7x7_s1(conv5_3x)\n",
        "        classifier_preflatten = self.classifier(pool5_7x7_s1)\n",
        "        classifier = classifier_preflatten.view(classifier_preflatten.size(0), -1)\n",
        "        #return classifier, pool5_7x7_s1 　出力を変更しておかないと次元が合わないと言われる\n",
        "        return classifier\n",
        "\n",
        "def resnet50_ft_dag(weights_path=None, **kwargs):\n",
        "    \"\"\"\n",
        "    load imported model instance\n",
        "\n",
        "    Args:\n",
        "        weights_path (str): If set, loads model weights from the given path\n",
        "    \"\"\"\n",
        "    model = Resnet50_ft_dag()\n",
        "    if weights_path:\n",
        "        state_dict = torch.load(weights_path)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "#モデルのロード\n",
        "model_ft = Resnet50_ft_dag()\n",
        "\n",
        "#最終結合層のリセットと付け替え(全結合層を2つに)\n",
        "model_ft.classifier = nn.Linear(2048, 2)\n",
        "model_ft.classifier = nn.Sequential(*([Flatten()] + list(model_ft.children())[-1:])) #Flattenを挿入\n",
        "\n",
        "#重みロード\n",
        "PATH = '/content/drive/My Drive/Deep_learning/GravCont_Resnet50_VGGFace2_seed_'+str(manualSeed)+'.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()\n",
        "\n",
        "#Prediction\n",
        "result = calculateAccuracy(image_path)\n",
        "model_pred_prob.append(result[0])\n",
        "label_list = result[1]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50 15 54 9\n",
            "Accuracy: 0.8125\n",
            "Precision (positive predictive value): 0.847457627118644\n",
            "Recall (sensitivity): 0.7692307692307693\n",
            "Specificity: 0.8571428571428571\n",
            "F_value: 0.8064516129032259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72UkHpANnFjw",
        "colab_type": "text"
      },
      "source": [
        "#**ResNet50_ImageNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNwSFAOfnEtq",
        "colab_type": "code",
        "outputId": "b1890e00-d734-4652-8e8b-cd68a180c0e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "ModelName = 'ResNet50_ImageNet'\n",
        "checkModelName(ModelName, ModelName_list)\n",
        "\n",
        "model_ft = models.resnet50(pretrained=False)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# 重みロード\n",
        "PATH = '/content/drive/My Drive/Deep_learning/GravCont_Resnet50_ImageNet_seed_'+str(manualSeed)+'.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()\n",
        "\n",
        "#Prediction\n",
        "result = calculateAccuracy(image_path)\n",
        "model_pred_prob.append(result[0])\n",
        "label_list = result[1]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-86ff6f613c29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mModelName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ResNet50_ImageNet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheckModelName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModelName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelName_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_ftrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-87fcbda7289a>\u001b[0m in \u001b[0;36mcheckModelName\u001b[0;34m(ModelName, ModelName_list)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheckModelName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModelName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelName_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mModelName\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mModelName_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This model has been already loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mModelName_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModelName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: This model has been already loaded"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H64GGa2JmT9D",
        "colab_type": "text"
      },
      "source": [
        "#**ResNet50_nonPretrained**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVKpRFdAmUDR",
        "colab_type": "code",
        "outputId": "8ad7ebce-3e87-4214-ca59-ebbff0bdfae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "ModelName = 'ResNet50_nonPretrained'\n",
        "checkModelName(ModelName, ModelName_list)\n",
        "\n",
        "model_ft = models.resnet50(pretrained=False)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# 重みロード\n",
        "PATH = '/content/drive/My Drive/Deep_learning/GravCont_Resnet50_ImageNet_seed_'+str(manualSeed)+'.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()\n",
        "\n",
        "#Prediction\n",
        "result = calculateAccuracy(image_path)\n",
        "model_pred_prob.append(result[0])\n",
        "label_list = result[1]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47 18 36 27\n",
            "Accuracy: 0.6484375\n",
            "Precision (positive predictive value): 0.6351351351351351\n",
            "Recall (sensitivity): 0.7230769230769231\n",
            "Specificity: 0.5714285714285714\n",
            "F_value: 0.6762589928057553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWhxHmDPns3R",
        "colab_type": "text"
      },
      "source": [
        "#**EfficientNet_b4_ImageNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syACduJCntAB",
        "colab_type": "code",
        "outputId": "fcc0d126-3502-441c-edb1-8b76386daf9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451,
          "referenced_widgets": [
            "257dd1df1bc047cdb106d16b83120c23",
            "9c34f073cd8b4829a1d8dada7b403ad3",
            "2dd26a665da34b8c9e1df818852f2903",
            "00224a91fc8d4e1fbf3aa24dc3b72e79",
            "a8ea6ebe16764b5b8c76b9ada35596a6",
            "5bcae66d5ff547d0b096f976c5f1cd6c",
            "eed2a602181543f388550239fddc62d4",
            "22470e6ed8214e47a66a31d693dece15"
          ]
        }
      },
      "source": [
        "ModelName = 'EfficientNet_b4_ImageNet'\n",
        "checkModelName(ModelName, ModelName_list)    \n",
        "\n",
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet \n",
        "\n",
        "model_ft = EfficientNet.from_pretrained('efficientnet-b4')\n",
        "num_ftrs = model_ft._fc.in_features\n",
        "model_ft._fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#ネットワークの読み込み\n",
        "PATH = '/content/drive/My Drive/Deep_learning/GravCont_EfficientNet-b4_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()\n",
        "\n",
        "#Prediction\n",
        "result = calculateAccuracy(image_path)\n",
        "model_pred_prob.append(result[0])\n",
        "label_list = result[1]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.5.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-cp36-none-any.whl size=12422 sha256=720f3b1f6bcbaf4d4e385cc89d7716e4b1ccf16631c9c14671f430d5d934077b\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/1e/a9/2a578ba9ad04e776e80bf0f70d8a7f4c29ec0718b92d8f6ccd\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /root/.cache/torch/checkpoints/efficientnet-b4-6ed6700e.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "257dd1df1bc047cdb106d16b83120c23",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=77999237.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded pretrained weights for efficientnet-b4\n",
            "55 10 52 11\n",
            "Accuracy: 0.8359375\n",
            "Precision (positive predictive value): 0.8333333333333334\n",
            "Recall (sensitivity): 0.8461538461538461\n",
            "Specificity: 0.8253968253968254\n",
            "F_value: 0.8396946564885497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymGrWxHfntKI",
        "colab_type": "text"
      },
      "source": [
        "#**Attention_branch_Network_ImageNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gESMORA2ntRo",
        "colab_type": "code",
        "outputId": "0466d5fe-4e4f-45d5-a1f2-be196095938e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "ModelName = 'Attention_branch_Network_ImageNet'\n",
        "checkModelName(ModelName, ModelName_list)   \n",
        "\n",
        "\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
        "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
        "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
        "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "\n",
        "class ResNet_ARN(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet_ARN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], down_size=True)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, down_size=True)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, down_size=True)\n",
        "\n",
        "        self.att_layer4 = self._make_layer(block, 512, layers[3], stride=1, down_size=False)\n",
        "        self.bn_att = nn.BatchNorm2d(512 * block.expansion)\n",
        "        self.att_conv   = nn.Conv2d(512 * block.expansion, num_classes, kernel_size=1, padding=0,\n",
        "                               bias=False)\n",
        "        self.bn_att2 = nn.BatchNorm2d(num_classes)\n",
        "        self.att_conv2  = nn.Conv2d(num_classes, num_classes, kernel_size=1, padding=0,\n",
        "                               bias=False)\n",
        "        self.att_conv3  = nn.Conv2d(num_classes, 1, kernel_size=3, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn_att3 = nn.BatchNorm2d(1)\n",
        "        self.att_gap = nn.AvgPool2d(14)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, down_size=True)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, down_size=True):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "\n",
        "        if down_size:\n",
        "            self.inplanes = planes * block.expansion\n",
        "            for i in range(1, blocks):\n",
        "                layers.append(block(self.inplanes, planes))\n",
        "\n",
        "            return nn.Sequential(*layers)\n",
        "        else:\n",
        "            inplanes = planes * block.expansion\n",
        "            for i in range(1, blocks):\n",
        "                layers.append(block(inplanes, planes))\n",
        "\n",
        "            return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        fe = x\n",
        "\n",
        "        ax = self.bn_att(self.att_layer4(x))\n",
        "        ax = self.relu(self.bn_att2(self.att_conv(ax)))\n",
        "        bs, cs, ys, xs = ax.shape\n",
        "        self.att = self.sigmoid(self.bn_att3(self.att_conv3(ax)))        \n",
        "        # self.att = self.att.view(bs, 1, ys, xs)\n",
        "        ax = self.att_conv2(ax)\n",
        "        ax = self.att_gap(ax)\n",
        "        ax = ax.view(ax.size(0), -1)\n",
        "\n",
        "        rx = x * self.att\n",
        "        rx = rx + x\n",
        "        per = rx\n",
        "        rx = self.layer4(rx)\n",
        "        rx = self.avgpool(rx)\n",
        "        rx = rx.view(rx.size(0), -1)\n",
        "        rx = self.fc(rx)\n",
        "\n",
        "        return ax, rx, [self.att, fe, per]\n",
        "\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "def resnetARN50(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet_ARN(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "#モデルのロード\n",
        "model_ft = resnetARN50().to(device)\n",
        "\n",
        "#attention branch networkの最終出力を2つにする\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#ネットワークの読み込み\n",
        "PATH = '/content/drive/My Drive/Deep_learning/gravcont_att_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#ネットワークの読み込み\n",
        "PATH = '/content/drive/My Drive/Deep_learning/gravcont_att_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()\n",
        "model_ft.to(device)\n",
        "\n",
        "#Prediction\n",
        "result = calculateAccuracy(image_path)\n",
        "model_pred_prob.append(result[0])\n",
        "label_list = result[1]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49 16 52 11\n",
            "Accuracy: 0.7890625\n",
            "Precision (positive predictive value): 0.8166666666666667\n",
            "Recall (sensitivity): 0.7538461538461538\n",
            "Specificity: 0.8253968253968254\n",
            "F_value: 0.784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVay7Id8oIPK",
        "colab_type": "text"
      },
      "source": [
        "#**Drawing ROC curve** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q1bF1hpg5Qd",
        "colab_type": "code",
        "outputId": "f150db0f-1edf-42da-9e6d-ea6f21e75829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "print(ModelName_list)\n",
        "\n",
        "print(model_pred_prob)\n",
        "len(model_pred_prob[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ResNet50_VGGFace2', 'ResNet50_ImageNet', 'ResNet50_nonPretrained', 'EfficientNet_b4_ImageNet', 'Attention_branch_Network_ImageNet']\n",
            "[[0.9790650606155396, 0.026246607303619385, 0.9771180152893066, 0.034967899322509766, 0.23866605758666992, 0.4647541046142578, 0.9999843835830688, 0.018199443817138672, 0.9705369472503662, 0.9829356670379639, 0.20673328638076782, 0.9550123810768127, 0.115531325340271, 0.21190625429153442, 0.9998389482498169, 0.009984791278839111, 0.2542804479598999, 0.8634684681892395, 0.15973007678985596, 0.9996811151504517, 0.4335808753967285, 0.4469411373138428, 0.9999979734420776, 0.24956220388412476, 0.9947236776351929, 0.9912379384040833, 0.5207807421684265, 0.5824019312858582, 0.08007705211639404, 0.07400882244110107, 0.9950986504554749, 0.9411635994911194, 0.12976133823394775, 0.0979154109954834, 0.7021567821502686, 0.9999922513961792, 0.7264547348022461, 0.035286784172058105, 0.044655799865722656, 0.08215898275375366, 1.0, 0.38154661655426025, 0.2631845474243164, 0.10793709754943848, 0.12338149547576904, 0.9950608611106873, 0.9999029636383057, 0.036663711071014404, 0.04064488410949707, 0.9987905621528625, 0.8118093013763428, 0.11153936386108398, 0.18998384475708008, 0.9998177886009216, 0.08021163940429688, 0.5520241260528564, 0.7029680013656616, 0.9597899317741394, 0.08155953884124756, 0.9965883493423462, 0.8348885774612427, 0.991655707359314, 0.10690063238143921, 0.50101238489151, 0.9993981122970581, 0.9790109992027283, 0.07347387075424194, 0.7218027114868164, 0.8180245757102966, 0.999922513961792, 0.9999620914459229, 0.034631550312042236, 0.14328551292419434, 0.24226748943328857, 0.027871131896972656, 0.9999953508377075, 0.9997712969779968, 0.980217695236206, 0.04016178846359253, 0.1825065016746521, 0.7494966387748718, 0.10501933097839355, 0.3626706004142761, 0.9999786615371704, 0.9999947547912598, 0.4843406677246094, 0.7178724408149719, 0.054137587547302246, 0.7727088928222656, 0.42002350091934204, 0.4994310140609741, 0.5611247420310974, 0.9909512996673584, 0.1644439697265625, 0.8928737044334412, 0.617763340473175, 0.25128233432769775, 0.9999992847442627, 0.9997441172599792, 0.999994158744812, 0.463189959526062, 0.017274916172027588, 0.7397899627685547, 0.5534926056861877, 0.15833890438079834, 0.3338892459869385, 0.9045776128768921, 0.34198999404907227, 0.9999529123306274, 0.9999799728393555, 0.9988924860954285, 0.8987223505973816, 0.9997963309288025, 0.999891996383667, 0.8475646376609802, 0.5122610926628113, 0.056265175342559814, 0.9981873631477356, 0.9999887943267822, 0.04878133535385132, 0.7320812940597534, 0.020694434642791748, 0.24655413627624512, 0.7642732262611389, 0.13279128074645996, 0.03722041845321655, 0.11166650056838989, 0.9999929666519165], [0.5045126080513, 0.44307589530944824, 0.5527889132499695, 0.46735960245132446, 0.4392452836036682, 0.588966965675354, 0.46496206521987915, 0.3950538635253906, 0.8563628792762756, 0.9778621196746826, 0.4404844045639038, 0.9676823616027832, 0.8785755038261414, 0.49471449851989746, 0.45561647415161133, 0.4485463500022888, 0.448797345161438, 0.9579796195030212, 0.4443066120147705, 0.6959050893783569, 0.472176730632782, 0.6545975804328918, 0.6279266476631165, 0.486394464969635, 0.9902614951133728, 0.5129293203353882, 0.523269772529602, 0.4445747137069702, 0.5043448209762573, 0.457197904586792, 0.4872545003890991, 0.7328001260757446, 0.4600644111633301, 0.44945383071899414, 0.4510357975959778, 0.9007282257080078, 0.2621484398841858, 0.7772385478019714, 0.4700145721435547, 0.4819785952568054, 0.665060818195343, 0.4883279800415039, 0.5167866945266724, 0.45748597383499146, 0.45760560035705566, 0.6348122358322144, 0.6342640519142151, 0.4575575590133667, 0.4513764977455139, 0.2614743113517761, 0.4444500803947449, 0.4547216296195984, 0.7105836868286133, 0.5550156235694885, 0.5330690741539001, 0.46317386627197266, 0.9977260231971741, 0.3400474786758423, 0.4540392756462097, 0.45731836557388306, 0.44579291343688965, 0.4601612091064453, 0.5098046064376831, 0.4445977210998535, 0.6010584831237793, 0.6834436058998108, 0.45215898752212524, 0.4452696442604065, 0.4514177441596985, 0.6890971064567566, 0.4686068296432495, 0.8911248445510864, 0.6661463379859924, 0.6509571671485901, 0.4673295021057129, 0.9863038659095764, 0.8418664932250977, 0.5030667781829834, 0.6278179883956909, 0.447370707988739, 0.457591712474823, 0.46048790216445923, 0.4467776417732239, 0.45511138439178467, 0.42616045475006104, 0.4386497735977173, 0.4367274045944214, 0.4963163137435913, 0.5009387731552124, 0.4913640022277832, 0.44409239292144775, 0.5486435294151306, 0.46251553297042847, 0.45038676261901855, 0.45255887508392334, 0.6175581812858582, 0.44690996408462524, 0.8883811235427856, 0.8560894131660461, 0.8997153043746948, 0.4580063819885254, 0.4005424380302429, 0.46268218755722046, 0.5756432414054871, 0.5119511485099792, 0.4366557002067566, 0.6870983242988586, 0.47137463092803955, 0.477481484413147, 0.6300921440124512, 0.4337611198425293, 0.3746839761734009, 0.6061873435974121, 0.5978227853775024, 0.49674248695373535, 0.9800602197647095, 0.4723024368286133, 0.4485820531845093, 0.6131135821342468, 0.4470701813697815, 0.4455602765083313, 0.4416743516921997, 0.43959057331085205, 0.43456220626831055, 0.47970861196517944, 0.5729544162750244, 0.9984369874000549, 0.7793661952018738], [0.5045126080513, 0.44307589530944824, 0.5527889132499695, 0.46735960245132446, 0.4392452836036682, 0.588966965675354, 0.46496206521987915, 0.3950538635253906, 0.8563628792762756, 0.9778621196746826, 0.4404844045639038, 0.9676823616027832, 0.8785755038261414, 0.49471449851989746, 0.45561647415161133, 0.4485463500022888, 0.448797345161438, 0.9579796195030212, 0.4443066120147705, 0.6959050893783569, 0.472176730632782, 0.6545975804328918, 0.6279266476631165, 0.486394464969635, 0.9902614951133728, 0.5129293203353882, 0.523269772529602, 0.4445747137069702, 0.5043448209762573, 0.457197904586792, 0.4872545003890991, 0.7328001260757446, 0.4600644111633301, 0.44945383071899414, 0.4510357975959778, 0.9007282257080078, 0.2621484398841858, 0.7772385478019714, 0.4700145721435547, 0.4819785952568054, 0.665060818195343, 0.4883279800415039, 0.5167866945266724, 0.45748597383499146, 0.45760560035705566, 0.6348122358322144, 0.6342640519142151, 0.4575575590133667, 0.4513764977455139, 0.2614743113517761, 0.4444500803947449, 0.4547216296195984, 0.7105836868286133, 0.5550156235694885, 0.5330690741539001, 0.46317386627197266, 0.9977260231971741, 0.3400474786758423, 0.4540392756462097, 0.45731836557388306, 0.44579291343688965, 0.4601612091064453, 0.5098046064376831, 0.4445977210998535, 0.6010584831237793, 0.6834436058998108, 0.45215898752212524, 0.4452696442604065, 0.4514177441596985, 0.6890971064567566, 0.4686068296432495, 0.8911248445510864, 0.6661463379859924, 0.6509571671485901, 0.4673295021057129, 0.9863038659095764, 0.8418664932250977, 0.5030667781829834, 0.6278179883956909, 0.447370707988739, 0.457591712474823, 0.46048790216445923, 0.4467776417732239, 0.45511138439178467, 0.42616045475006104, 0.4386497735977173, 0.4367274045944214, 0.4963163137435913, 0.5009387731552124, 0.4913640022277832, 0.44409239292144775, 0.5486435294151306, 0.46251553297042847, 0.45038676261901855, 0.45255887508392334, 0.6175581812858582, 0.44690996408462524, 0.8883811235427856, 0.8560894131660461, 0.8997153043746948, 0.4580063819885254, 0.4005424380302429, 0.46268218755722046, 0.5756432414054871, 0.5119511485099792, 0.4366557002067566, 0.6870983242988586, 0.47137463092803955, 0.477481484413147, 0.6300921440124512, 0.4337611198425293, 0.3746839761734009, 0.6061873435974121, 0.5978227853775024, 0.49674248695373535, 0.9800602197647095, 0.4723024368286133, 0.4485820531845093, 0.6131135821342468, 0.4470701813697815, 0.4455602765083313, 0.4416743516921997, 0.43959057331085205, 0.43456220626831055, 0.47970861196517944, 0.5729544162750244, 0.9984369874000549, 0.7793661952018738], [0.9997701048851013, 4.947185516357422e-05, 0.960808515548706, 0.0034273862838745117, 0.001295924186706543, 0.020458638668060303, 0.9996297359466553, 0.00048291683197021484, 0.9919238686561584, 0.694550096988678, 0.006132781505584717, 0.9714308977127075, 0.030348539352416992, 0.003927350044250488, 0.9928106665611267, 0.00014698505401611328, 0.5668216347694397, 0.7031481266021729, 0.2557086944580078, 0.9998812675476074, 0.6457254886627197, 0.00605165958404541, 0.9987878203392029, 0.19384366273880005, 0.9996860027313232, 0.14230096340179443, 0.6909026503562927, 0.01883256435394287, 0.03855395317077637, 0.039182305335998535, 0.9391413927078247, 0.89683997631073, 0.0575408935546875, 0.002390146255493164, 0.09144806861877441, 0.999346911907196, 0.026497840881347656, 0.001439511775970459, 0.00044339895248413086, 0.5837352871894836, 0.999996542930603, 0.01166313886642456, 0.8678992390632629, 0.00047969818115234375, 0.0001442432403564453, 0.9974523186683655, 0.9996174573898315, 0.056277573108673096, 4.3392181396484375e-05, 0.9857271313667297, 0.9479318261146545, 0.0011022090911865234, 0.0007329583168029785, 0.9876694083213806, 0.005273997783660889, 0.3774154782295227, 0.6500130295753479, 0.9933193922042847, 0.0036216378211975098, 0.9984018206596375, 0.10499626398086548, 0.9275047183036804, 0.0016132593154907227, 0.007214009761810303, 0.9999672174453735, 0.9948262572288513, 0.1640021800994873, 0.01568394899368286, 0.0006622672080993652, 0.9994410872459412, 0.9947071671485901, 0.0006186962127685547, 0.2648875117301941, 0.005148470401763916, 0.13252687454223633, 0.9994408488273621, 0.893115222454071, 0.9884399175643921, 6.365776062011719e-05, 0.5740213394165039, 0.479858934879303, 0.8137931823730469, 0.00036978721618652344, 0.9958206415176392, 0.9992615580558777, 0.25491148233413696, 0.03431934118270874, 0.021691620349884033, 0.39654988050460815, 0.2320232391357422, 0.9679015278816223, 0.05251777172088623, 0.9997363686561584, 0.006535828113555908, 0.8373453617095947, 0.9187158346176147, 0.009379982948303223, 0.9999723434448242, 0.9990183115005493, 0.9682961702346802, 0.0007756948471069336, 0.001774132251739502, 0.8732227087020874, 0.2577984929084778, 0.035999596118927, 0.9654382467269897, 0.9590820074081421, 0.0502665638923645, 0.9989601373672485, 0.9996063113212585, 0.9999167919158936, 0.9949856996536255, 0.9942471981048584, 0.9999662637710571, 0.02578216791152954, 0.0781937837600708, 0.23124510049819946, 0.987168550491333, 0.9997565150260925, 0.0002949833869934082, 0.796005129814148, 0.006403923034667969, 0.786651074886322, 0.9756995439529419, 0.05095958709716797, 0.037167131900787354, 0.14627480506896973, 0.9918732047080994], [0.9998331069946289, 0.047308146953582764, 0.844965398311615, 0.22335076332092285, 0.5264374613761902, 0.34342706203460693, 0.868098795413971, 0.016292154788970947, 0.8197618126869202, 0.4384010434150696, 0.5235747694969177, 0.8822904825210571, 0.07900810241699219, 0.17334705591201782, 0.9013834595680237, 0.004872679710388184, 0.5848946571350098, 0.5685372352600098, 0.1450669765472412, 0.9955253005027771, 0.7645732164382935, 0.10411667823791504, 1.0, 0.6723499894142151, 0.9674075841903687, 0.8928790092468262, 0.0284348726272583, 0.8133178949356079, 0.0519370436668396, 0.04287010431289673, 0.2416958212852478, 0.808040976524353, 0.27207982540130615, 0.03621870279312134, 0.49727195501327515, 0.9993699193000793, 0.19886451959609985, 0.04912972450256348, 0.061676204204559326, 0.18716281652450562, 0.9999985694885254, 0.059578657150268555, 0.8715780377388, 0.02027946710586548, 0.10933226346969604, 0.9132652282714844, 0.9999998807907104, 0.10639292001724243, 0.07066148519515991, 0.8831198811531067, 0.5581653118133545, 0.22890013456344604, 0.448685884475708, 0.9585177302360535, 0.006657660007476807, 0.08534902334213257, 0.8163159489631653, 0.9299746155738831, 0.15869605541229248, 0.9062340259552002, 0.5408828258514404, 0.7241644263267517, 0.10157102346420288, 0.32390809059143066, 0.9449374079704285, 0.6817405223846436, 0.033984601497650146, 0.033384859561920166, 0.5492004752159119, 0.999737560749054, 0.913486123085022, 0.009530961513519287, 0.09376770257949829, 0.7048996090888977, 0.20170456171035767, 0.991766631603241, 0.806511640548706, 0.8477585315704346, 0.09485447406768799, 0.5565565228462219, 0.5260176658630371, 0.650922417640686, 0.03692936897277832, 0.973350465297699, 0.9999746084213257, 0.43813788890838623, 0.20580226182937622, 0.03488600254058838, 0.48967885971069336, 0.628494143486023, 0.7368251085281372, 0.3279690146446228, 0.951073944568634, 0.6835908889770508, 0.8157559037208557, 0.825607180595398, 0.12119263410568237, 0.9997435212135315, 0.9323363900184631, 0.9981837868690491, 0.016269803047180176, 0.0020933151245117188, 0.8190549612045288, 0.13870441913604736, 0.11759328842163086, 0.5283309817314148, 0.6878512501716614, 0.04961514472961426, 0.9998475313186646, 0.9867516756057739, 0.9296479821205139, 0.8791587948799133, 0.9984000325202942, 0.9999804496765137, 0.5773994326591492, 0.3164275288581848, 0.0636715292930603, 0.5420143008232117, 0.9743345379829407, 0.03191089630126953, 0.5028619170188904, 0.006848454475402832, 0.26131904125213623, 0.1631256341934204, 0.1711687445640564, 0.02117025852203369, 0.020971357822418213, 0.9238229393959045]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gom3bMGgSXVn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "3c2445f4-635f-4a5c-a969-91b3bce1d574"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_score = []\n",
        "y_true = []\n",
        "\n",
        "k=0\n",
        "for i in label_list:\n",
        "    if label_list[k] == 'cont':\n",
        "          y_true.append(0)\n",
        "    elif label_list[k] == 'grav':\n",
        "          y_true.append(1)\n",
        "    k+=1\n",
        "\n",
        "\n",
        "#健康な状態を「0」、病気を「1」としてラベルよりリストを作成\n",
        "y_true = y_true\n",
        "\n",
        "#グラフの外形を作成\n",
        "plt.figure(figsize=(8.0, 6.0))\n",
        "lw = 2\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "\n",
        "ycolor = ['darkorange','blue','green','red','black']      # 各プロットの色\n",
        "ylabel = ModelName_list   # 各ラベル\n",
        "\n",
        "k=0\n",
        "for i in ModelName_list:\n",
        "    y_score = model_pred_prob[k]\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label=ylabel[k]+'(area = %0.2f)' % roc_auc)\n",
        "    k+=1\n",
        "\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}