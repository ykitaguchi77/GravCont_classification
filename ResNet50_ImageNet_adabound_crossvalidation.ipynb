{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled31.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/ResNet50_ImageNet_adabound_crossvalidation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-a4ZBlqPNdU",
        "colab_type": "text"
      },
      "source": [
        "#**GravCont: EfficientNet_b4_ImageNet**\n",
        "ValidationとTestに分けて解析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgM-Y7SVPNkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "cbae8f54-71f8-4dda-b2d3-d1978c47ddae"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "#Advanced Pytorchから\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set random seem for reproducibility\n",
        "manualSeed = 1234\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.cuda.manual_seed(manualSeed)\n",
        "\n",
        "torch.torch.backends.cudnn.benchmark = True\n",
        "torch.torch.backends.cudnn.enabled = True\n",
        "\n",
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet \n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "'''\n",
        "grav: 甲状腺眼症\n",
        "cont: コントロール\n",
        "黒の空白を挿入することにより225px*225pxの画像を生成、EfficientNetを用いて転移学習\n",
        "－－－－－－－－－－－－－－\n",
        "データの構造\n",
        "gravcont.zip ------grav\n",
        "               |---cont\n",
        "'''                                     \n",
        "\n",
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_optimizer in /usr/local/lib/python3.6/dist-packages (0.0.1a15)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from torch_optimizer) (0.1.1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torch_optimizer) (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (1.18.5)\n",
            "Random Seed:  1234\n",
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzp_09fWPNoU",
        "colab_type": "text"
      },
      "source": [
        "#**モジュール群**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7sJV06qPNsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_process(data_dir):\n",
        "    # 入力画像の前処理をするクラス\n",
        "    # 訓練時と推論時で処理が異なる\n",
        "\n",
        "    \"\"\"\n",
        "        画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "        画像のサイズをリサイズし、色を標準化する。\n",
        "        訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n",
        "\n",
        "\n",
        "        Attributes\n",
        "        ----------\n",
        "        resize : int\n",
        "            リサイズ先の画像の大きさ。\n",
        "        mean : (R, G, B)\n",
        "            各色チャネルの平均値。\n",
        "        std : (R, G, B)\n",
        "            各色チャネルの標準偏差。\n",
        "    \"\"\"\n",
        "\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224, scale=(0.75,1.0)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    data_dir = data_dir\n",
        "    n_samples = len(data_dir)\n",
        "\n",
        "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                              data_transforms[x])\n",
        "                      for x in ['train', 'val']}\n",
        "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=20,\n",
        "                                                shuffle=True, num_workers=4)\n",
        "                  for x in ['train', 'val']}\n",
        "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "    class_names = image_datasets['train'].classes\n",
        "\n",
        "\n",
        "    print(class_names)\n",
        "    k=0\n",
        "    for i in class_names:\n",
        "        print(class_names[k]+\"_train:\"+str(len(os.listdir(path=data_dir + '/train/'+class_names[k]))))\n",
        "        k+=1\n",
        "    k=0\n",
        "    for i in class_names:\n",
        "        print(class_names[k]+\"_val:\"+str(len(os.listdir(path=data_dir + '/val/'+class_names[k]))))\n",
        "        k+=1\n",
        "\n",
        "    print(\"training data set_total：\"+ str(len(image_datasets['train'])))\n",
        "    print(\"validating data set_total：\"+str(len(image_datasets['val'])))\n",
        "    \n",
        "    return image_datasets, dataloaders, dataset_sizes, class_names, device\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "def getBatch(dataloaders):    \n",
        "    # Get a batch of training data\n",
        "    inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "    # Make a grid from batch\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "    #imshow(out, title=[class_names[x] for x in classes])\n",
        "    return(inputs, classes)\n",
        "\n",
        "#Defining early stopping class\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_loss = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_loss = []\n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase] \n",
        "            \n",
        "            # record train_loss and valid_loss\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "            if phase == 'val':\n",
        "                valid_loss.append(epoch_loss)\n",
        "            #print(train_loss)\n",
        "            #print(valid_loss)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "      \n",
        "      # early_stopping needs the validation loss to check if it has decresed, \n",
        "      # and if it has, it will make a checkpoint of the current model\n",
        "        if phase == 'val':    \n",
        "            early_stopping(epoch_loss, model)\n",
        "                \n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "        print()\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_loss, valid_loss\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "def convnet():\n",
        "    model_ft = models.resnet50(pretrained=True)\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    #https://blog.knjcode.com/adabound-memo/\n",
        "    #https://pypi.org/project/torch-optimizer/\n",
        "    optimizer_ft = optim.AdaBound(\n",
        "        model_ft.parameters(),\n",
        "        lr= 1e-3,\n",
        "        betas= (0.9, 0.999),\n",
        "        final_lr = 0.1,\n",
        "        gamma=1e-3,\n",
        "        eps= 1e-8,\n",
        "        weight_decay=0,\n",
        "        amsbound=False,\n",
        "    )\n",
        "    return (model_ft, criterion, optimizer_ft)\n",
        "\n",
        "\n",
        "def training(model_ft, criterion, optimizer_ft,  patience=15, num_epochs=50):\n",
        "    model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=patience, num_epochs=num_epochs)\n",
        "\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      return(image_name, label)\n",
        "\n",
        "'''\n",
        "#変形後の画像を表示\n",
        "def image_transform(image_path):\n",
        "\n",
        "    image=Image.open(image_path)\n",
        "\n",
        "    \n",
        "    #変形した画像を表示する\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224)])\n",
        "    image_transformed = transform(image)\n",
        "    plt.imshow(np.array(image_transformed))\n",
        "'''\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を表示\n",
        "def image_eval(image_tensor, label):\n",
        "    output = model_ft(image_tensor)\n",
        "    #print(output.size())  # torch.Size([1, 1000])\n",
        "    #print(output)\n",
        "\n",
        "    #model_pred:クラス名前、prob:確率、pred:クラス番号\n",
        "    prob, pred = torch.topk(nn.Softmax(dim=1)(output), 1)\n",
        "    model_pred = class_names[pred]\n",
        "    \n",
        "    #甲状腺眼症のprobabilityを計算（classが0なら1から減算、classが1ならそのまま）\n",
        "    prob = abs(1-float(prob)-float(pred))\n",
        " \n",
        "    return model_pred, prob, pred\n",
        "\n",
        "    \"\"\"\n",
        "    #probalilityを計算する\n",
        "    pred_prob = torch.topk(nn.Softmax(dim=1)(output), 1)[0]\n",
        "    pred_class = torch.topk(nn.Softmax(dim=1)(output), 1)[1]\n",
        "    if pred_class == 1:\n",
        "        pred_prob = pred_prob\n",
        "    elif pred_class == 0:\n",
        "        pred_prob = 1- pred_prob\n",
        "    return(model_pred, pred_prob)  #class_nameの番号で出力される\n",
        "    \"\"\"\n",
        "\n",
        "def showImage(image_path):\n",
        "    #画像のインポート\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    #画像のリサイズ\n",
        "    height = img.shape[0]\n",
        "    width = img.shape[1]\n",
        "    resized_img = cv2.resize(img, (int(width*300/height), 300))\n",
        "    cv2_imshow(resized_img)\n",
        "\n",
        "def calculateAccuracy (TP, TN, FP, FN):\n",
        "    accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "    precision  = TP/(FP + TP)\n",
        "    recall = TP/(TP + FN)\n",
        "    specificity = TN/(FP + TN)\n",
        "    f_value = (2*recall*precision)/(recall+precision)\n",
        "    return(accuracy, precision, recall, specificity, f_value)\n",
        "\n",
        "\"\"\"\n",
        "・True positive (TN)\n",
        "・False positive (FP)\n",
        "・True negative (TN)\n",
        "・False negative (FN)\n",
        "Accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "Precision = TP/(FP + TP) ※positive predictive value\n",
        "Recall = TP/(TP + FN)　※sensitivity\n",
        "Specificity = TN/(FP + TN)\n",
        "F_value = (2RecallPrecision)/(Recall+Precision)\n",
        "\"\"\"\n",
        "\n",
        "def evaluation(model_ft, testset_dir):\n",
        "    #評価モードにする\n",
        "    model_ft.eval()\n",
        "\n",
        "    #testデータセット内のファイル名を取得\n",
        "    image_path = glob.glob(testset_dir + \"/*/*\")\n",
        "    #random.shuffle(image_path)  #表示順をランダムにする\n",
        "    print('number of images: ' +str(len(image_path)))\n",
        "\n",
        "\n",
        "    TP, FP, TN, FN, TP, FP, TN, FN = [0,0,0,0,0,0,0,0]\n",
        "    image_name_list = []\n",
        "    label_list = []\n",
        "    model_pred_list = []\n",
        "    hum_pred_list = []\n",
        "\n",
        "    model_pred_class = []\n",
        "    model_pred_prob = []\n",
        "\n",
        "    for i in image_path:\n",
        "          image_name, label = getlabel(i)  #画像の名前とラベルを取得\n",
        "          image_tensor = image_transform(i)  #予測のための画像下処理\n",
        "          model_pred, prob, pred = image_eval(image_tensor, label)  #予測結果を出力   \n",
        "          #print('Image: '+ image_name)\n",
        "          #print('Label: '+ label)\n",
        "          #print('Pred: '+ model_pred)\n",
        "          #showImage(i)  #画像を表示\n",
        "          #print() #空白行を入れる\n",
        "          time.sleep(0.1)\n",
        "\n",
        "          image_name_list.append(image_name)\n",
        "          label_list.append(label)\n",
        "          model_pred_list.append(model_pred)\n",
        "\n",
        "          model_pred_class.append(int(pred))\n",
        "          model_pred_prob.append(float(prob))\n",
        "\n",
        "          if label == class_names[0]:\n",
        "              if model_pred == class_names[0]:\n",
        "                  TN += 1\n",
        "              else:\n",
        "                  FP += 1\n",
        "          elif label == class_names[1]:\n",
        "              if model_pred == class_names[1]:\n",
        "                  TP += 1\n",
        "              else:\n",
        "                  FN += 1     \n",
        "\n",
        "    print(TP, FN, TN, FP)\n",
        "\n",
        "    #Accuracyを計算\n",
        "    accuracy, precision, recall, specificity, f_value = calculateAccuracy (TP, TN, FP, FN)\n",
        "    print('Accuracy: ' + str(accuracy))\n",
        "    print('Precision (positive predictive value): ' + str(precision))\n",
        "    print('Recall (sensitivity): ' + str(recall))\n",
        "    print('Specificity: ' + str(specificity))\n",
        "    print('F_value: ' + str(f_value))\n",
        "\n",
        "    #print(model_pred_class)\n",
        "    #print(model_pred_prob)\n",
        "\n",
        "    return TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, label_list, model_pred_prob\n",
        "\n",
        "\n",
        "def make_csv(roc_label_list):\n",
        "    #csvのdata tableを作成\n",
        "    pd.set_option('display.max_rows', 800)  # 省略なしで表示\n",
        "    #columns1 = [\"EfficientNet_32\", \"EfficientNet_64\", \"EfficientNet_128\", \"EfficientNet_256\", \"EfficientNet_512\", \"EfficientNet_558\"]\n",
        "    columns1 = roc_label_list.extend([\"avg\", \"std\"])\n",
        "    index1 = [\"TP\",\"TN\",\"FP\",\"FN\",\"Accuracy\",\"Positive predictive value\",\"sensitity\",\"specificity\",\"F-value\",\"roc_auc\"]\n",
        "    df = pd.DataFrame(index=index1, columns=columns1)\n",
        "    return df\n",
        "\n",
        "def write_csv(df, col, TP, TN, FP, FN, accuracy, precision, recall, specificity, f_value,roc_auc):\n",
        "    df.iloc[0:10, col] = TP, TN, FP, FN, accuracy, precision, recall, specificity, f_value,roc_auc \n",
        "    #print(df)\n",
        "\n",
        "    # CSVとして出力\n",
        "    #df2.to_csv(\"/content/drive/My Drive/Grav_bootcamp/Posttrain_model_eval_result.csv\",encoding=\"shift_jis\")\n",
        "    return df\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == 'cont':\n",
        "                  y_true.append(0)\n",
        "            elif i == 'grav':\n",
        "                  y_true.append(1)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_auc(label_list, model_pred_prob):\n",
        "    y_true, y_score = [], []\n",
        "    for i in label_list:\n",
        "        if i == 'cont':\n",
        "              y_true.append(0)\n",
        "        elif i == 'grav':\n",
        "              y_true.append(1)\n",
        "            \n",
        "    #それぞれの画像における陽性の確率についてリストを作成\n",
        "    y_score = model_pred_prob\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc: \" +str(roc_auc))\n",
        "    return(roc_auc, y_true, y_score)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USGfUwQXv6Jc",
        "colab_type": "text"
      },
      "source": [
        "#**まとめて解析**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObCZwRvYCPTI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "4ca6effc-f65e-4ee4-96c7-d5737f896df1"
      },
      "source": [
        "#create data_dir_list\n",
        "data_dir = '/content/drive/My Drive/gravcont_crossvalidation'\n",
        "fold = len(os.listdir(data_dir))\n",
        "print(fold)\n",
        "\n",
        "data_dir_list = [0]*fold\n",
        "\n",
        "for i in range(fold):\n",
        "    data_dir_list[i] = data_dir + '/' + str(i)\n",
        "    print(data_dir_list[i])\n",
        "\n",
        "#create roc_label_list\n",
        "roc_label_list = [0]*fold\n",
        "roc_label_list = list(range(fold))\n",
        "print(roc_label_list)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "/content/drive/My Drive/gravcont_crossvalidation/0\n",
            "/content/drive/My Drive/gravcont_crossvalidation/1\n",
            "/content/drive/My Drive/gravcont_crossvalidation/2\n",
            "/content/drive/My Drive/gravcont_crossvalidation/3\n",
            "/content/drive/My Drive/gravcont_crossvalidation/4\n",
            "[0, 1, 2, 3, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM2VMXltwBs5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1981826f-8d7c-44d7-9dba-7c00c8512a50"
      },
      "source": [
        "df = make_csv(roc_label_list)\n",
        "\n",
        "label_list_list, model_pred_prob_list, Y_TRUE, Y_SCORE = [],[],[],[]\n",
        "\n",
        "print(data_dir_list)\n",
        "print(roc_label_list)\n",
        "\n",
        "for i, t in enumerate(zip(data_dir_list, roc_label_list)):\n",
        "\n",
        "    image_datasets, dataloaders, dataset_sizes, class_names, device = pre_process(t[0]) #path\n",
        "    inputs, classes = getBatch(dataloaders)\n",
        "    model_ft, criterion, optimizer_ft = convnet()\n",
        "    training(model_ft, criterion, optimizer_ft,  patience=15, num_epochs=50)  \n",
        "    TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, label_list, model_pred_prob = evaluation(model_ft, '/content/drive/My Drive/Grav_bootcamp/Posttrain_250px')\n",
        "    roc_auc, y_true, y_score = calculate_auc(label_list, model_pred_prob)\n",
        "    Y_TRUE.append(y_true)\n",
        "    Y_SCORE.append(y_score)\n",
        "    df = write_csv(df, i,TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, roc_auc) #numberをcsvの行として指定\n",
        "\n",
        "    label_list_list.append(label_list)\n",
        "    model_pred_prob_list.append(model_pred_prob)\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "\n",
        "#Draw ROC curve\n",
        "fig = Draw_roc_curve(label_list_list, model_pred_prob_list, roc_label_list, len(label_list_list))\n",
        "\n",
        "pd.set_option('display.max_columns', 100)\n",
        "#それぞれの項目の平均を計算しcsvに追記する\n",
        "df.iloc[0:4,fold], df.iloc[9,fold]   = df.mean(axis=1)[0:4], df.mean(axis=1)[9] \n",
        "df.iloc[0:10,fold+1] = df.std(axis=1)[0:10]\n",
        "TP,TN,FP,FN = df.mean(axis=1)[0:4]\n",
        "df.iloc[4:9,fold] = calculateAccuracy (TP, TN, FP, FN)\n",
        "print(df)\n",
        "print(df)\n",
        "\n",
        "\n",
        "# CSVとして出力\n",
        "df.to_csv(\"/content/drive/My Drive/Grav_bootcamp/crossvaridation_ResNet50_ImageNet.csv\",encoding=\"shift_jis\")\n",
        "\n",
        "#ROC_curveを保存\n",
        "fig.savefig(\"/content/drive/My Drive/Grav_bootcamp/img.png\")\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/gravcont_crossvalidation/0', '/content/drive/My Drive/gravcont_crossvalidation/1', '/content/drive/My Drive/gravcont_crossvalidation/2', '/content/drive/My Drive/gravcont_crossvalidation/3', '/content/drive/My Drive/gravcont_crossvalidation/4']\n",
            "[0, 1, 2, 3, 4]\n",
            "['cont', 'grav']\n",
            "cont_train:223\n",
            "grav_train:223\n",
            "cont_val:56\n",
            "grav_val:56\n",
            "training data set_total：446\n",
            "validating data set_total：112\n",
            "Epoch 0/49\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch_optimizer/adabound.py:142: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.7053 Acc: 0.6390\n",
            "val Loss: 33.2317 Acc: 0.4643\n",
            "Validation loss decreased (inf --> 33.231714).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.5164 Acc: 0.7668\n",
            "val Loss: 6.8638 Acc: 0.5000\n",
            "Validation loss decreased (33.231714 --> 6.863774).  Saving model ...\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.4300 Acc: 0.8049\n",
            "val Loss: 1.3460 Acc: 0.6250\n",
            "Validation loss decreased (6.863774 --> 1.345950).  Saving model ...\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.4382 Acc: 0.8161\n",
            "val Loss: 1.0019 Acc: 0.6250\n",
            "Validation loss decreased (1.345950 --> 1.001931).  Saving model ...\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.3653 Acc: 0.8430\n",
            "val Loss: 0.8842 Acc: 0.6429\n",
            "Validation loss decreased (1.001931 --> 0.884228).  Saving model ...\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.3913 Acc: 0.8251\n",
            "val Loss: 0.9314 Acc: 0.6339\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.2961 Acc: 0.8744\n",
            "val Loss: 1.5007 Acc: 0.5000\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.3421 Acc: 0.8430\n",
            "val Loss: 1.2701 Acc: 0.6429\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.2605 Acc: 0.8924\n",
            "val Loss: 1.4706 Acc: 0.6161\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.3089 Acc: 0.8677\n",
            "val Loss: 0.8393 Acc: 0.6696\n",
            "Validation loss decreased (0.884228 --> 0.839319).  Saving model ...\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.3207 Acc: 0.8475\n",
            "val Loss: 1.1847 Acc: 0.6339\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.2814 Acc: 0.8857\n",
            "val Loss: 1.5456 Acc: 0.5625\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.2343 Acc: 0.9013\n",
            "val Loss: 1.1153 Acc: 0.6429\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.3097 Acc: 0.8744\n",
            "val Loss: 1.0752 Acc: 0.6339\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.2993 Acc: 0.8677\n",
            "val Loss: 1.8586 Acc: 0.5893\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.2522 Acc: 0.8924\n",
            "val Loss: 1.7438 Acc: 0.5804\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.1996 Acc: 0.9148\n",
            "val Loss: 1.5515 Acc: 0.5982\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.1383 Acc: 0.9507\n",
            "val Loss: 1.0043 Acc: 0.7411\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.5270 Acc: 0.7848\n",
            "val Loss: 45.1464 Acc: 0.4464\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.4465 Acc: 0.7982\n",
            "val Loss: 0.6223 Acc: 0.6518\n",
            "Validation loss decreased (0.839319 --> 0.622289).  Saving model ...\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.3960 Acc: 0.8274\n",
            "val Loss: 0.8573 Acc: 0.6786\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.3657 Acc: 0.8498\n",
            "val Loss: 1.7128 Acc: 0.5714\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.3230 Acc: 0.8722\n",
            "val Loss: 0.7410 Acc: 0.7054\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.2942 Acc: 0.8677\n",
            "val Loss: 0.9039 Acc: 0.6964\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.2276 Acc: 0.9170\n",
            "val Loss: 1.4311 Acc: 0.5179\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.3033 Acc: 0.8789\n",
            "val Loss: 1.8722 Acc: 0.5268\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.1867 Acc: 0.9260\n",
            "val Loss: 1.2844 Acc: 0.6518\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.2150 Acc: 0.9126\n",
            "val Loss: 1.3987 Acc: 0.6518\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.3524 Acc: 0.8587\n",
            "val Loss: 0.9361 Acc: 0.5982\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.2496 Acc: 0.8991\n",
            "val Loss: 1.5941 Acc: 0.5625\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.1876 Acc: 0.9350\n",
            "val Loss: 1.8773 Acc: 0.5804\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.1948 Acc: 0.9260\n",
            "val Loss: 1.2882 Acc: 0.5536\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.2224 Acc: 0.9148\n",
            "val Loss: 0.8961 Acc: 0.5089\n",
            "EarlyStopping counter: 13 out of 15\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.1912 Acc: 0.9305\n",
            "val Loss: 1.7763 Acc: 0.5089\n",
            "EarlyStopping counter: 14 out of 15\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.1333 Acc: 0.9507\n",
            "val Loss: 1.5384 Acc: 0.5357\n",
            "EarlyStopping counter: 15 out of 15\n",
            "Early stopping\n",
            "Training complete in 4m 30s\n",
            "Best val Acc: 0.741071\n",
            "number of images: 108\n",
            "40 14 42 12\n",
            "Accuracy: 0.7592592592592593\n",
            "Precision (positive predictive value): 0.7692307692307693\n",
            "Recall (sensitivity): 0.7407407407407407\n",
            "Specificity: 0.7777777777777778\n",
            "F_value: 0.7547169811320754\n",
            "roc_auc: 0.8511659807956103\n",
            "\n",
            "\n",
            "['cont', 'grav']\n",
            "cont_train:223\n",
            "grav_train:223\n",
            "cont_val:56\n",
            "grav_val:56\n",
            "training data set_total：446\n",
            "validating data set_total：112\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.7737 Acc: 0.6345\n",
            "val Loss: 14.4403 Acc: 0.5000\n",
            "Validation loss decreased (inf --> 14.440330).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.5255 Acc: 0.7399\n",
            "val Loss: 0.6878 Acc: 0.7143\n",
            "Validation loss decreased (14.440330 --> 0.687775).  Saving model ...\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.4250 Acc: 0.8161\n",
            "val Loss: 0.9703 Acc: 0.7054\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.4872 Acc: 0.7735\n",
            "val Loss: 0.4892 Acc: 0.7857\n",
            "Validation loss decreased (0.687775 --> 0.489230).  Saving model ...\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.4445 Acc: 0.7915\n",
            "val Loss: 0.6981 Acc: 0.7411\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.3410 Acc: 0.8453\n",
            "val Loss: 1.3358 Acc: 0.6071\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.4637 Acc: 0.7915\n",
            "val Loss: 5.2661 Acc: 0.5268\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.5339 Acc: 0.7242\n",
            "val Loss: 0.6460 Acc: 0.5804\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.3992 Acc: 0.7803\n",
            "val Loss: 0.6686 Acc: 0.7679\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.3748 Acc: 0.8206\n",
            "val Loss: 0.5751 Acc: 0.7232\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.3534 Acc: 0.8812\n",
            "val Loss: 0.5262 Acc: 0.7768\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.3163 Acc: 0.8498\n",
            "val Loss: 0.5274 Acc: 0.7232\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.2870 Acc: 0.8700\n",
            "val Loss: 0.5687 Acc: 0.7143\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.2912 Acc: 0.8834\n",
            "val Loss: 0.6503 Acc: 0.7143\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.2559 Acc: 0.8677\n",
            "val Loss: 0.7858 Acc: 0.7054\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.2532 Acc: 0.8789\n",
            "val Loss: 0.7677 Acc: 0.7411\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.2120 Acc: 0.9193\n",
            "val Loss: 0.6078 Acc: 0.6875\n",
            "EarlyStopping counter: 13 out of 15\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.2776 Acc: 0.8789\n",
            "val Loss: 0.8343 Acc: 0.7054\n",
            "EarlyStopping counter: 14 out of 15\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.2274 Acc: 0.9170\n",
            "val Loss: 0.4747 Acc: 0.7857\n",
            "Validation loss decreased (0.489230 --> 0.474660).  Saving model ...\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.2421 Acc: 0.8991\n",
            "val Loss: 0.6389 Acc: 0.7411\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.2160 Acc: 0.9170\n",
            "val Loss: 0.8049 Acc: 0.7054\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.2056 Acc: 0.9193\n",
            "val Loss: 0.4858 Acc: 0.7946\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.2333 Acc: 0.8946\n",
            "val Loss: 0.7325 Acc: 0.7143\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.1700 Acc: 0.9305\n",
            "val Loss: 0.5161 Acc: 0.7589\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.1301 Acc: 0.9574\n",
            "val Loss: 0.6593 Acc: 0.8125\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.2255 Acc: 0.9103\n",
            "val Loss: 0.6680 Acc: 0.7143\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.2297 Acc: 0.9081\n",
            "val Loss: 0.7494 Acc: 0.7143\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.2101 Acc: 0.9103\n",
            "val Loss: 0.5927 Acc: 0.7589\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.1505 Acc: 0.9507\n",
            "val Loss: 0.6484 Acc: 0.7946\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.1062 Acc: 0.9686\n",
            "val Loss: 0.7311 Acc: 0.7768\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.1010 Acc: 0.9641\n",
            "val Loss: 0.8841 Acc: 0.7321\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.1148 Acc: 0.9529\n",
            "val Loss: 0.8954 Acc: 0.7589\n",
            "EarlyStopping counter: 13 out of 15\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.1060 Acc: 0.9574\n",
            "val Loss: 1.1121 Acc: 0.7589\n",
            "EarlyStopping counter: 14 out of 15\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.1344 Acc: 0.9417\n",
            "val Loss: 1.0393 Acc: 0.7054\n",
            "EarlyStopping counter: 15 out of 15\n",
            "Early stopping\n",
            "Training complete in 4m 29s\n",
            "Best val Acc: 0.812500\n",
            "number of images: 108\n",
            "48 6 48 6\n",
            "Accuracy: 0.8888888888888888\n",
            "Precision (positive predictive value): 0.8888888888888888\n",
            "Recall (sensitivity): 0.8888888888888888\n",
            "Specificity: 0.8888888888888888\n",
            "F_value: 0.8888888888888888\n",
            "roc_auc: 0.926954732510288\n",
            "\n",
            "\n",
            "['cont', 'grav']\n",
            "cont_train:223\n",
            "grav_train:223\n",
            "cont_val:56\n",
            "grav_val:56\n",
            "training data set_total：446\n",
            "validating data set_total：112\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.7239 Acc: 0.6570\n",
            "val Loss: 11.5247 Acc: 0.5000\n",
            "Validation loss decreased (inf --> 11.524660).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.5623 Acc: 0.7556\n",
            "val Loss: 1.5005 Acc: 0.4821\n",
            "Validation loss decreased (11.524660 --> 1.500469).  Saving model ...\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.5352 Acc: 0.7511\n",
            "val Loss: 0.6898 Acc: 0.6429\n",
            "Validation loss decreased (1.500469 --> 0.689823).  Saving model ...\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.4599 Acc: 0.7848\n",
            "val Loss: 0.5748 Acc: 0.7411\n",
            "Validation loss decreased (0.689823 --> 0.574807).  Saving model ...\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.4067 Acc: 0.8072\n",
            "val Loss: 0.5990 Acc: 0.6964\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.3727 Acc: 0.8386\n",
            "val Loss: 0.9400 Acc: 0.6339\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.4103 Acc: 0.8229\n",
            "val Loss: 0.5267 Acc: 0.7589\n",
            "Validation loss decreased (0.574807 --> 0.526712).  Saving model ...\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.3991 Acc: 0.8318\n",
            "val Loss: 0.5177 Acc: 0.7679\n",
            "Validation loss decreased (0.526712 --> 0.517697).  Saving model ...\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.4447 Acc: 0.7982\n",
            "val Loss: 0.5530 Acc: 0.7679\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.3901 Acc: 0.8296\n",
            "val Loss: 0.4733 Acc: 0.8125\n",
            "Validation loss decreased (0.517697 --> 0.473281).  Saving model ...\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.3090 Acc: 0.8655\n",
            "val Loss: 0.5536 Acc: 0.7321\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.3025 Acc: 0.8610\n",
            "val Loss: 1.1255 Acc: 0.6518\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.3017 Acc: 0.8408\n",
            "val Loss: 0.4748 Acc: 0.8125\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.2613 Acc: 0.8901\n",
            "val Loss: 0.8777 Acc: 0.7054\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.2529 Acc: 0.9058\n",
            "val Loss: 1.4024 Acc: 0.6339\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.2606 Acc: 0.8969\n",
            "val Loss: 0.6157 Acc: 0.7411\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.2525 Acc: 0.8924\n",
            "val Loss: 0.8274 Acc: 0.6964\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.1817 Acc: 0.9283\n",
            "val Loss: 0.7926 Acc: 0.7321\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.2111 Acc: 0.9215\n",
            "val Loss: 0.8408 Acc: 0.7411\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.2065 Acc: 0.9148\n",
            "val Loss: 1.0907 Acc: 0.6607\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.2332 Acc: 0.9148\n",
            "val Loss: 0.5638 Acc: 0.7679\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.1580 Acc: 0.9372\n",
            "val Loss: 0.9786 Acc: 0.7679\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.1804 Acc: 0.9193\n",
            "val Loss: 0.5660 Acc: 0.7679\n",
            "EarlyStopping counter: 13 out of 15\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.1778 Acc: 0.9193\n",
            "val Loss: 0.6333 Acc: 0.7768\n",
            "EarlyStopping counter: 14 out of 15\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.1860 Acc: 0.9327\n",
            "val Loss: 1.8621 Acc: 0.5982\n",
            "EarlyStopping counter: 15 out of 15\n",
            "Early stopping\n",
            "Training complete in 3m 22s\n",
            "Best val Acc: 0.812500\n",
            "number of images: 108\n",
            "43 11 50 4\n",
            "Accuracy: 0.8611111111111112\n",
            "Precision (positive predictive value): 0.9148936170212766\n",
            "Recall (sensitivity): 0.7962962962962963\n",
            "Specificity: 0.9259259259259259\n",
            "F_value: 0.8514851485148516\n",
            "roc_auc: 0.8978052126200274\n",
            "\n",
            "\n",
            "['cont', 'grav']\n",
            "cont_train:223\n",
            "grav_train:223\n",
            "cont_val:56\n",
            "grav_val:56\n",
            "training data set_total：446\n",
            "validating data set_total：112\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.8878 Acc: 0.5247\n",
            "val Loss: 5.0379 Acc: 0.5000\n",
            "Validation loss decreased (inf --> 5.037936).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.6559 Acc: 0.6256\n",
            "val Loss: 2.5917 Acc: 0.5000\n",
            "Validation loss decreased (5.037936 --> 2.591693).  Saving model ...\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.5663 Acc: 0.7063\n",
            "val Loss: 1.3987 Acc: 0.6696\n",
            "Validation loss decreased (2.591693 --> 1.398732).  Saving model ...\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.5281 Acc: 0.7220\n",
            "val Loss: 0.5052 Acc: 0.7232\n",
            "Validation loss decreased (1.398732 --> 0.505199).  Saving model ...\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.4891 Acc: 0.7601\n",
            "val Loss: 0.5434 Acc: 0.7321\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.4634 Acc: 0.7892\n",
            "val Loss: 0.5177 Acc: 0.6964\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.4658 Acc: 0.7803\n",
            "val Loss: 0.5140 Acc: 0.6964\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.4323 Acc: 0.7960\n",
            "val Loss: 0.4379 Acc: 0.8036\n",
            "Validation loss decreased (0.505199 --> 0.437896).  Saving model ...\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.3882 Acc: 0.8274\n",
            "val Loss: 0.3672 Acc: 0.8482\n",
            "Validation loss decreased (0.437896 --> 0.367165).  Saving model ...\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.4068 Acc: 0.8251\n",
            "val Loss: 2.2919 Acc: 0.5179\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.4343 Acc: 0.7960\n",
            "val Loss: 0.5088 Acc: 0.7500\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.3527 Acc: 0.8408\n",
            "val Loss: 0.6135 Acc: 0.6964\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.2901 Acc: 0.8767\n",
            "val Loss: 0.3745 Acc: 0.8482\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.3236 Acc: 0.8677\n",
            "val Loss: 1.5464 Acc: 0.6161\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.3178 Acc: 0.8722\n",
            "val Loss: 0.5431 Acc: 0.7857\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.3499 Acc: 0.8587\n",
            "val Loss: 0.5734 Acc: 0.7411\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.3391 Acc: 0.8565\n",
            "val Loss: 0.3904 Acc: 0.8661\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.2605 Acc: 0.8946\n",
            "val Loss: 0.3635 Acc: 0.8750\n",
            "Validation loss decreased (0.367165 --> 0.363510).  Saving model ...\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.2352 Acc: 0.8969\n",
            "val Loss: 0.4169 Acc: 0.8393\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.3325 Acc: 0.8677\n",
            "val Loss: 0.6747 Acc: 0.7857\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.3242 Acc: 0.8655\n",
            "val Loss: 0.4245 Acc: 0.7768\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.2031 Acc: 0.9305\n",
            "val Loss: 0.5228 Acc: 0.8036\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.1629 Acc: 0.9305\n",
            "val Loss: 0.5847 Acc: 0.8036\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.1909 Acc: 0.9170\n",
            "val Loss: 0.5100 Acc: 0.8125\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.2165 Acc: 0.9193\n",
            "val Loss: 0.5183 Acc: 0.8750\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.2489 Acc: 0.8879\n",
            "val Loss: 0.7343 Acc: 0.7679\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.1785 Acc: 0.9170\n",
            "val Loss: 0.8178 Acc: 0.7589\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.2076 Acc: 0.9170\n",
            "val Loss: 0.3526 Acc: 0.8214\n",
            "Validation loss decreased (0.363510 --> 0.352566).  Saving model ...\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.1541 Acc: 0.9395\n",
            "val Loss: 0.3983 Acc: 0.8571\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.1011 Acc: 0.9552\n",
            "val Loss: 0.4080 Acc: 0.8661\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.1775 Acc: 0.9327\n",
            "val Loss: 0.6184 Acc: 0.8125\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.1656 Acc: 0.9417\n",
            "val Loss: 0.5838 Acc: 0.8661\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.1012 Acc: 0.9552\n",
            "val Loss: 0.6578 Acc: 0.8214\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.1126 Acc: 0.9596\n",
            "val Loss: 0.6286 Acc: 0.8393\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.1101 Acc: 0.9574\n",
            "val Loss: 0.7466 Acc: 0.8036\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.1044 Acc: 0.9619\n",
            "val Loss: 0.7057 Acc: 0.8304\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.1129 Acc: 0.9574\n",
            "val Loss: 0.4087 Acc: 0.8839\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.1642 Acc: 0.9327\n",
            "val Loss: 0.5939 Acc: 0.7857\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.0598 Acc: 0.9821\n",
            "val Loss: 0.7280 Acc: 0.7857\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.1619 Acc: 0.9305\n",
            "val Loss: 1.5755 Acc: 0.6786\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.1335 Acc: 0.9439\n",
            "val Loss: 0.6419 Acc: 0.7946\n",
            "EarlyStopping counter: 13 out of 15\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.0824 Acc: 0.9686\n",
            "val Loss: 0.5903 Acc: 0.8125\n",
            "EarlyStopping counter: 14 out of 15\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.0894 Acc: 0.9596\n",
            "val Loss: 0.8250 Acc: 0.8125\n",
            "EarlyStopping counter: 15 out of 15\n",
            "Early stopping\n",
            "Training complete in 5m 33s\n",
            "Best val Acc: 0.883929\n",
            "number of images: 108\n",
            "41 13 53 1\n",
            "Accuracy: 0.8703703703703703\n",
            "Precision (positive predictive value): 0.9761904761904762\n",
            "Recall (sensitivity): 0.7592592592592593\n",
            "Specificity: 0.9814814814814815\n",
            "F_value: 0.8541666666666667\n",
            "roc_auc: 0.9290123456790124\n",
            "\n",
            "\n",
            "['cont', 'grav']\n",
            "cont_train:224\n",
            "grav_train:224\n",
            "cont_val:55\n",
            "grav_val:55\n",
            "training data set_total：448\n",
            "validating data set_total：110\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.7519 Acc: 0.6295\n",
            "val Loss: 3.1820 Acc: 0.7545\n",
            "Validation loss decreased (inf --> 3.182045).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.5452 Acc: 0.7143\n",
            "val Loss: 1.0575 Acc: 0.5000\n",
            "Validation loss decreased (3.182045 --> 1.057499).  Saving model ...\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.5041 Acc: 0.7478\n",
            "val Loss: 0.4112 Acc: 0.8455\n",
            "Validation loss decreased (1.057499 --> 0.411159).  Saving model ...\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.5018 Acc: 0.7612\n",
            "val Loss: 0.6714 Acc: 0.7091\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.4456 Acc: 0.7902\n",
            "val Loss: 0.4754 Acc: 0.7636\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.4390 Acc: 0.7991\n",
            "val Loss: 0.9470 Acc: 0.6364\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.4173 Acc: 0.8304\n",
            "val Loss: 0.5092 Acc: 0.8364\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.3493 Acc: 0.8393\n",
            "val Loss: 0.7726 Acc: 0.6545\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.3647 Acc: 0.8438\n",
            "val Loss: 0.3774 Acc: 0.8545\n",
            "Validation loss decreased (0.411159 --> 0.377428).  Saving model ...\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.3684 Acc: 0.8438\n",
            "val Loss: 0.6413 Acc: 0.6545\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.3622 Acc: 0.8438\n",
            "val Loss: 0.5202 Acc: 0.7182\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.3716 Acc: 0.8527\n",
            "val Loss: 0.4043 Acc: 0.8818\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.2808 Acc: 0.8817\n",
            "val Loss: 0.2949 Acc: 0.8273\n",
            "Validation loss decreased (0.377428 --> 0.294878).  Saving model ...\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.2452 Acc: 0.8951\n",
            "val Loss: 0.3878 Acc: 0.8091\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.2259 Acc: 0.9018\n",
            "val Loss: 0.3533 Acc: 0.8545\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.2408 Acc: 0.8929\n",
            "val Loss: 0.5033 Acc: 0.7545\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.2461 Acc: 0.8951\n",
            "val Loss: 0.2930 Acc: 0.8727\n",
            "Validation loss decreased (0.294878 --> 0.293030).  Saving model ...\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.2037 Acc: 0.9196\n",
            "val Loss: 0.3303 Acc: 0.8364\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.2087 Acc: 0.9263\n",
            "val Loss: 0.8292 Acc: 0.8091\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.2775 Acc: 0.8862\n",
            "val Loss: 0.3622 Acc: 0.8909\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.1559 Acc: 0.9308\n",
            "val Loss: 0.5826 Acc: 0.8091\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.1722 Acc: 0.9375\n",
            "val Loss: 0.6398 Acc: 0.7727\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.2662 Acc: 0.8996\n",
            "val Loss: 0.2967 Acc: 0.9000\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.1744 Acc: 0.9308\n",
            "val Loss: 1.0513 Acc: 0.6364\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.1713 Acc: 0.9308\n",
            "val Loss: 0.7710 Acc: 0.7636\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.1926 Acc: 0.9330\n",
            "val Loss: 0.4384 Acc: 0.8545\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.2508 Acc: 0.8996\n",
            "val Loss: 0.7354 Acc: 0.8273\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.1846 Acc: 0.9286\n",
            "val Loss: 0.5797 Acc: 0.8182\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.2455 Acc: 0.9107\n",
            "val Loss: 0.3891 Acc: 0.8727\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.1776 Acc: 0.9375\n",
            "val Loss: 0.2540 Acc: 0.8727\n",
            "Validation loss decreased (0.293030 --> 0.254045).  Saving model ...\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.0904 Acc: 0.9554\n",
            "val Loss: 0.3390 Acc: 0.8818\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.1027 Acc: 0.9621\n",
            "val Loss: 0.4769 Acc: 0.8455\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.1830 Acc: 0.9241\n",
            "val Loss: 0.6410 Acc: 0.8545\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.2005 Acc: 0.9286\n",
            "val Loss: 0.2510 Acc: 0.9273\n",
            "Validation loss decreased (0.254045 --> 0.251026).  Saving model ...\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.1240 Acc: 0.9531\n",
            "val Loss: 0.2145 Acc: 0.9182\n",
            "Validation loss decreased (0.251026 --> 0.214466).  Saving model ...\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.0762 Acc: 0.9732\n",
            "val Loss: 0.2263 Acc: 0.9273\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.1102 Acc: 0.9598\n",
            "val Loss: 0.1851 Acc: 0.9000\n",
            "Validation loss decreased (0.214466 --> 0.185096).  Saving model ...\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.1149 Acc: 0.9621\n",
            "val Loss: 0.3368 Acc: 0.8909\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.1312 Acc: 0.9442\n",
            "val Loss: 0.3899 Acc: 0.8727\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.0871 Acc: 0.9621\n",
            "val Loss: 0.4725 Acc: 0.8273\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.0857 Acc: 0.9732\n",
            "val Loss: 0.4223 Acc: 0.8818\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.0573 Acc: 0.9777\n",
            "val Loss: 0.4443 Acc: 0.8818\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.0765 Acc: 0.9688\n",
            "val Loss: 0.2010 Acc: 0.9364\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.0781 Acc: 0.9732\n",
            "val Loss: 0.4608 Acc: 0.8545\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.0585 Acc: 0.9777\n",
            "val Loss: 0.2568 Acc: 0.9000\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.0499 Acc: 0.9821\n",
            "val Loss: 0.4454 Acc: 0.9000\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.0621 Acc: 0.9777\n",
            "val Loss: 0.3751 Acc: 0.8818\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.0244 Acc: 0.9955\n",
            "val Loss: 0.3363 Acc: 0.8909\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.0448 Acc: 0.9866\n",
            "val Loss: 0.4209 Acc: 0.8818\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.0621 Acc: 0.9844\n",
            "val Loss: 0.5697 Acc: 0.8091\n",
            "EarlyStopping counter: 13 out of 15\n",
            "\n",
            "Training complete in 6m 25s\n",
            "Best val Acc: 0.936364\n",
            "number of images: 108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "43 11 49 5\n",
            "Accuracy: 0.8518518518518519\n",
            "Precision (positive predictive value): 0.8958333333333334\n",
            "Recall (sensitivity): 0.7962962962962963\n",
            "Specificity: 0.9074074074074074\n",
            "F_value: 0.8431372549019608\n",
            "roc_auc: 0.9029492455418382\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b3fa3be2a0d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#それぞれの項目の平均を計算しcsvに追記する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mTP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_setitem_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many indexers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m                 \u001b[0mkeyidx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, raise_missing)\u001b[0m\n\u001b[1;32m   2153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2156\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1992\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1994\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1995\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m             \u001b[0;31m# a tuple should already have been caught by this point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2061\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w6AhUhKpxjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "f4181354-a089-446e-b8e9-9840b51de860"
      },
      "source": [
        "print(df)\n",
        "\n",
        "# CSVとして出力\n",
        "df.to_csv(\"/content/drive/My Drive/Grav_bootcamp/crossvaridation_ResNet50_ImageNet.csv\",encoding=\"shift_jis\")\n",
        "\n",
        "#ROC_curveを保存\n",
        "fig.savefig(\"/content/drive/My Drive/Grav_bootcamp/img.png\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                  0         1         2         3         4\n",
            "TP                               40        48        43        41        43\n",
            "TN                               42        48        50        53        49\n",
            "FP                               12         6         4         1         5\n",
            "FN                               14         6        11        13        11\n",
            "Accuracy                   0.759259  0.888889  0.861111   0.87037  0.851852\n",
            "Positive predictive value  0.769231  0.888889  0.914894   0.97619  0.895833\n",
            "sensitity                  0.740741  0.888889  0.796296  0.759259  0.796296\n",
            "specificity                0.777778  0.888889  0.925926  0.981481  0.907407\n",
            "F-value                    0.754717  0.888889  0.851485  0.854167  0.843137\n",
            "roc_auc                    0.851166  0.926955  0.897805  0.929012  0.902949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMjDfLrYojRv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "2ba06faa-eb53-4fc4-ad29-1f0eafc72f3b"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Grav_bootcamp/crossvaridation_ResNet50_ImageNet.csv', index_col=0)\n",
        "fold = 5\n",
        "#それぞれの項目の平均を計算しcsvに追記する\n",
        "df.iloc[0:4,fold], df.iloc[9,fold]   = df.mean(axis=1)[0:4], df.mean(axis=1)[9] \n",
        "df.iloc[0:10,fold+1] = df.std(axis=1)[0:10]\n",
        "TP,TN,FP,FN = df.mean(axis=1)[0:4]\n",
        "df.iloc[4:9,fold] = calculateAccuracy (TP, TN, FP, FN)\n",
        "print(df)\n",
        "df.to_csv(\"/content/drive/My Drive/Grav_bootcamp/crossvaridation_ResNet50_ImageNet.csv\",encoding=\"shift_jis\")\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                   0          1          2          3  \\\n",
            "TP                         40.000000  48.000000  43.000000  41.000000   \n",
            "TN                         42.000000  48.000000  50.000000  53.000000   \n",
            "FP                         12.000000   6.000000   4.000000   1.000000   \n",
            "FN                         14.000000   6.000000  11.000000  13.000000   \n",
            "Accuracy                    0.759259   0.888889   0.861111   0.870370   \n",
            "Positive predictive value   0.769231   0.888889   0.914894   0.976190   \n",
            "sensitity                   0.740741   0.888889   0.796296   0.759259   \n",
            "specificity                 0.777778   0.888889   0.925926   0.981481   \n",
            "F-value                     0.754717   0.888889   0.851485   0.854167   \n",
            "roc_auc                     0.851166   0.926955   0.897805   0.929012   \n",
            "\n",
            "                                   4        avg        std  \n",
            "TP                         43.000000  37.250973  15.211740  \n",
            "TN                         49.000000  42.001585  17.019008  \n",
            "FP                          5.000000   5.315871   3.378816  \n",
            "FN                         11.000000   9.822401   3.971947  \n",
            "Accuracy                    0.851852   0.843482   0.303177  \n",
            "Positive predictive value   0.895833   0.879356   0.312828  \n",
            "sensitity                   0.796296   0.795411   0.282956  \n",
            "specificity                 0.907407   0.891344   0.315936  \n",
            "F-value                     0.843137   0.835280   0.300357  \n",
            "roc_auc                     0.902949   0.776798   0.326623  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah2BSEqtteN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8a8q2pcQPWJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "43a1d4a7-ae9a-4455-9239-1eadd7b94e51"
      },
      "source": [
        "import csv\n",
        "#Save ROC data\n",
        "with open(\"/content/drive/My Drive/Grav_bootcamp/ROCdata_ResNet50_ImageNet.csv\", 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    for i, t in enumerate(zip(Y_TRUE, Y_SCORE)):\n",
        "        writer.writerow([t[0],t[1]])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-9efd0a958da6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Grav_bootcamp/ROCdata_ResNet50_ImageNet.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_TRUE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_SCORE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Y_TRUE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPO-b2cAT0yF",
        "colab_type": "text"
      },
      "source": [
        "#**ネットワークの保存と読み込み**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMYyFQ6ATzyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ネットワークの保存\n",
        "PATH = '/content/drive/My Drive/Grav_bootcamp/GravCont_EfficientNet-b4_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "torch.save(model_ft.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c744XUtfT6xW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73a923de-e875-4e71-b4b5-1ae266557981"
      },
      "source": [
        "#ネットワークの読み込み\n",
        "PATH = '/content/drive/My Drive/Grav_bootcamp/GravCont_EfficientNet-b4_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "torch.save(model_ft.state_dict(), PATH)\n",
        "model_ft.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}