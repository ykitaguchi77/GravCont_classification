{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled35.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNJ+ipZWTdaRPjnKovltKbG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fe270595fd80465fb1b6a574b28ef610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ed11a23659dc4260b2a96a4f2b37cc0b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1286b73e2ad54576b476d02bb08034d7",
              "IPY_MODEL_e0d543ae0e9b46d8a55ef11c81d186f2"
            ]
          }
        },
        "ed11a23659dc4260b2a96a4f2b37cc0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1286b73e2ad54576b476d02bb08034d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_66c5add1e4d94f6abe2cac82dfdfb6bb",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 77999237,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 77999237,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ae55706d7664d588f9741ae51117094"
          }
        },
        "e0d543ae0e9b46d8a55ef11c81d186f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a7a8c34b44c3400ebfaffd9ec99cb1fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 74.4M/74.4M [00:07&lt;00:00, 10.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bfcca9a920b945329c692411a4980810"
          }
        },
        "66c5add1e4d94f6abe2cac82dfdfb6bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ae55706d7664d588f9741ae51117094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7a8c34b44c3400ebfaffd9ec99cb1fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bfcca9a920b945329c692411a4980810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/Assessment2.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpC0Fk9lUn2"
      },
      "source": [
        "#**Assessment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9B59fSXlT5f",
        "outputId": "d5568b32-44e6-4c36-b381-f89583d1d2b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "#Advanced Pytorchから\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set random seem for reproducibility\n",
        "manualSeed = 1234\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.cuda.manual_seed(manualSeed)\n",
        "\n",
        "torch.torch.backends.cudnn.benchmark = True\n",
        "torch.torch.backends.cudnn.enabled = True\n",
        "\n",
        "\n",
        "'''\n",
        "grav: 甲状腺眼症\n",
        "cont: コントロール\n",
        "黒の空白を挿入することにより225px*225pxの画像を生成、EfficientNetを用いて転移学習\n",
        "－－－－－－－－－－－－－－\n",
        "データの構造\n",
        "gravcont.zip ------grav\n",
        "               |---cont\n",
        "'''                                     \n",
        "\n",
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed:  1234\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHO1RjNom0Pr"
      },
      "source": [
        "#**モジュール群**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-yVbbvSm3Ay",
        "outputId": "3cc2a6c3-5194-482c-8fbe-69a3caee8542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        }
      },
      "source": [
        "#ModelNameをリストにする\n",
        "ModelName_list = []\n",
        "ModelName = ''\n",
        "model_pred_prob = []\n",
        "eval_index = []\n",
        "\n",
        "def checkModelName(ModelName, ModelName_list):\n",
        "    if ModelName in ModelName_list:\n",
        "        raise Exception(\"This model has been already loaded\")\n",
        "    else:\n",
        "        ModelName_list.append(ModelName)\n",
        "\n",
        "\n",
        "# 入力画像の前処理をするクラス\n",
        "# 訓練時と推論時で処理が異なる\n",
        "\n",
        "\"\"\"\n",
        "    画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "    画像のサイズをリサイズし、色を標準化する。\n",
        "    訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n",
        "\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    resize : int\n",
        "        リサイズ先の画像の大きさ。\n",
        "    mean : (R, G, B)\n",
        "        各色チャネルの平均値。\n",
        "    std : (R, G, B)\n",
        "        各色チャネルの標準偏差。\n",
        "\"\"\"\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224, scale=(0.75,1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/drive/My Drive/Grav_bootcamp/Posttrain_250px'\n",
        "n_samples = len(data_dir)\n",
        "\n",
        "image_datasets = datasets.ImageFolder(data_dir,data_transforms)\n",
        "                  \n",
        "dataloaders = torch.utils.data.DataLoader(image_datasets, batch_size=20,\n",
        "                                             shuffle=True, num_workers=0)\n",
        "dataset_sizes = len(image_datasets)\n",
        "class_names = image_datasets.classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "print(class_names)\n",
        "k=0\n",
        "for i in class_names:\n",
        "    print(class_names[k]+\"_train:\"+str(len(os.listdir(path=data_dir + '/'+class_names[k]))))\n",
        "    k+=1\n",
        "k=0\n",
        "for i in class_names:\n",
        "    print(class_names[k]+\"_val:\"+str(len(os.listdir(path=data_dir + '/'+class_names[k]))))\n",
        "    k+=1\n",
        "\n",
        "print(\"test data set_total：\"+ str(len(image_datasets)))\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cont', 'grav']\n",
            "cont_train:54\n",
            "grav_train:54\n",
            "cont_val:54\n",
            "grav_val:54\n",
            "test data set_total：108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zLnknjNnqNU"
      },
      "source": [
        "#**Calculate Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doQbOyGHpJYU",
        "outputId": "0297893f-b7dc-4df3-a2c9-274d01b5b992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "##########Calculate Accuracy#############\n",
        "#valフォルダ内のファイル名を取得\n",
        "image_path = glob.glob(\"/content/drive/My Drive/Grav_bootcamp/Posttrain_250px/*/*\")\n",
        "random.shuffle(image_path)  #表示順をランダムにする\n",
        "print('number of images: ' +str(len(image_path)))\n",
        "#print(image_path) \n",
        "\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      return(image_name, label)\n",
        "\n",
        "'''\n",
        "#変形後の画像を表示\n",
        "def image_transform(image_path):\n",
        "\n",
        "    image=Image.open(image_path)\n",
        "\n",
        "    \n",
        "    #変形した画像を表示する\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224)])\n",
        "    image_transformed = transform(image)\n",
        "    plt.imshow(np.array(image_transformed))\n",
        "'''\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を表示\n",
        "def image_eval(image_tensor, label):\n",
        "    \n",
        "    if ModelName == 'Attention_branch_Network_ImageNet':\n",
        "        _, output, _ = model_ft(image_tensor)\n",
        "    else:\n",
        "        output = model_ft(image_tensor)\n",
        "    #print(output.size())  # torch.Size([1, 1000])\n",
        "    #print(output)\n",
        "\n",
        "    #評価モードにする\n",
        "    model_ft.eval()\n",
        "\n",
        "    #model_pred:クラス名前、prob:確率、pred:クラス番号\n",
        "    prob, pred = torch.topk(nn.Softmax(dim=1)(output), 1)\n",
        "    model_pred = class_names[pred]\n",
        "    \n",
        "    #甲状腺眼症のprobabilityを計算（classが0なら1から減算、classが1ならそのまま）\n",
        "    prob = abs(1-float(prob)-float(pred))\n",
        " \n",
        "    return model_pred, prob, pred\n",
        "\n",
        "\n",
        "def showImage(image_path):\n",
        "    #画像のインポート\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    #画像のリサイズ\n",
        "    height = img.shape[0]\n",
        "    width = img.shape[1]\n",
        "    resized_img = cv2.resize(img, (int(width*300/height), 300))\n",
        "    cv2_imshow(resized_img)\n",
        "\n",
        "def calculateAccuracy (image_path):\n",
        "\n",
        "    #ここからがメイン\n",
        "    TP, FP, TN, FN, TP, FP, TN, FN = [0,0,0,0,0,0,0,0]\n",
        "    image_name_list = []\n",
        "    label_list = []\n",
        "    model_pred_list = []\n",
        "    hum_pred_list = []\n",
        "\n",
        "    model_pred_class = []\n",
        "    model_pred_prob = []\n",
        "\n",
        "    for i in image_path:\n",
        "          image_name, label = getlabel(i)  #画像の名前とラベルを取得\n",
        "          image_tensor = image_transform(i)  #予測のための画像下処理\n",
        "          model_pred, prob, pred = image_eval(image_tensor, label)  #予測結果を出力 \n",
        "\n",
        "          #print('Image: '+ image_name)\n",
        "          #print('Label: '+ label)\n",
        "          #print('Pred: '+ model_pred)\n",
        "          #showImage(i)  #画像を表示\n",
        "          #print() #空白行を入れる\n",
        "          time.sleep(0.1)\n",
        "\n",
        "          image_name_list.append(image_name)\n",
        "          label_list.append(label)\n",
        "          model_pred_list.append(model_pred)\n",
        "\n",
        "          model_pred_class.append(int(pred))\n",
        "          model_pred_prob.append(float(prob))\n",
        "\n",
        "          if label == class_names[0]:\n",
        "              if model_pred == class_names[0]:\n",
        "                  TP += 1\n",
        "              else:\n",
        "                  FN += 1\n",
        "          elif label == class_names[1]:\n",
        "              if model_pred == class_names[1]:\n",
        "                  TN += 1\n",
        "              else:\n",
        "                  FP += 1\n",
        "          \n",
        "\n",
        "    print(TP, FN, TN, FP)\n",
        "\n",
        "    #Accuracyを計算\n",
        "    accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "    precision  = TP/(FP + TP)\n",
        "    recall = TP/(TP + FN)\n",
        "    specificity = TN/(FP + TN)\n",
        "    f_value = (2*recall*precision)/(recall+precision)\n",
        "    \n",
        "    #各指標をeval_indexに格納\n",
        "    eval_index = accuracy, precision, recall, specificity, f_value\n",
        "\n",
        "    print('Accuracy: ' + str(accuracy))\n",
        "    print('Precision (positive predictive value): ' + str(precision))\n",
        "    print('Recall (sensitivity): ' + str(recall))\n",
        "    print('Specificity: ' + str(specificity))\n",
        "    print('F_value: ' + str(f_value))\n",
        "\n",
        "    #print(model_pred_class)\n",
        "    #print(model_pred_prob)\n",
        "\n",
        "    #return(accuracy, precision, recall, specificity, f_value)\n",
        "    return model_pred_prob, label_list, eval_index\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of images: 108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk-s71bSlLMJ"
      },
      "source": [
        "#**ResNet50_VGGFace2のネットワーク**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twcn29TKk7kM",
        "outputId": "3701c951-30c4-42d1-e495-5dca19886815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "ModelName = 'ResNet50_VGGFace2'\n",
        "checkModelName(ModelName, ModelName_list)\n",
        "\n",
        "class Resnet50_ft_dag(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Resnet50_ft_dag, self).__init__()\n",
        "        self.meta = {'mean': [131.0912, 103.8827, 91.4953],\n",
        "                     'std': [1, 1, 1],\n",
        "                     'imageSize': [224, 224, 3]}\n",
        "        self.conv1_7x7_s2 = nn.Conv2d(3, 64, kernel_size=[7, 7], stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        self.conv1_7x7_s2_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv1_relu_7x7_s2 = nn.ReLU()\n",
        "        self.pool1_3x3_s2 = nn.MaxPool2d(kernel_size=[3, 3], stride=[2, 2], padding=(0, 0), dilation=1, ceil_mode=True)\n",
        "        self.conv2_1_1x1_reduce = nn.Conv2d(64, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_1_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_1_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_3x3_relu = nn.ReLU()\n",
        "        self.conv2_1_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_1x1_proj = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_proj_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_relu = nn.ReLU()\n",
        "        self.conv2_2_1x1_reduce = nn.Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_2_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_2_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_2_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_3x3_relu = nn.ReLU()\n",
        "        self.conv2_2_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_2_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_relu = nn.ReLU()\n",
        "        self.conv2_3_1x1_reduce = nn.Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_3_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_3_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_3_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_3x3_relu = nn.ReLU()\n",
        "        self.conv2_3_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_3_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_relu = nn.ReLU()\n",
        "        self.conv3_1_1x1_reduce = nn.Conv2d(256, 128, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv3_1_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_1_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_1_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_3x3_relu = nn.ReLU()\n",
        "        self.conv3_1_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_1_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_1x1_proj = nn.Conv2d(256, 512, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv3_1_1x1_proj_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_relu = nn.ReLU()\n",
        "        self.conv3_2_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_2_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_2_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_2_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_3x3_relu = nn.ReLU()\n",
        "        self.conv3_2_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_2_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_relu = nn.ReLU()\n",
        "        self.conv3_3_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_3_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_3_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_3_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_3x3_relu = nn.ReLU()\n",
        "        self.conv3_3_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_3_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_relu = nn.ReLU()\n",
        "        self.conv3_4_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_4_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_4_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_4_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_3x3_relu = nn.ReLU()\n",
        "        self.conv3_4_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_4_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_relu = nn.ReLU()\n",
        "        self.conv4_1_1x1_reduce = nn.Conv2d(512, 256, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv4_1_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_1_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_1_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_3x3_relu = nn.ReLU()\n",
        "        self.conv4_1_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_1_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_1x1_proj = nn.Conv2d(512, 1024, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv4_1_1x1_proj_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_relu = nn.ReLU()\n",
        "        self.conv4_2_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_2_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_2_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_2_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_3x3_relu = nn.ReLU()\n",
        "        self.conv4_2_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_2_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_relu = nn.ReLU()\n",
        "        self.conv4_3_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_3_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_3_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_3_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_3x3_relu = nn.ReLU()\n",
        "        self.conv4_3_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_3_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_relu = nn.ReLU()\n",
        "        self.conv4_4_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_4_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_4_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_4_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_3x3_relu = nn.ReLU()\n",
        "        self.conv4_4_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_4_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_relu = nn.ReLU()\n",
        "        self.conv4_5_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_5_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_5_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_5_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_3x3_relu = nn.ReLU()\n",
        "        self.conv4_5_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_5_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_relu = nn.ReLU()\n",
        "        self.conv4_6_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_6_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_6_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_6_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_3x3_relu = nn.ReLU()\n",
        "        self.conv4_6_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_6_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_relu = nn.ReLU()\n",
        "        self.conv5_1_1x1_reduce = nn.Conv2d(1024, 512, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv5_1_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_1_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_1_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_3x3_relu = nn.ReLU()\n",
        "        self.conv5_1_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_1_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_1x1_proj = nn.Conv2d(1024, 2048, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv5_1_1x1_proj_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_relu = nn.ReLU()\n",
        "        self.conv5_2_1x1_reduce = nn.Conv2d(2048, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_2_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_2_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_2_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_3x3_relu = nn.ReLU()\n",
        "        self.conv5_2_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_2_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_relu = nn.ReLU()\n",
        "        self.conv5_3_1x1_reduce = nn.Conv2d(2048, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_3_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_3_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_3_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_3x3_relu = nn.ReLU()\n",
        "        self.conv5_3_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_3_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_relu = nn.ReLU()\n",
        "        self.pool5_7x7_s1 = nn.AvgPool2d(kernel_size=[7, 7], stride=[1, 1], padding=0)\n",
        "        self.classifier = nn.Conv2d(2048, 8631, kernel_size=[1, 1], stride=(1, 1))\n",
        "\n",
        "    def forward(self, data):\n",
        "        conv1_7x7_s2 = self.conv1_7x7_s2(data)\n",
        "        conv1_7x7_s2_bn = self.conv1_7x7_s2_bn(conv1_7x7_s2)\n",
        "        conv1_7x7_s2_bnxx = self.conv1_relu_7x7_s2(conv1_7x7_s2_bn)\n",
        "        pool1_3x3_s2 = self.pool1_3x3_s2(conv1_7x7_s2_bnxx)\n",
        "        conv2_1_1x1_reduce = self.conv2_1_1x1_reduce(pool1_3x3_s2)\n",
        "        conv2_1_1x1_reduce_bn = self.conv2_1_1x1_reduce_bn(conv2_1_1x1_reduce)\n",
        "        conv2_1_1x1_reduce_bnxx = self.conv2_1_1x1_reduce_relu(conv2_1_1x1_reduce_bn)\n",
        "        conv2_1_3x3 = self.conv2_1_3x3(conv2_1_1x1_reduce_bnxx)\n",
        "        conv2_1_3x3_bn = self.conv2_1_3x3_bn(conv2_1_3x3)\n",
        "        conv2_1_3x3_bnxx = self.conv2_1_3x3_relu(conv2_1_3x3_bn)\n",
        "        conv2_1_1x1_increase = self.conv2_1_1x1_increase(conv2_1_3x3_bnxx)\n",
        "        conv2_1_1x1_increase_bn = self.conv2_1_1x1_increase_bn(conv2_1_1x1_increase)\n",
        "        conv2_1_1x1_proj = self.conv2_1_1x1_proj(pool1_3x3_s2)\n",
        "        conv2_1_1x1_proj_bn = self.conv2_1_1x1_proj_bn(conv2_1_1x1_proj)\n",
        "        conv2_1 = torch.add(conv2_1_1x1_proj_bn, 1, conv2_1_1x1_increase_bn)\n",
        "        conv2_1x = self.conv2_1_relu(conv2_1)\n",
        "        conv2_2_1x1_reduce = self.conv2_2_1x1_reduce(conv2_1x)\n",
        "        conv2_2_1x1_reduce_bn = self.conv2_2_1x1_reduce_bn(conv2_2_1x1_reduce)\n",
        "        conv2_2_1x1_reduce_bnxx = self.conv2_2_1x1_reduce_relu(conv2_2_1x1_reduce_bn)\n",
        "        conv2_2_3x3 = self.conv2_2_3x3(conv2_2_1x1_reduce_bnxx)\n",
        "        conv2_2_3x3_bn = self.conv2_2_3x3_bn(conv2_2_3x3)\n",
        "        conv2_2_3x3_bnxx = self.conv2_2_3x3_relu(conv2_2_3x3_bn)\n",
        "        conv2_2_1x1_increase = self.conv2_2_1x1_increase(conv2_2_3x3_bnxx)\n",
        "        conv2_2_1x1_increase_bn = self.conv2_2_1x1_increase_bn(conv2_2_1x1_increase)\n",
        "        conv2_2 = torch.add(conv2_1x, 1, conv2_2_1x1_increase_bn)\n",
        "        conv2_2x = self.conv2_2_relu(conv2_2)\n",
        "        conv2_3_1x1_reduce = self.conv2_3_1x1_reduce(conv2_2x)\n",
        "        conv2_3_1x1_reduce_bn = self.conv2_3_1x1_reduce_bn(conv2_3_1x1_reduce)\n",
        "        conv2_3_1x1_reduce_bnxx = self.conv2_3_1x1_reduce_relu(conv2_3_1x1_reduce_bn)\n",
        "        conv2_3_3x3 = self.conv2_3_3x3(conv2_3_1x1_reduce_bnxx)\n",
        "        conv2_3_3x3_bn = self.conv2_3_3x3_bn(conv2_3_3x3)\n",
        "        conv2_3_3x3_bnxx = self.conv2_3_3x3_relu(conv2_3_3x3_bn)\n",
        "        conv2_3_1x1_increase = self.conv2_3_1x1_increase(conv2_3_3x3_bnxx)\n",
        "        conv2_3_1x1_increase_bn = self.conv2_3_1x1_increase_bn(conv2_3_1x1_increase)\n",
        "        conv2_3 = torch.add(conv2_2x, 1, conv2_3_1x1_increase_bn)\n",
        "        conv2_3x = self.conv2_3_relu(conv2_3)\n",
        "        conv3_1_1x1_reduce = self.conv3_1_1x1_reduce(conv2_3x)\n",
        "        conv3_1_1x1_reduce_bn = self.conv3_1_1x1_reduce_bn(conv3_1_1x1_reduce)\n",
        "        conv3_1_1x1_reduce_bnxx = self.conv3_1_1x1_reduce_relu(conv3_1_1x1_reduce_bn)\n",
        "        conv3_1_3x3 = self.conv3_1_3x3(conv3_1_1x1_reduce_bnxx)\n",
        "        conv3_1_3x3_bn = self.conv3_1_3x3_bn(conv3_1_3x3)\n",
        "        conv3_1_3x3_bnxx = self.conv3_1_3x3_relu(conv3_1_3x3_bn)\n",
        "        conv3_1_1x1_increase = self.conv3_1_1x1_increase(conv3_1_3x3_bnxx)\n",
        "        conv3_1_1x1_increase_bn = self.conv3_1_1x1_increase_bn(conv3_1_1x1_increase)\n",
        "        conv3_1_1x1_proj = self.conv3_1_1x1_proj(conv2_3x)\n",
        "        conv3_1_1x1_proj_bn = self.conv3_1_1x1_proj_bn(conv3_1_1x1_proj)\n",
        "        conv3_1 = torch.add(conv3_1_1x1_proj_bn, 1, conv3_1_1x1_increase_bn)\n",
        "        conv3_1x = self.conv3_1_relu(conv3_1)\n",
        "        conv3_2_1x1_reduce = self.conv3_2_1x1_reduce(conv3_1x)\n",
        "        conv3_2_1x1_reduce_bn = self.conv3_2_1x1_reduce_bn(conv3_2_1x1_reduce)\n",
        "        conv3_2_1x1_reduce_bnxx = self.conv3_2_1x1_reduce_relu(conv3_2_1x1_reduce_bn)\n",
        "        conv3_2_3x3 = self.conv3_2_3x3(conv3_2_1x1_reduce_bnxx)\n",
        "        conv3_2_3x3_bn = self.conv3_2_3x3_bn(conv3_2_3x3)\n",
        "        conv3_2_3x3_bnxx = self.conv3_2_3x3_relu(conv3_2_3x3_bn)\n",
        "        conv3_2_1x1_increase = self.conv3_2_1x1_increase(conv3_2_3x3_bnxx)\n",
        "        conv3_2_1x1_increase_bn = self.conv3_2_1x1_increase_bn(conv3_2_1x1_increase)\n",
        "        conv3_2 = torch.add(conv3_1x, 1, conv3_2_1x1_increase_bn)\n",
        "        conv3_2x = self.conv3_2_relu(conv3_2)\n",
        "        conv3_3_1x1_reduce = self.conv3_3_1x1_reduce(conv3_2x)\n",
        "        conv3_3_1x1_reduce_bn = self.conv3_3_1x1_reduce_bn(conv3_3_1x1_reduce)\n",
        "        conv3_3_1x1_reduce_bnxx = self.conv3_3_1x1_reduce_relu(conv3_3_1x1_reduce_bn)\n",
        "        conv3_3_3x3 = self.conv3_3_3x3(conv3_3_1x1_reduce_bnxx)\n",
        "        conv3_3_3x3_bn = self.conv3_3_3x3_bn(conv3_3_3x3)\n",
        "        conv3_3_3x3_bnxx = self.conv3_3_3x3_relu(conv3_3_3x3_bn)\n",
        "        conv3_3_1x1_increase = self.conv3_3_1x1_increase(conv3_3_3x3_bnxx)\n",
        "        conv3_3_1x1_increase_bn = self.conv3_3_1x1_increase_bn(conv3_3_1x1_increase)\n",
        "        conv3_3 = torch.add(conv3_2x, 1, conv3_3_1x1_increase_bn)\n",
        "        conv3_3x = self.conv3_3_relu(conv3_3)\n",
        "        conv3_4_1x1_reduce = self.conv3_4_1x1_reduce(conv3_3x)\n",
        "        conv3_4_1x1_reduce_bn = self.conv3_4_1x1_reduce_bn(conv3_4_1x1_reduce)\n",
        "        conv3_4_1x1_reduce_bnxx = self.conv3_4_1x1_reduce_relu(conv3_4_1x1_reduce_bn)\n",
        "        conv3_4_3x3 = self.conv3_4_3x3(conv3_4_1x1_reduce_bnxx)\n",
        "        conv3_4_3x3_bn = self.conv3_4_3x3_bn(conv3_4_3x3)\n",
        "        conv3_4_3x3_bnxx = self.conv3_4_3x3_relu(conv3_4_3x3_bn)\n",
        "        conv3_4_1x1_increase = self.conv3_4_1x1_increase(conv3_4_3x3_bnxx)\n",
        "        conv3_4_1x1_increase_bn = self.conv3_4_1x1_increase_bn(conv3_4_1x1_increase)\n",
        "        conv3_4 = torch.add(conv3_3x, 1, conv3_4_1x1_increase_bn)\n",
        "        conv3_4x = self.conv3_4_relu(conv3_4)\n",
        "        conv4_1_1x1_reduce = self.conv4_1_1x1_reduce(conv3_4x)\n",
        "        conv4_1_1x1_reduce_bn = self.conv4_1_1x1_reduce_bn(conv4_1_1x1_reduce)\n",
        "        conv4_1_1x1_reduce_bnxx = self.conv4_1_1x1_reduce_relu(conv4_1_1x1_reduce_bn)\n",
        "        conv4_1_3x3 = self.conv4_1_3x3(conv4_1_1x1_reduce_bnxx)\n",
        "        conv4_1_3x3_bn = self.conv4_1_3x3_bn(conv4_1_3x3)\n",
        "        conv4_1_3x3_bnxx = self.conv4_1_3x3_relu(conv4_1_3x3_bn)\n",
        "        conv4_1_1x1_increase = self.conv4_1_1x1_increase(conv4_1_3x3_bnxx)\n",
        "        conv4_1_1x1_increase_bn = self.conv4_1_1x1_increase_bn(conv4_1_1x1_increase)\n",
        "        conv4_1_1x1_proj = self.conv4_1_1x1_proj(conv3_4x)\n",
        "        conv4_1_1x1_proj_bn = self.conv4_1_1x1_proj_bn(conv4_1_1x1_proj)\n",
        "        conv4_1 = torch.add(conv4_1_1x1_proj_bn, 1, conv4_1_1x1_increase_bn)\n",
        "        conv4_1x = self.conv4_1_relu(conv4_1)\n",
        "        conv4_2_1x1_reduce = self.conv4_2_1x1_reduce(conv4_1x)\n",
        "        conv4_2_1x1_reduce_bn = self.conv4_2_1x1_reduce_bn(conv4_2_1x1_reduce)\n",
        "        conv4_2_1x1_reduce_bnxx = self.conv4_2_1x1_reduce_relu(conv4_2_1x1_reduce_bn)\n",
        "        conv4_2_3x3 = self.conv4_2_3x3(conv4_2_1x1_reduce_bnxx)\n",
        "        conv4_2_3x3_bn = self.conv4_2_3x3_bn(conv4_2_3x3)\n",
        "        conv4_2_3x3_bnxx = self.conv4_2_3x3_relu(conv4_2_3x3_bn)\n",
        "        conv4_2_1x1_increase = self.conv4_2_1x1_increase(conv4_2_3x3_bnxx)\n",
        "        conv4_2_1x1_increase_bn = self.conv4_2_1x1_increase_bn(conv4_2_1x1_increase)\n",
        "        conv4_2 = torch.add(conv4_1x, 1, conv4_2_1x1_increase_bn)\n",
        "        conv4_2x = self.conv4_2_relu(conv4_2)\n",
        "        conv4_3_1x1_reduce = self.conv4_3_1x1_reduce(conv4_2x)\n",
        "        conv4_3_1x1_reduce_bn = self.conv4_3_1x1_reduce_bn(conv4_3_1x1_reduce)\n",
        "        conv4_3_1x1_reduce_bnxx = self.conv4_3_1x1_reduce_relu(conv4_3_1x1_reduce_bn)\n",
        "        conv4_3_3x3 = self.conv4_3_3x3(conv4_3_1x1_reduce_bnxx)\n",
        "        conv4_3_3x3_bn = self.conv4_3_3x3_bn(conv4_3_3x3)\n",
        "        conv4_3_3x3_bnxx = self.conv4_3_3x3_relu(conv4_3_3x3_bn)\n",
        "        conv4_3_1x1_increase = self.conv4_3_1x1_increase(conv4_3_3x3_bnxx)\n",
        "        conv4_3_1x1_increase_bn = self.conv4_3_1x1_increase_bn(conv4_3_1x1_increase)\n",
        "        conv4_3 = torch.add(conv4_2x, 1, conv4_3_1x1_increase_bn)\n",
        "        conv4_3x = self.conv4_3_relu(conv4_3)\n",
        "        conv4_4_1x1_reduce = self.conv4_4_1x1_reduce(conv4_3x)\n",
        "        conv4_4_1x1_reduce_bn = self.conv4_4_1x1_reduce_bn(conv4_4_1x1_reduce)\n",
        "        conv4_4_1x1_reduce_bnxx = self.conv4_4_1x1_reduce_relu(conv4_4_1x1_reduce_bn)\n",
        "        conv4_4_3x3 = self.conv4_4_3x3(conv4_4_1x1_reduce_bnxx)\n",
        "        conv4_4_3x3_bn = self.conv4_4_3x3_bn(conv4_4_3x3)\n",
        "        conv4_4_3x3_bnxx = self.conv4_4_3x3_relu(conv4_4_3x3_bn)\n",
        "        conv4_4_1x1_increase = self.conv4_4_1x1_increase(conv4_4_3x3_bnxx)\n",
        "        conv4_4_1x1_increase_bn = self.conv4_4_1x1_increase_bn(conv4_4_1x1_increase)\n",
        "        conv4_4 = torch.add(conv4_3x, 1, conv4_4_1x1_increase_bn)\n",
        "        conv4_4x = self.conv4_4_relu(conv4_4)\n",
        "        conv4_5_1x1_reduce = self.conv4_5_1x1_reduce(conv4_4x)\n",
        "        conv4_5_1x1_reduce_bn = self.conv4_5_1x1_reduce_bn(conv4_5_1x1_reduce)\n",
        "        conv4_5_1x1_reduce_bnxx = self.conv4_5_1x1_reduce_relu(conv4_5_1x1_reduce_bn)\n",
        "        conv4_5_3x3 = self.conv4_5_3x3(conv4_5_1x1_reduce_bnxx)\n",
        "        conv4_5_3x3_bn = self.conv4_5_3x3_bn(conv4_5_3x3)\n",
        "        conv4_5_3x3_bnxx = self.conv4_5_3x3_relu(conv4_5_3x3_bn)\n",
        "        conv4_5_1x1_increase = self.conv4_5_1x1_increase(conv4_5_3x3_bnxx)\n",
        "        conv4_5_1x1_increase_bn = self.conv4_5_1x1_increase_bn(conv4_5_1x1_increase)\n",
        "        conv4_5 = torch.add(conv4_4x, 1, conv4_5_1x1_increase_bn)\n",
        "        conv4_5x = self.conv4_5_relu(conv4_5)\n",
        "        conv4_6_1x1_reduce = self.conv4_6_1x1_reduce(conv4_5x)\n",
        "        conv4_6_1x1_reduce_bn = self.conv4_6_1x1_reduce_bn(conv4_6_1x1_reduce)\n",
        "        conv4_6_1x1_reduce_bnxx = self.conv4_6_1x1_reduce_relu(conv4_6_1x1_reduce_bn)\n",
        "        conv4_6_3x3 = self.conv4_6_3x3(conv4_6_1x1_reduce_bnxx)\n",
        "        conv4_6_3x3_bn = self.conv4_6_3x3_bn(conv4_6_3x3)\n",
        "        conv4_6_3x3_bnxx = self.conv4_6_3x3_relu(conv4_6_3x3_bn)\n",
        "        conv4_6_1x1_increase = self.conv4_6_1x1_increase(conv4_6_3x3_bnxx)\n",
        "        conv4_6_1x1_increase_bn = self.conv4_6_1x1_increase_bn(conv4_6_1x1_increase)\n",
        "        conv4_6 = torch.add(conv4_5x, 1, conv4_6_1x1_increase_bn)\n",
        "        conv4_6x = self.conv4_6_relu(conv4_6)\n",
        "        conv5_1_1x1_reduce = self.conv5_1_1x1_reduce(conv4_6x)\n",
        "        conv5_1_1x1_reduce_bn = self.conv5_1_1x1_reduce_bn(conv5_1_1x1_reduce)\n",
        "        conv5_1_1x1_reduce_bnxx = self.conv5_1_1x1_reduce_relu(conv5_1_1x1_reduce_bn)\n",
        "        conv5_1_3x3 = self.conv5_1_3x3(conv5_1_1x1_reduce_bnxx)\n",
        "        conv5_1_3x3_bn = self.conv5_1_3x3_bn(conv5_1_3x3)\n",
        "        conv5_1_3x3_bnxx = self.conv5_1_3x3_relu(conv5_1_3x3_bn)\n",
        "        conv5_1_1x1_increase = self.conv5_1_1x1_increase(conv5_1_3x3_bnxx)\n",
        "        conv5_1_1x1_increase_bn = self.conv5_1_1x1_increase_bn(conv5_1_1x1_increase)\n",
        "        conv5_1_1x1_proj = self.conv5_1_1x1_proj(conv4_6x)\n",
        "        conv5_1_1x1_proj_bn = self.conv5_1_1x1_proj_bn(conv5_1_1x1_proj)\n",
        "        conv5_1 = torch.add(conv5_1_1x1_proj_bn, 1, conv5_1_1x1_increase_bn)\n",
        "        conv5_1x = self.conv5_1_relu(conv5_1)\n",
        "        conv5_2_1x1_reduce = self.conv5_2_1x1_reduce(conv5_1x)\n",
        "        conv5_2_1x1_reduce_bn = self.conv5_2_1x1_reduce_bn(conv5_2_1x1_reduce)\n",
        "        conv5_2_1x1_reduce_bnxx = self.conv5_2_1x1_reduce_relu(conv5_2_1x1_reduce_bn)\n",
        "        conv5_2_3x3 = self.conv5_2_3x3(conv5_2_1x1_reduce_bnxx)\n",
        "        conv5_2_3x3_bn = self.conv5_2_3x3_bn(conv5_2_3x3)\n",
        "        conv5_2_3x3_bnxx = self.conv5_2_3x3_relu(conv5_2_3x3_bn)\n",
        "        conv5_2_1x1_increase = self.conv5_2_1x1_increase(conv5_2_3x3_bnxx)\n",
        "        conv5_2_1x1_increase_bn = self.conv5_2_1x1_increase_bn(conv5_2_1x1_increase)\n",
        "        conv5_2 = torch.add(conv5_1x, 1, conv5_2_1x1_increase_bn)\n",
        "        conv5_2x = self.conv5_2_relu(conv5_2)\n",
        "        conv5_3_1x1_reduce = self.conv5_3_1x1_reduce(conv5_2x)\n",
        "        conv5_3_1x1_reduce_bn = self.conv5_3_1x1_reduce_bn(conv5_3_1x1_reduce)\n",
        "        conv5_3_1x1_reduce_bnxx = self.conv5_3_1x1_reduce_relu(conv5_3_1x1_reduce_bn)\n",
        "        conv5_3_3x3 = self.conv5_3_3x3(conv5_3_1x1_reduce_bnxx)\n",
        "        conv5_3_3x3_bn = self.conv5_3_3x3_bn(conv5_3_3x3)\n",
        "        conv5_3_3x3_bnxx = self.conv5_3_3x3_relu(conv5_3_3x3_bn)\n",
        "        conv5_3_1x1_increase = self.conv5_3_1x1_increase(conv5_3_3x3_bnxx)\n",
        "        conv5_3_1x1_increase_bn = self.conv5_3_1x1_increase_bn(conv5_3_1x1_increase)\n",
        "        conv5_3 = torch.add(conv5_2x, 1, conv5_3_1x1_increase_bn)\n",
        "        conv5_3x = self.conv5_3_relu(conv5_3)\n",
        "        pool5_7x7_s1 = self.pool5_7x7_s1(conv5_3x)\n",
        "        classifier_preflatten = self.classifier(pool5_7x7_s1)\n",
        "        classifier = classifier_preflatten.view(classifier_preflatten.size(0), -1)\n",
        "        #return classifier, pool5_7x7_s1 　出力を変更しておかないと次元が合わないと言われる\n",
        "        return classifier\n",
        "\n",
        "def resnet50_ft_dag(weights_path=None, **kwargs):\n",
        "    \"\"\"\n",
        "    load imported model instance\n",
        "\n",
        "    Args:\n",
        "        weights_path (str): If set, loads model weights from the given path\n",
        "    \"\"\"\n",
        "    model = Resnet50_ft_dag()\n",
        "    if weights_path:\n",
        "        state_dict = torch.load(weights_path)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "#モデルのロード\n",
        "model_ft = Resnet50_ft_dag()\n",
        "\n",
        "#最終結合層のリセットと付け替え(全結合層を2つに)\n",
        "model_ft.classifier = nn.Linear(2048, 2)\n",
        "model_ft.classifier = nn.Sequential(*([Flatten()] + list(model_ft.children())[-1:])) #Flattenを挿入\n",
        "\n",
        "#重みロード\n",
        "PATH = '/content/drive/My Drive/EfficientNet_ImageNet_558_1.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()\n",
        "\n",
        "#Prediction\n",
        "result = calculateAccuracy(image_path)\n",
        "model_pred_prob.append(result[0])\n",
        "label_list = result[1]\n",
        "eval_index.append(result[2])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-fe874e3acfe2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;31m#重みロード\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/Deep_learning/GravCont_Resnet50_VGGFace2_seed_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanualSeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Deep_learning/GravCont_Resnet50_VGGFace2_seed_1234.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72UkHpANnFjw"
      },
      "source": [
        "#**ResNet50_ImageNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNwSFAOfnEtq",
        "outputId": "8fd44380-a790-420f-b1ee-61f45ae4f491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "ModelName = 'ResNet50_ImageNet'\n",
        "checkModelName(ModelName, ModelName_list)\n",
        "\n",
        "model_ft = models.resnet50(pretrained=False)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# 重みロード\n",
        "PATH = '/content/drive/My Drive/Deep_learning/GravCont_Resnet50_ImageNet_seed_'+str(manualSeed)+'.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()\n",
        "\n",
        "#Prediction\n",
        "result = calculateAccuracy(image_path)\n",
        "model_pred_prob.append(result[0])\n",
        "label_list = result[1]\n",
        "eval_index.append(result[2])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47 18 36 27\n",
            "Accuracy: 0.6484375\n",
            "Precision (positive predictive value): 0.6351351351351351\n",
            "Recall (sensitivity): 0.7230769230769231\n",
            "Specificity: 0.5714285714285714\n",
            "F_value: 0.6762589928057553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H64GGa2JmT9D"
      },
      "source": [
        "#**ResNet50_nonPretrained**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVKpRFdAmUDR",
        "outputId": "e25c7003-d3b3-460b-a51f-e9075aab9aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "ModelName = 'ResNet50_nonPretrained'\n",
        "checkModelName(ModelName, ModelName_list)\n",
        "\n",
        "model_ft = models.resnet50(pretrained=False)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "model_ft = model_ft.to(device)\n",
        "# 重みロード\n",
        "PATH = '/content/drive/My Drive/Deep_learning/GravCont_Resnet50_nonPretrained_seed_'+str(manualSeed)+'.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()\n",
        "\n",
        "#Prediction\n",
        "result = calculateAccuracy(image_path)\n",
        "model_pred_prob.append(result[0])\n",
        "label_list = result[1]\n",
        "eval_index.append(result[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34 31 32 31\n",
            "Accuracy: 0.515625\n",
            "Precision (positive predictive value): 0.5230769230769231\n",
            "Recall (sensitivity): 0.5230769230769231\n",
            "Specificity: 0.5079365079365079\n",
            "F_value: 0.5230769230769231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWhxHmDPns3R"
      },
      "source": [
        "#**EfficientNet_b4_ImageNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syACduJCntAB",
        "outputId": "da0f23ce-3ca5-4185-8760-b37c05a0ce9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318,
          "referenced_widgets": [
            "fe270595fd80465fb1b6a574b28ef610",
            "ed11a23659dc4260b2a96a4f2b37cc0b",
            "1286b73e2ad54576b476d02bb08034d7",
            "e0d543ae0e9b46d8a55ef11c81d186f2",
            "66c5add1e4d94f6abe2cac82dfdfb6bb",
            "8ae55706d7664d588f9741ae51117094",
            "a7a8c34b44c3400ebfaffd9ec99cb1fa",
            "bfcca9a920b945329c692411a4980810"
          ]
        }
      },
      "source": [
        "ModelName = 'EfficientNet_b4_ImageNet'\n",
        "checkModelName(ModelName, ModelName_list)    \n",
        "\n",
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet \n",
        "\n",
        "model_ft = EfficientNet.from_pretrained('efficientnet-b4')\n",
        "num_ftrs = model_ft._fc.in_features\n",
        "model_ft._fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#ネットワークの読み込み\n",
        "PATH = '/content/drive/My Drive/EfficientNet_ImageNet_558_1.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()\n",
        "\n",
        "#Prediction\n",
        "result = calculateAccuracy(image_path)\n",
        "model_pred_prob.append(result[0])\n",
        "label_list = result[1]\n",
        "eval_index.append(result[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/83/f9c5f44060f996279e474185ebcbd8dbd91179593bffb9abe3afa55d085b/efficientnet_pytorch-0.7.0.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.5)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.0-cp36-none-any.whl size=16031 sha256=c0b3ddc234706e8b255710c70efef0740d9844c14c2dc5a80a803a09892ffc81\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/c6/e1/7a808b26406239712cfce4b5ceeb67d9513ae32aa4b31445c6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b4-6ed6700e.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe270595fd80465fb1b6a574b28ef610",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=77999237.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded pretrained weights for efficientnet-b4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymGrWxHfntKI"
      },
      "source": [
        "#**Attention_branch_Network_ImageNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gESMORA2ntRo",
        "outputId": "9d068bd4-1585-47c3-ad39-4e161a49dcd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "ModelName = 'Attention_branch_Network_ImageNet'\n",
        "checkModelName(ModelName, ModelName_list)   \n",
        "\n",
        "\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
        "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
        "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
        "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "\n",
        "class ResNet_ARN(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet_ARN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], down_size=True)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, down_size=True)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, down_size=True)\n",
        "\n",
        "        self.att_layer4 = self._make_layer(block, 512, layers[3], stride=1, down_size=False)\n",
        "        self.bn_att = nn.BatchNorm2d(512 * block.expansion)\n",
        "        self.att_conv   = nn.Conv2d(512 * block.expansion, num_classes, kernel_size=1, padding=0,\n",
        "                               bias=False)\n",
        "        self.bn_att2 = nn.BatchNorm2d(num_classes)\n",
        "        self.att_conv2  = nn.Conv2d(num_classes, num_classes, kernel_size=1, padding=0,\n",
        "                               bias=False)\n",
        "        self.att_conv3  = nn.Conv2d(num_classes, 1, kernel_size=3, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn_att3 = nn.BatchNorm2d(1)\n",
        "        self.att_gap = nn.AvgPool2d(14)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, down_size=True)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, down_size=True):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "\n",
        "        if down_size:\n",
        "            self.inplanes = planes * block.expansion\n",
        "            for i in range(1, blocks):\n",
        "                layers.append(block(self.inplanes, planes))\n",
        "\n",
        "            return nn.Sequential(*layers)\n",
        "        else:\n",
        "            inplanes = planes * block.expansion\n",
        "            for i in range(1, blocks):\n",
        "                layers.append(block(inplanes, planes))\n",
        "\n",
        "            return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        fe = x\n",
        "\n",
        "        ax = self.bn_att(self.att_layer4(x))\n",
        "        ax = self.relu(self.bn_att2(self.att_conv(ax)))\n",
        "        bs, cs, ys, xs = ax.shape\n",
        "        self.att = self.sigmoid(self.bn_att3(self.att_conv3(ax)))        \n",
        "        # self.att = self.att.view(bs, 1, ys, xs)\n",
        "        ax = self.att_conv2(ax)\n",
        "        ax = self.att_gap(ax)\n",
        "        ax = ax.view(ax.size(0), -1)\n",
        "\n",
        "        rx = x * self.att\n",
        "        rx = rx + x\n",
        "        per = rx\n",
        "        rx = self.layer4(rx)\n",
        "        rx = self.avgpool(rx)\n",
        "        rx = rx.view(rx.size(0), -1)\n",
        "        rx = self.fc(rx)\n",
        "\n",
        "        return ax, rx, [self.att, fe, per]\n",
        "\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "def resnetARN50(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet_ARN(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "#モデルのロード\n",
        "model_ft = resnetARN50().to(device)\n",
        "\n",
        "#attention branch networkの最終出力を2つにする\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#ネットワークの読み込み\n",
        "PATH = '/content/drive/My Drive/Deep_learning/gravcont_att_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#ネットワークの読み込み\n",
        "PATH = '/content/drive/My Drive/Deep_learning/gravcont_att_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()\n",
        "model_ft.to(device)\n",
        "\n",
        "#Prediction\n",
        "result = calculateAccuracy(image_path)\n",
        "model_pred_prob.append(result[0])\n",
        "label_list = result[1]\n",
        "eval_index.append(result[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49 16 52 11\n",
            "Accuracy: 0.7890625\n",
            "Precision (positive predictive value): 0.8166666666666667\n",
            "Recall (sensitivity): 0.7538461538461538\n",
            "Specificity: 0.8253968253968254\n",
            "F_value: 0.784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVay7Id8oIPK"
      },
      "source": [
        "#**Drawing ROC curve** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q1bF1hpg5Qd",
        "outputId": "3b6a7cc0-07a5-4dc4-a9d2-808c63dfdedf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "print(ModelName_list)\n",
        "\n",
        "print(model_pred_prob)\n",
        "len(model_pred_prob[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ResNet50_VGGFace2', 'ResNet50_ImageNet', 'ResNet50_nonPretrained', 'EfficientNet_b4_ImageNet', 'Attention_branch_Network_ImageNet']\n",
            "[[0.9790650606155396, 0.026246607303619385, 0.9771180152893066, 0.034967899322509766, 0.2386661171913147, 0.4647541046142578, 0.9999843835830688, 0.018199443817138672, 0.9705369472503662, 0.9829356670379639, 0.20673340559005737, 0.9550123810768127, 0.115531325340271, 0.21190613508224487, 0.9998389482498169, 0.009984791278839111, 0.2542803883552551, 0.86346834897995, 0.15973007678985596, 0.9996811151504517, 0.4335808753967285, 0.4469411373138428, 0.9999979734420776, 0.2495620846748352, 0.9947236776351929, 0.9912379384040833, 0.5207807421684265, 0.5824018120765686, 0.08007705211639404, 0.07400882244110107, 0.9950986504554749, 0.9411635994911194, 0.12976133823394775, 0.09791553020477295, 0.7021567821502686, 0.9999922513961792, 0.7264546751976013, 0.035286784172058105, 0.044655799865722656, 0.08215898275375366, 1.0, 0.38154661655426025, 0.2631845474243164, 0.10793709754943848, 0.12338149547576904, 0.9950608611106873, 0.9999029636383057, 0.036663711071014404, 0.04064500331878662, 0.9987905621528625, 0.8118093013763428, 0.11153936386108398, 0.18998384475708008, 0.9998177886009216, 0.08021163940429688, 0.5520241260528564, 0.7029680609703064, 0.9597899317741394, 0.08155941963195801, 0.9965883493423462, 0.8348885774612427, 0.991655707359314, 0.10690063238143921, 0.5010124444961548, 0.9993981122970581, 0.9790109992027283, 0.07347387075424194, 0.7218027114868164, 0.8180245757102966, 0.999922513961792, 0.9999620914459229, 0.034631550312042236, 0.14328551292419434, 0.24226748943328857, 0.027871131896972656, 0.9999953508377075, 0.9997712969779968, 0.980217695236206, 0.04016178846359253, 0.18250668048858643, 0.7494967579841614, 0.10501933097839355, 0.36267054080963135, 0.9999786615371704, 0.9999947547912598, 0.4843406677246094, 0.7178724408149719, 0.054137587547302246, 0.7727088928222656, 0.42002350091934204, 0.4994310140609741, 0.5611247420310974, 0.9909512996673584, 0.1644439697265625, 0.8928737640380859, 0.617763340473175, 0.25128239393234253, 0.9999992847442627, 0.9997441172599792, 0.999994158744812, 0.4631900191307068, 0.017274916172027588, 0.7397900223731995, 0.5534926056861877, 0.15833890438079834, 0.3338891863822937, 0.9045776128768921, 0.34198999404907227, 0.9999529123306274, 0.9999799728393555, 0.9988924860954285, 0.8987222909927368, 0.9997963309288025, 0.999891996383667, 0.8475645184516907, 0.5122610926628113, 0.056265175342559814, 0.9981873631477356, 0.9999887943267822, 0.04878133535385132, 0.7320812940597534, 0.020694434642791748, 0.2465541958808899, 0.7642732262611389, 0.13279128074645996, 0.037220299243927, 0.11166650056838989, 0.9999929666519165], [0.5045126080513, 0.44307589530944824, 0.5527889132499695, 0.46735960245132446, 0.4392452836036682, 0.5889669060707092, 0.46496206521987915, 0.3950539231300354, 0.8563628792762756, 0.9778621196746826, 0.4404844045639038, 0.9676823616027832, 0.8785753846168518, 0.49471426010131836, 0.45561647415161133, 0.4485463500022888, 0.448797345161438, 0.9579796195030212, 0.4443066120147705, 0.6959050893783569, 0.472176730632782, 0.6545975208282471, 0.6279265284538269, 0.486394464969635, 0.9902614951133728, 0.5129293203353882, 0.523269772529602, 0.4445747137069702, 0.5043448209762573, 0.457197904586792, 0.4872545003890991, 0.7328001260757446, 0.4600644111633301, 0.44945383071899414, 0.4510357975959778, 0.9007282257080078, 0.26214832067489624, 0.7772383689880371, 0.4700145721435547, 0.4819785952568054, 0.6650607585906982, 0.4883279800415039, 0.5167866945266724, 0.45748597383499146, 0.45760560035705566, 0.6348122358322144, 0.6342640519142151, 0.4575575590133667, 0.4513765573501587, 0.2614743113517761, 0.4444500803947449, 0.4547216296195984, 0.7105836868286133, 0.5550155639648438, 0.5330690741539001, 0.46317386627197266, 0.9977260231971741, 0.3400474786758423, 0.4540392756462097, 0.45731836557388306, 0.44579291343688965, 0.4601612091064453, 0.5098046064376831, 0.4445977210998535, 0.6010584831237793, 0.6834436655044556, 0.45215898752212524, 0.4452695846557617, 0.4514177441596985, 0.6890971064567566, 0.46860694885253906, 0.8911247253417969, 0.6661463379859924, 0.6509571671485901, 0.4673294425010681, 0.9863038659095764, 0.8418664932250977, 0.5030667781829834, 0.6278179287910461, 0.447370707988739, 0.457591712474823, 0.46048790216445923, 0.44677770137786865, 0.45511138439178467, 0.4261605143547058, 0.4386497735977173, 0.4367274045944214, 0.4963163137435913, 0.5009387731552124, 0.4913640022277832, 0.44409239292144775, 0.5486435890197754, 0.4625154733657837, 0.45038676261901855, 0.45255881547927856, 0.6175582408905029, 0.44690996408462524, 0.8883811235427856, 0.8560894131660461, 0.8997153043746948, 0.4580063819885254, 0.4005424380302429, 0.46268218755722046, 0.5756432414054871, 0.5119511485099792, 0.4366557002067566, 0.6870983242988586, 0.47137463092803955, 0.477481484413147, 0.6300921440124512, 0.4337611198425293, 0.37468409538269043, 0.6061874032020569, 0.5978228449821472, 0.49674248695373535, 0.9800602197647095, 0.4723024368286133, 0.4485820531845093, 0.6131135821342468, 0.4470701813697815, 0.4455602765083313, 0.4416743516921997, 0.43959057331085205, 0.4345622658729553, 0.4797086715698242, 0.5729544162750244, 0.9984369874000549, 0.7793660759925842], [0.4995516538619995, 0.4981405735015869, 0.5406818389892578, 0.9983962178230286, 0.49841099977493286, 0.5034869909286499, 0.8561266660690308, 0.4961293339729309, 0.5005523562431335, 0.5021836757659912, 0.4986761212348938, 0.5038682818412781, 0.4977453351020813, 0.5400657653808594, 0.5000349879264832, 0.49899613857269287, 0.4989013671875, 0.49970078468322754, 0.4985657334327698, 0.5031099319458008, 0.5008513331413269, 0.4993351697921753, 0.4990605115890503, 0.9523511528968811, 0.5018839240074158, 0.49834978580474854, 0.5001053214073181, 0.49896878004074097, 0.5015809535980225, 0.4987833499908447, 0.5199571847915649, 0.5006330013275146, 0.4984434247016907, 0.5007516145706177, 0.4994746446609497, 0.5029686689376831, 0.5416406989097595, 0.49880290031433105, 0.5064346790313721, 0.5347419381141663, 0.5133593678474426, 0.49750572443008423, 0.5277620553970337, 0.5005217790603638, 0.5106772780418396, 0.5022414922714233, 0.5013771057128906, 0.499184250831604, 0.49800974130630493, 0.4978069067001343, 0.49889224767684937, 0.500967264175415, 0.5032215714454651, 0.5730724930763245, 0.497241735458374, 0.5015990734100342, 0.5020627379417419, 0.49901002645492554, 0.9997572302818298, 0.49952030181884766, 0.49935293197631836, 0.5003407001495361, 0.5016103982925415, 0.5006135702133179, 0.4986083507537842, 0.4978272318840027, 0.500471293926239, 0.5002779960632324, 0.49769967794418335, 0.5015349984169006, 0.500235378742218, 0.4991973042488098, 0.5008293390274048, 0.6187830567359924, 0.5146377682685852, 0.5011207461357117, 0.5037609338760376, 0.504493772983551, 0.5000174641609192, 0.4981878995895386, 0.4995492696762085, 0.9587014317512512, 0.4987751245498657, 0.4986637234687805, 0.4999192953109741, 0.4989809989929199, 0.4982386827468872, 0.49892866611480713, 0.49844980239868164, 0.49690115451812744, 0.49924057722091675, 0.49800175428390503, 0.500064492225647, 0.5009902119636536, 0.49900639057159424, 0.500654399394989, 0.49950551986694336, 0.49712157249450684, 0.5006778240203857, 0.5014069676399231, 0.4991414546966553, 0.49636369943618774, 0.5036296844482422, 0.49843865633010864, 0.5017905831336975, 0.4973679780960083, 0.5011544823646545, 0.49653977155685425, 0.49872297048568726, 0.4995957016944885, 0.49860453605651855, 0.5345274209976196, 0.4986807703971863, 0.499431848526001, 0.49743980169296265, 0.5034826993942261, 0.4973195791244507, 0.4995543360710144, 0.49963533878326416, 0.49897849559783936, 0.49995559453964233, 0.4995468258857727, 0.49648600816726685, 0.5067803859710693, 0.5080053210258484, 0.5025866627693176, 0.4984009265899658, 0.7379171252250671], [0.9997701048851013, 4.947185516357422e-05, 0.960808515548706, 0.0034273862838745117, 0.001295924186706543, 0.020458638668060303, 0.9996297359466553, 0.00048291683197021484, 0.9919238686561584, 0.6945501565933228, 0.006132781505584717, 0.9714308977127075, 0.030348539352416992, 0.003927350044250488, 0.9928106665611267, 0.00014698505401611328, 0.5668221116065979, 0.7031484842300415, 0.2557094693183899, 0.9998812675476074, 0.6457259654998779, 0.00605165958404541, 0.9987878203392029, 0.19384390115737915, 0.9996860027313232, 0.142300546169281, 0.6909024119377136, 0.01883256435394287, 0.03855395317077637, 0.03918254375457764, 0.939141035079956, 0.8968400955200195, 0.05754077434539795, 0.002390146255493164, 0.09144806861877441, 0.999346911907196, 0.026497721672058105, 0.001439511775970459, 0.00044339895248413086, 0.5837361216545105, 0.999996542930603, 0.01166313886642456, 0.8678990602493286, 0.00047969818115234375, 0.0001442432403564453, 0.9974523186683655, 0.9996174573898315, 0.05627739429473877, 4.3392181396484375e-05, 0.9857271313667297, 0.9479319453239441, 0.0011022090911865234, 0.0007329583168029785, 0.9876694083213806, 0.005273997783660889, 0.3774159550666809, 0.6500129699707031, 0.9933193922042847, 0.0036216378211975098, 0.9984018206596375, 0.10499626398086548, 0.92750483751297, 0.0016132593154907227, 0.007214009761810303, 0.9999672174453735, 0.9948262572288513, 0.1640024185180664, 0.01568394899368286, 0.0006622672080993652, 0.9994410872459412, 0.9947071671485901, 0.0006186962127685547, 0.2648875117301941, 0.005148470401763916, 0.13252681493759155, 0.9994408488273621, 0.8931154012680054, 0.9884399175643921, 6.365776062011719e-05, 0.574020504951477, 0.47985875606536865, 0.8137936592102051, 0.00036978721618652344, 0.9958206415176392, 0.9992615580558777, 0.25491172075271606, 0.03431934118270874, 0.021691620349884033, 0.39654940366744995, 0.23202383518218994, 0.9679015278816223, 0.05251765251159668, 0.9997363686561584, 0.006535828113555908, 0.8373453617095947, 0.91871577501297, 0.009379982948303223, 0.9999723434448242, 0.9990183115005493, 0.968296229839325, 0.0007756948471069336, 0.0017742514610290527, 0.8732233643531799, 0.2577991485595703, 0.035999596118927, 0.9654382467269897, 0.9590818881988525, 0.0502665638923645, 0.9989601373672485, 0.9996063113212585, 0.9999167919158936, 0.9949856996536255, 0.9942471981048584, 0.9999662637710571, 0.02578216791152954, 0.07819390296936035, 0.23124468326568604, 0.987168550491333, 0.9997565150260925, 0.0002949833869934082, 0.7960054874420166, 0.006403923034667969, 0.7866515517234802, 0.9756995439529419, 0.05095946788787842, 0.037167251110076904, 0.14627444744110107, 0.9918732047080994], [0.9998331069946289, 0.047308146953582764, 0.8449653387069702, 0.22335082292556763, 0.5264374017715454, 0.3434271216392517, 0.868098795413971, 0.016292154788970947, 0.8197617530822754, 0.43840110301971436, 0.523574709892273, 0.8822904825210571, 0.07900810241699219, 0.17334705591201782, 0.9013834595680237, 0.004872679710388184, 0.5848946571350098, 0.568537175655365, 0.1450669765472412, 0.9955253005027771, 0.7645732164382935, 0.10411667823791504, 1.0, 0.6723499894142151, 0.9674075841903687, 0.8928790092468262, 0.0284348726272583, 0.8133178353309631, 0.05193692445755005, 0.04287010431289673, 0.2416958212852478, 0.8080409169197083, 0.27207982540130615, 0.03621870279312134, 0.4972720146179199, 0.9993699193000793, 0.19886451959609985, 0.04912972450256348, 0.061676204204559326, 0.18716275691986084, 0.9999985694885254, 0.059578657150268555, 0.8715779185295105, 0.02027946710586548, 0.10933226346969604, 0.9132653474807739, 0.9999998807907104, 0.10639292001724243, 0.07066148519515991, 0.8831198811531067, 0.5581653118133545, 0.22890013456344604, 0.448685884475708, 0.9585177302360535, 0.006657660007476807, 0.08534902334213257, 0.8163159489631653, 0.9299746155738831, 0.15869605541229248, 0.9062340259552002, 0.5408827662467957, 0.7241644263267517, 0.10157102346420288, 0.3239080309867859, 0.9449374079704285, 0.6817405819892883, 0.033984601497650146, 0.033384859561920166, 0.5492003560066223, 0.999737560749054, 0.913486123085022, 0.009530961513519287, 0.09376770257949829, 0.7048995494842529, 0.20170456171035767, 0.991766631603241, 0.8065115213394165, 0.8477585315704346, 0.09485447406768799, 0.5565565824508667, 0.5260176658630371, 0.6509225368499756, 0.03692948818206787, 0.973350465297699, 0.9999746084213257, 0.43813782930374146, 0.20580220222473145, 0.03488600254058838, 0.48967891931533813, 0.6284942030906677, 0.7368251085281372, 0.3279690146446228, 0.951073944568634, 0.6835908889770508, 0.8157558441162109, 0.825607180595398, 0.12119263410568237, 0.9997435212135315, 0.9323363900184631, 0.9981837868690491, 0.016269803047180176, 0.0020933151245117188, 0.819054901599884, 0.13870441913604736, 0.11759328842163086, 0.5283310413360596, 0.6878511905670166, 0.04961514472961426, 0.9998475313186646, 0.9867516756057739, 0.9296479821205139, 0.8791587948799133, 0.9984000325202942, 0.9999804496765137, 0.5773994326591492, 0.3164275288581848, 0.0636715292930603, 0.5420143008232117, 0.9743345379829407, 0.03191089630126953, 0.5028619170188904, 0.006848454475402832, 0.26131898164749146, 0.16312569379806519, 0.1711687445640564, 0.02117025852203369, 0.020971357822418213, 0.9238229393959045]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gom3bMGgSXVn",
        "outputId": "09af43af-880f-4e9f-f479-c301aa6877f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_score = []\n",
        "y_true = []\n",
        "\n",
        "k=0\n",
        "for i in label_list:\n",
        "    if label_list[k] == 'cont':\n",
        "          y_true.append(0)\n",
        "    elif label_list[k] == 'grav':\n",
        "          y_true.append(1)\n",
        "    k+=1\n",
        "\n",
        "\n",
        "#健康な状態を「0」、病気を「1」としてラベルよりリストを作成\n",
        "y_true = y_true\n",
        "\n",
        "#グラフの外形を作成\n",
        "plt.figure(figsize=(8.0, 6.0))\n",
        "lw = 2\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "\n",
        "ycolor = ['darkorange','blue','green','red','black']      # 各プロットの色\n",
        "ylabel = ModelName_list   # 各ラベル\n",
        "\n",
        "k=0\n",
        "for i in ModelName_list:\n",
        "    y_score = model_pred_prob[k]\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label=ylabel[k]+'(area = %0.2f)' % roc_auc)\n",
        "    k+=1\n",
        "\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPvEEG6J08xj",
        "outputId": "0a3b2436-217a-4d2d-8f21-1131224538c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "rowname= ModelName_list\n",
        "colname= ['Accuracy','Positive predictive value','Sensitivity','Specificity','F_value']\n",
        "\n",
        "df = pd.DataFrame(data=eval_index, index=rowname, columns=colname)\n",
        "print(df)\n",
        "\n",
        "df.to_csv(\"/content/eval_index.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                   Accuracy  ...   F_value\n",
            "ResNet50_VGGFace2                  0.812500  ...  0.806452\n",
            "ResNet50_ImageNet                  0.648438  ...  0.676259\n",
            "ResNet50_nonPretrained             0.515625  ...  0.523077\n",
            "EfficientNet_b4_ImageNet           0.835938  ...  0.839695\n",
            "Attention_branch_Network_ImageNet  0.789062  ...  0.784000\n",
            "\n",
            "[5 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}