{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled31.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/EfficientNet_b4_VGGFace2_adabound_crossvalidation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-a4ZBlqPNdU"
      },
      "source": [
        "#**GravCont: EfficientNet_b4_VGGFace2**\n",
        "ValidationとTestに分けて解析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgM-Y7SVPNkM",
        "outputId": "54eee060-0cc7-46bf-b4ed-15185fdd6588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "#Advanced Pytorchから\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set random seem for reproducibility\n",
        "manualSeed = 1234\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.cuda.manual_seed(manualSeed)\n",
        "\n",
        "torch.torch.backends.cudnn.benchmark = True\n",
        "torch.torch.backends.cudnn.enabled = True\n",
        "\n",
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet \n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "'''\n",
        "grav: 甲状腺眼症\n",
        "cont: コントロール\n",
        "黒の空白を挿入することにより225px*225pxの画像を生成、EfficientNetを用いて転移学習\n",
        "－－－－－－－－－－－－－－\n",
        "データの構造\n",
        "gravcont.zip ------grav\n",
        "               |---cont\n",
        "'''                                     \n",
        "\n",
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_optimizer in /usr/local/lib/python3.6/dist-packages (0.0.1a15)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torch_optimizer) (1.6.0+cu101)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from torch_optimizer) (0.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (0.16.0)\n",
            "Random Seed:  1234\n",
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzp_09fWPNoU"
      },
      "source": [
        "#**モジュール群**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7sJV06qPNsM"
      },
      "source": [
        "def pre_process(data_dir):\n",
        "    # 入力画像の前処理をするクラス\n",
        "    # 訓練時と推論時で処理が異なる\n",
        "\n",
        "    \"\"\"\n",
        "        画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "        画像のサイズをリサイズし、色を標準化する。\n",
        "        訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n",
        "\n",
        "\n",
        "        Attributes\n",
        "        ----------\n",
        "        resize : int\n",
        "            リサイズ先の画像の大きさ。\n",
        "        mean : (R, G, B)\n",
        "            各色チャネルの平均値。\n",
        "        std : (R, G, B)\n",
        "            各色チャネルの標準偏差。\n",
        "    \"\"\"\n",
        "\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224, scale=(0.75,1.0)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    data_dir = data_dir\n",
        "    n_samples = len(data_dir)\n",
        "\n",
        "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                              data_transforms[x])\n",
        "                      for x in ['train', 'val']}\n",
        "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n",
        "                                                shuffle=True, num_workers=4)\n",
        "                  for x in ['train', 'val']}\n",
        "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "    class_names = image_datasets['train'].classes\n",
        "\n",
        "\n",
        "    print(class_names)\n",
        "    k=0\n",
        "    for i in class_names:\n",
        "        print(class_names[k]+\"_train:\"+str(len(os.listdir(path=data_dir + '/train/'+class_names[k]))))\n",
        "        k+=1\n",
        "    k=0\n",
        "    for i in class_names:\n",
        "        print(class_names[k]+\"_val:\"+str(len(os.listdir(path=data_dir + '/val/'+class_names[k]))))\n",
        "        k+=1\n",
        "\n",
        "    print(\"training data set_total：\"+ str(len(image_datasets['train'])))\n",
        "    print(\"validating data set_total：\"+str(len(image_datasets['val'])))\n",
        "    \n",
        "    return image_datasets, dataloaders, dataset_sizes, class_names, device\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "def getBatch(dataloaders):    \n",
        "    # Get a batch of training data\n",
        "    inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "    # Make a grid from batch\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "    #imshow(out, title=[class_names[x] for x in classes])\n",
        "    return(inputs, classes)\n",
        "\n",
        "#Defining early stopping class\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_loss = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_loss = []\n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase] \n",
        "            \n",
        "            # record train_loss and valid_loss\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "            if phase == 'val':\n",
        "                valid_loss.append(epoch_loss)\n",
        "            #print(train_loss)\n",
        "            #print(valid_loss)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "      \n",
        "      # early_stopping needs the validation loss to check if it has decresed, \n",
        "      # and if it has, it will make a checkpoint of the current model\n",
        "        if phase == 'val':    \n",
        "            early_stopping(epoch_loss, model)\n",
        "                \n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "        print()\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_loss, valid_loss\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "\n",
        "def training(model_ft, criterion, optimizer_ft,  patience=15, num_epochs=50):\n",
        "    model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=patience, num_epochs=num_epochs)\n",
        "\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      return(image_name, label)\n",
        "\n",
        "'''\n",
        "#変形後の画像を表示\n",
        "def image_transform(image_path):\n",
        "\n",
        "    image=Image.open(image_path)\n",
        "\n",
        "    \n",
        "    #変形した画像を表示する\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224)])\n",
        "    image_transformed = transform(image)\n",
        "    plt.imshow(np.array(image_transformed))\n",
        "'''\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を表示\n",
        "def image_eval(image_tensor, label):\n",
        "    output = model_ft(image_tensor)\n",
        "    #print(output.size())  # torch.Size([1, 1000])\n",
        "    #print(output)\n",
        "\n",
        "    #model_pred:クラス名前、prob:確率、pred:クラス番号\n",
        "    prob, pred = torch.topk(nn.Softmax(dim=1)(output), 1)\n",
        "    model_pred = class_names[pred]\n",
        "    \n",
        "    #甲状腺眼症のprobabilityを計算（classが0なら1から減算、classが1ならそのまま）\n",
        "    prob = abs(1-float(prob)-float(pred))\n",
        " \n",
        "    return model_pred, prob, pred\n",
        "\n",
        "    \"\"\"\n",
        "    #probalilityを計算する\n",
        "    pred_prob = torch.topk(nn.Softmax(dim=1)(output), 1)[0]\n",
        "    pred_class = torch.topk(nn.Softmax(dim=1)(output), 1)[1]\n",
        "    if pred_class == 1:\n",
        "        pred_prob = pred_prob\n",
        "    elif pred_class == 0:\n",
        "        pred_prob = 1- pred_prob\n",
        "    return(model_pred, pred_prob)  #class_nameの番号で出力される\n",
        "    \"\"\"\n",
        "\n",
        "def showImage(image_path):\n",
        "    #画像のインポート\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    #画像のリサイズ\n",
        "    height = img.shape[0]\n",
        "    width = img.shape[1]\n",
        "    resized_img = cv2.resize(img, (int(width*300/height), 300))\n",
        "    cv2_imshow(resized_img)\n",
        "\n",
        "def calculateAccuracy (TP, TN, FP, FN):\n",
        "    accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "    precision  = TP/(FP + TP)\n",
        "    recall = TP/(TP + FN)\n",
        "    specificity = TN/(FP + TN)\n",
        "    f_value = (2*recall*precision)/(recall+precision)\n",
        "    return(accuracy, precision, recall, specificity, f_value)\n",
        "\n",
        "\"\"\"\n",
        "・True positive (TN)\n",
        "・False positive (FP)\n",
        "・True negative (TN)\n",
        "・False negative (FN)\n",
        "Accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "Precision = TP/(FP + TP) ※positive predictive value\n",
        "Recall = TP/(TP + FN)　※sensitivity\n",
        "Specificity = TN/(FP + TN)\n",
        "F_value = (2RecallPrecision)/(Recall+Precision)\n",
        "\"\"\"\n",
        "\n",
        "def evaluation(model_ft, testset_dir):\n",
        "    #評価モードにする\n",
        "    model_ft.eval()\n",
        "\n",
        "    #testデータセット内のファイル名を取得\n",
        "    image_path = glob.glob(testset_dir + \"/*/*\")\n",
        "    #random.shuffle(image_path)  #表示順をランダムにする\n",
        "    print('number of images: ' +str(len(image_path)))\n",
        "\n",
        "\n",
        "    TP, FP, TN, FN, TP, FP, TN, FN = [0,0,0,0,0,0,0,0]\n",
        "    image_name_list = []\n",
        "    label_list = []\n",
        "    model_pred_list = []\n",
        "    hum_pred_list = []\n",
        "\n",
        "    model_pred_class = []\n",
        "    model_pred_prob = []\n",
        "\n",
        "    for i in image_path:\n",
        "          image_name, label = getlabel(i)  #画像の名前とラベルを取得\n",
        "          image_tensor = image_transform(i)  #予測のための画像下処理\n",
        "          model_pred, prob, pred = image_eval(image_tensor, label)  #予測結果を出力   \n",
        "          #print('Image: '+ image_name)\n",
        "          #print('Label: '+ label)\n",
        "          #print('Pred: '+ model_pred)\n",
        "          #showImage(i)  #画像を表示\n",
        "          #print() #空白行を入れる\n",
        "          time.sleep(0.1)\n",
        "\n",
        "          image_name_list.append(image_name)\n",
        "          label_list.append(label)\n",
        "          model_pred_list.append(model_pred)\n",
        "\n",
        "          model_pred_class.append(int(pred))\n",
        "          model_pred_prob.append(float(prob))\n",
        "\n",
        "          if label == class_names[0]:\n",
        "              if model_pred == class_names[0]:\n",
        "                  TN += 1\n",
        "              else:\n",
        "                  FP += 1\n",
        "          elif label == class_names[1]:\n",
        "              if model_pred == class_names[1]:\n",
        "                  TP += 1\n",
        "              else:\n",
        "                  FN += 1     \n",
        "\n",
        "    print(TP, FN, TN, FP)\n",
        "\n",
        "    #Accuracyを計算\n",
        "    accuracy, precision, recall, specificity, f_value = calculateAccuracy (TP, TN, FP, FN)\n",
        "    print('Accuracy: ' + str(accuracy))\n",
        "    print('Precision (positive predictive value): ' + str(precision))\n",
        "    print('Recall (sensitivity): ' + str(recall))\n",
        "    print('Specificity: ' + str(specificity))\n",
        "    print('F_value: ' + str(f_value))\n",
        "\n",
        "    #print(model_pred_class)\n",
        "    #print(model_pred_prob)\n",
        "\n",
        "    return TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, label_list, model_pred_prob\n",
        "\n",
        "\n",
        "def make_csv(roc_label_list):\n",
        "    #csvのdata tableを作成\n",
        "    pd.set_option('display.max_rows', 800)  # 省略なしで表示\n",
        "    #columns1 = [\"EfficientNet_32\", \"EfficientNet_64\", \"EfficientNet_128\", \"EfficientNet_256\", \"EfficientNet_512\", \"EfficientNet_558\"]\n",
        "    roc_label_list.extend([\"avg\", \"std\"])\n",
        "    index1 = [\"TP\",\"TN\",\"FP\",\"FN\",\"Accuracy\",\"Positive predictive value\",\"sensitity\",\"specificity\",\"F-value\",\"roc_auc\"]\n",
        "    df = pd.DataFrame(index=index1, columns=roc_label_list)\n",
        "    return df\n",
        "\n",
        "def write_csv(df, col, TP, TN, FP, FN, accuracy, precision, recall, specificity, f_value,roc_auc):\n",
        "    df.iloc[0:10, col] = TP, TN, FP, FN, accuracy, precision, recall, specificity, f_value,roc_auc \n",
        "    #print(df)\n",
        "\n",
        "    # CSVとして出力\n",
        "    #df2.to_csv(\"/content/drive/My Drive/Grav_bootcamp/Posttrain_model_eval_result.csv\",encoding=\"shift_jis\")\n",
        "    return df\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == 'cont':\n",
        "                  y_true.append(0)\n",
        "            elif i == 'grav':\n",
        "                  y_true.append(1)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_auc(label_list, model_pred_prob):\n",
        "    y_true, y_score = [], []\n",
        "    for i in label_list:\n",
        "        if i == 'cont':\n",
        "              y_true.append(0)\n",
        "        elif i == 'grav':\n",
        "              y_true.append(1)\n",
        "            \n",
        "    #それぞれの画像における陽性の確率についてリストを作成\n",
        "    y_score = model_pred_prob\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc: \" +str(roc_auc))\n",
        "    return(roc_auc, y_true, y_score)\n",
        "\n",
        "def calcurate_ave_std(df, fold):\n",
        "    for i in range(5):\n",
        "        df.iloc[i,fold] = df[i,0:5].mean \n",
        "\n",
        "def makefolder(path):\n",
        "    if not os.path.exists(path):  # ディレクトリがなかったら\n",
        "        os.mkdir(path)  # 作成したいフォルダ名を作成\n",
        "\n",
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "def convnet():\n",
        "    model_ft = EfficientNet.from_pretrained('efficientnet-b4')\n",
        "    model_ft._fc = nn.Linear(1792, 8631)\n",
        "\n",
        "    #model_ft = EfficientNet.from_pretrained('efficientnet-b4')\n",
        "    model_ft.load_state_dict(torch.load('/content/drive/My Drive/EfficientNet_VGGFace2_pretrained.pth'))\n",
        "    #最終結合層のリセットと付け替え(全結合層を2つに)\n",
        "    model_ft._fc = nn.Linear(1792, 2)\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    #https://blog.knjcode.com/adabound-memo/\n",
        "    #https://pypi.org/project/torch-optimizer/\n",
        "    optimizer_ft = optim.AdaBound(\n",
        "        model_ft.parameters(),\n",
        "        lr= 1e-3,\n",
        "        betas= (0.9, 0.999),\n",
        "        final_lr = 0.1,\n",
        "        gamma=1e-3,\n",
        "        eps= 1e-8,\n",
        "        weight_decay=0,\n",
        "        amsbound=False,\n",
        "    )\n",
        "    return (model_ft, criterion, optimizer_ft)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USGfUwQXv6Jc"
      },
      "source": [
        "#**まとめて解析**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM2VMXltwBs5"
      },
      "source": [
        "# 出力名を記入\n",
        "out_name = \"EfficientNet_VGGFace2_320\"\n",
        "\n",
        "#create data_dir_list\n",
        "data_dir = '/content/drive/My Drive/crossvalidation/320'\n",
        "fold = len(os.listdir(data_dir))\n",
        "print(str(fold)+'-fold cross validation')\n",
        "\n",
        "\n",
        "data_dir_list = [0]*fold\n",
        "\n",
        "for i in range(fold):\n",
        "    data_dir_list[i] = data_dir + '/' + str(i)\n",
        "    print(data_dir_list[i])\n",
        "\n",
        "#create roc_label_list\n",
        "roc_label_list = [0]*fold\n",
        "roc_label_list = list(range(fold))\n",
        "#print(roc_label_list)\n",
        "\n",
        "\n",
        "\n",
        "df = make_csv(roc_label_list)\n",
        "\n",
        "label_list_list, model_pred_prob_list, Y_TRUE, Y_SCORE = [],[],[],[]\n",
        "\n",
        "#print(data_dir_list)\n",
        "#print(roc_label_list)\n",
        "\n",
        "for i, t in enumerate(zip(data_dir_list, roc_label_list)):\n",
        "\n",
        "    image_datasets, dataloaders, dataset_sizes, class_names, device = pre_process(t[0]) #path\n",
        "    inputs, classes = getBatch(dataloaders)\n",
        "    model_ft, criterion, optimizer_ft = convnet()\n",
        "    training(model_ft, criterion, optimizer_ft,  patience=15, num_epochs=50)  \n",
        "    torch.save(model_ft.state_dict(), '/content/'+str(out_name)+\"_\"+str(i)+\".pth\")    #ネットワークの保存\n",
        "    TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, label_list, model_pred_prob = evaluation(model_ft, '/content/drive/My Drive/Grav_bootcamp/Posttrain_250px')\n",
        "    roc_auc, y_true, y_score = calculate_auc(label_list, model_pred_prob)\n",
        "    Y_TRUE.append(y_true)\n",
        "    Y_SCORE.append(y_score)\n",
        "    df = write_csv(df, i,TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, roc_auc) #numberをcsvの行として指定\n",
        "\n",
        "    label_list_list.append(label_list)\n",
        "    model_pred_prob_list.append(model_pred_prob)\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "\n",
        "#Draw ROC curve\n",
        "fig = Draw_roc_curve(label_list_list, model_pred_prob_list, roc_label_list, len(label_list_list))\n",
        "\n",
        "pd.set_option('display.max_columns', 100)\n",
        "#それぞれの項目の平均を計算しcsvに追記する\n",
        "df.iloc[0:4,fold], df.iloc[9,fold]   = df.mean(axis=1)[0:4], df.mean(axis=1)[9] \n",
        "df.iloc[0:10,fold+1] = df.std(axis=1)[0:10]\n",
        "TP,TN,FP,FN = df.mean(axis=1)[0:4]\n",
        "df.iloc[4:9,fold] = calculateAccuracy (TP, TN, FP, FN)\n",
        "print(df)\n",
        "\n",
        "# CSVとして出力\n",
        "makefolder(\"/content/drive/My Drive/crossvalidation/crossvalidation_csv\")\n",
        "df.to_csv(\"/content/drive/My Drive/crossvalidation/crossvalidation_csv/crossvalidation_\" + out_name + \".csv\",encoding=\"shift_jis\")\n",
        "\n",
        "#ROC_curveを保存\n",
        "makefolder(\"/content/drive/My Drive/crossvalidation/crossvalidation_ROCfigure\")\n",
        "fig.savefig(\"/content/drive/My Drive/crossvalidation/crossvalidation_ROCfigure/crossvalidation_\" + out_name +\".png\")\n",
        "\n",
        "#Save ROC data\n",
        "makefolder(\"/content/drive/My Drive/crossvalidation/crossvalidation_ROCdata\")\n",
        "with open(\"/content/drive/My Drive/crossvalidation/crossvalidation_ROCdata/ROCdata_\"+out_name+\".csv\", 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    for i, t in enumerate(zip(Y_TRUE, Y_SCORE)):\n",
        "        writer.writerow([t[0],t[1]])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXWAmwUvLVIo",
        "outputId": "fa3eb102-d9dc-49ca-b809-f0779d19610c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_ft = EfficientNet.from_name('efficientnet-b4')\n",
        "#print(model_ft)\n",
        "\n",
        "#model_ft.to(device)\n",
        "#summary(model_ft, (3, 224, 224))\n",
        "\n",
        "\n",
        "model_ft._fc = nn.Linear(1792, 8631)\n",
        "\n",
        "model_ft.load_state_dict(torch.load('/content/drive/My Drive/EfficientNet_VGGFace2_pretrained.pth'))\n",
        "#最終結合層のリセットと付け替え(全結合層を2つに)\n",
        "model_ft._fc = nn.Linear(1792, 2)\n",
        "\n",
        "print(model_ft)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EfficientNet(\n",
            "  (_conv_stem): Conv2dStaticSamePadding(\n",
            "    3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
            "    (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "  )\n",
            "  (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "  (_blocks): ModuleList(\n",
            "    (0): MBConvBlock(\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (1): MBConvBlock(\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (2): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (3): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (4): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (5): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (6): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (7): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (8): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (9): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (10): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (11): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (12): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (13): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (14): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (15): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (16): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (17): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (18): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (19): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (20): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (21): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (22): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        960, 960, kernel_size=(5, 5), stride=[2, 2], groups=960, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (23): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (24): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (25): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (26): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (27): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (28): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (29): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (30): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1632, 1632, kernel_size=(3, 3), stride=[1, 1], groups=1632, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (31): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        2688, 2688, kernel_size=(3, 3), stride=(1, 1), groups=2688, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        2688, 112, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        112, 2688, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "  )\n",
            "  (_conv_head): Conv2dStaticSamePadding(\n",
            "    448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "    (static_padding): Identity()\n",
            "  )\n",
            "  (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
            "  (_dropout): Dropout(p=0.4, inplace=False)\n",
            "  (_fc): Linear(in_features=1792, out_features=2, bias=True)\n",
            "  (_swish): MemoryEfficientSwish()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPO-b2cAT0yF"
      },
      "source": [
        "#**ネットワークの保存と読み込み**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMYyFQ6ATzyX"
      },
      "source": [
        "#ネットワークの保存\n",
        "PATH = '/content/drive/My Drive/Grav_bootcamp/GravCont_EfficientNet-b4_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "torch.save(model_ft.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c744XUtfT6xW",
        "outputId": "73a923de-e875-4e71-b4b5-1ae266557981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#ネットワークの読み込み\n",
        "PATH = '/content/drive/My Drive/Grav_bootcamp/GravCont_EfficientNet-b4_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "torch.save(model_ft.state_dict(), PATH)\n",
        "model_ft.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}