{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled31.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dadc1796539e45fc902be88a25007b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3145945c6244464b8561b7f2e90d06c2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b77b6b1aa1564111977e11f804168cf7",
              "IPY_MODEL_179f5bb8070f481a969427f0321b42fb"
            ]
          }
        },
        "3145945c6244464b8561b7f2e90d06c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b77b6b1aa1564111977e11f804168cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d961bdcd70f742789d2b6d63fd2b7ce9",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 77999237,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 77999237,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6470675c69241b4ba4c36f9ae77589e"
          }
        },
        "179f5bb8070f481a969427f0321b42fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1d3f573821f3415cb0705bf4966bb195",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 74.4M/74.4M [00:00&lt;00:00, 108MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38a827321fef4715935b74ec0bfbeac5"
          }
        },
        "d961bdcd70f742789d2b6d63fd2b7ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6470675c69241b4ba4c36f9ae77589e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d3f573821f3415cb0705bf4966bb195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38a827321fef4715935b74ec0bfbeac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/EfficientNet_b4_ImageNet_adabound_ValidationTest_%E3%81%BE%E3%81%A8%E3%82%81%E3%81%A6%E8%A7%A3%E6%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-a4ZBlqPNdU",
        "colab_type": "text"
      },
      "source": [
        "#**GravCont: EfficientNet_b4_ImageNet**\n",
        "ValidationとTestに分けて解析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgM-Y7SVPNkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "cfd31724-0235-41d8-b47f-24b4ad6afcbc"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "#Advanced Pytorchから\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set random seem for reproducibility\n",
        "manualSeed = 1234\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.cuda.manual_seed(manualSeed)\n",
        "\n",
        "torch.torch.backends.cudnn.benchmark = True\n",
        "torch.torch.backends.cudnn.enabled = True\n",
        "\n",
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet \n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "'''\n",
        "grav: 甲状腺眼症\n",
        "cont: コントロール\n",
        "黒の空白を挿入することにより225px*225pxの画像を生成、EfficientNetを用いて転移学習\n",
        "－－－－－－－－－－－－－－\n",
        "データの構造\n",
        "gravcont.zip ------grav\n",
        "               |---cont\n",
        "'''                                     \n",
        "\n",
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch_optimizer\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/48/f670cf4b47c315861d0547f0c2be579cd801304c86e55008492f1acebd01/torch_optimizer-0.0.1a15-py3-none-any.whl (41kB)\n",
            "\r\u001b[K     |███████▉                        | 10kB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 20kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 30kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 40kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torch_optimizer) (1.6.0+cu101)\n",
            "Collecting pytorch-ranger>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/0d/70/12256257d861bbc3e176130d25be1de085ce7a9e60594064888a950f2154/pytorch_ranger-0.1.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (0.16.0)\n",
            "Installing collected packages: pytorch-ranger, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.0.1a15\n",
            "Random Seed:  1234\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/83/f9c5f44060f996279e474185ebcbd8dbd91179593bffb9abe3afa55d085b/efficientnet_pytorch-0.7.0.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.0-cp36-none-any.whl size=16031 sha256=8703f2ee95f0d59e96ac12c968d900fc0b562aedc31b3d2c8aff829bf771283e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/c6/e1/7a808b26406239712cfce4b5ceeb67d9513ae32aa4b31445c6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzp_09fWPNoU",
        "colab_type": "text"
      },
      "source": [
        "#**モジュール群**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7sJV06qPNsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_process(data_dir):\n",
        "    # 入力画像の前処理をするクラス\n",
        "    # 訓練時と推論時で処理が異なる\n",
        "\n",
        "    \"\"\"\n",
        "        画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "        画像のサイズをリサイズし、色を標準化する。\n",
        "        訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n",
        "\n",
        "\n",
        "        Attributes\n",
        "        ----------\n",
        "        resize : int\n",
        "            リサイズ先の画像の大きさ。\n",
        "        mean : (R, G, B)\n",
        "            各色チャネルの平均値。\n",
        "        std : (R, G, B)\n",
        "            各色チャネルの標準偏差。\n",
        "    \"\"\"\n",
        "\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224, scale=(0.75,1.0)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    data_dir = data_dir\n",
        "    n_samples = len(data_dir)\n",
        "\n",
        "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                              data_transforms[x])\n",
        "                      for x in ['train', 'val']}\n",
        "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=20,\n",
        "                                                shuffle=True, num_workers=4)\n",
        "                  for x in ['train', 'val']}\n",
        "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "    class_names = image_datasets['train'].classes\n",
        "\n",
        "\n",
        "    print(class_names)\n",
        "    k=0\n",
        "    for i in class_names:\n",
        "        print(class_names[k]+\"_train:\"+str(len(os.listdir(path=data_dir + '/train/'+class_names[k]))))\n",
        "        k+=1\n",
        "    k=0\n",
        "    for i in class_names:\n",
        "        print(class_names[k]+\"_val:\"+str(len(os.listdir(path=data_dir + '/val/'+class_names[k]))))\n",
        "        k+=1\n",
        "\n",
        "    print(\"training data set_total：\"+ str(len(image_datasets['train'])))\n",
        "    print(\"validating data set_total：\"+str(len(image_datasets['val'])))\n",
        "    \n",
        "    return image_datasets, dataloaders, dataset_sizes, class_names, device\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "def getBatch(dataloaders):    \n",
        "    # Get a batch of training data\n",
        "    inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "    # Make a grid from batch\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "    #imshow(out, title=[class_names[x] for x in classes])\n",
        "    return(inputs, classes)\n",
        "\n",
        "#Defining early stopping class\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_loss = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_loss = []\n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase] \n",
        "            \n",
        "            # record train_loss and valid_loss\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "            if phase == 'val':\n",
        "                valid_loss.append(epoch_loss)\n",
        "            #print(train_loss)\n",
        "            #print(valid_loss)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "      \n",
        "      # early_stopping needs the validation loss to check if it has decresed, \n",
        "      # and if it has, it will make a checkpoint of the current model\n",
        "        if phase == 'val':    \n",
        "            early_stopping(epoch_loss, model)\n",
        "                \n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "        print()\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_loss, valid_loss\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "def convnet():\n",
        "    model_ft = EfficientNet.from_pretrained('efficientnet-b4')\n",
        "    num_ftrs = model_ft._fc.in_features\n",
        "    model_ft._fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    #https://blog.knjcode.com/adabound-memo/\n",
        "    #https://pypi.org/project/torch-optimizer/\n",
        "    optimizer_ft = optim.AdaBound(\n",
        "        model_ft.parameters(),\n",
        "        lr= 1e-3,\n",
        "        betas= (0.9, 0.999),\n",
        "        final_lr = 0.1,\n",
        "        gamma=1e-3,\n",
        "        eps= 1e-8,\n",
        "        weight_decay=0,\n",
        "        amsbound=False,\n",
        "    )\n",
        "    return (model_ft, criterion, optimizer_ft)\n",
        "\n",
        "\n",
        "def training(model_ft, criterion, optimizer_ft,  patience=15, num_epochs=50):\n",
        "    model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=patience, num_epochs=num_epochs)\n",
        "\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      return(image_name, label)\n",
        "\n",
        "'''\n",
        "#変形後の画像を表示\n",
        "def image_transform(image_path):\n",
        "\n",
        "    image=Image.open(image_path)\n",
        "\n",
        "    \n",
        "    #変形した画像を表示する\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224)])\n",
        "    image_transformed = transform(image)\n",
        "    plt.imshow(np.array(image_transformed))\n",
        "'''\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を表示\n",
        "def image_eval(image_tensor, label):\n",
        "    output = model_ft(image_tensor)\n",
        "    #print(output.size())  # torch.Size([1, 1000])\n",
        "    #print(output)\n",
        "\n",
        "    #model_pred:クラス名前、prob:確率、pred:クラス番号\n",
        "    prob, pred = torch.topk(nn.Softmax(dim=1)(output), 1)\n",
        "    model_pred = class_names[pred]\n",
        "    \n",
        "    #甲状腺眼症のprobabilityを計算（classが0なら1から減算、classが1ならそのまま）\n",
        "    prob = abs(1-float(prob)-float(pred))\n",
        " \n",
        "    return model_pred, prob, pred\n",
        "\n",
        "    \"\"\"\n",
        "    #probalilityを計算する\n",
        "    pred_prob = torch.topk(nn.Softmax(dim=1)(output), 1)[0]\n",
        "    pred_class = torch.topk(nn.Softmax(dim=1)(output), 1)[1]\n",
        "    if pred_class == 1:\n",
        "        pred_prob = pred_prob\n",
        "    elif pred_class == 0:\n",
        "        pred_prob = 1- pred_prob\n",
        "    return(model_pred, pred_prob)  #class_nameの番号で出力される\n",
        "    \"\"\"\n",
        "\n",
        "def showImage(image_path):\n",
        "    #画像のインポート\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    #画像のリサイズ\n",
        "    height = img.shape[0]\n",
        "    width = img.shape[1]\n",
        "    resized_img = cv2.resize(img, (int(width*300/height), 300))\n",
        "    cv2_imshow(resized_img)\n",
        "\n",
        "def calculateAccuracy (TP, TN, FP, FN):\n",
        "    accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "    precision  = TP/(FP + TP)\n",
        "    recall = TP/(TP + FN)\n",
        "    specificity = TN/(FP + TN)\n",
        "    f_value = (2*recall*precision)/(recall+precision)\n",
        "    return(accuracy, precision, recall, specificity, f_value)\n",
        "\n",
        "\"\"\"\n",
        "・True positive (TN)\n",
        "・False positive (FP)\n",
        "・True negative (TN)\n",
        "・False negative (FN)\n",
        "Accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "Precision = TP/(FP + TP) ※positive predictive value\n",
        "Recall = TP/(TP + FN)　※sensitivity\n",
        "Specificity = TN/(FP + TN)\n",
        "F_value = (2RecallPrecision)/(Recall+Precision)\n",
        "\"\"\"\n",
        "\n",
        "def evaluation(model_ft):\n",
        "    #評価モードにする\n",
        "    model_ft.eval()\n",
        "\n",
        "    #testデータセット内のファイル名を取得\n",
        "    image_path = glob.glob(\"/content/drive/My Drive/Grav_bootcamp/Posttrain_250px/*/*\")\n",
        "    #random.shuffle(image_path)  #表示順をランダムにする\n",
        "    print('number of images: ' +str(len(image_path)))\n",
        "\n",
        "\n",
        "    TP, FP, TN, FN, TP, FP, TN, FN = [0,0,0,0,0,0,0,0]\n",
        "    image_name_list = []\n",
        "    label_list = []\n",
        "    model_pred_list = []\n",
        "    hum_pred_list = []\n",
        "\n",
        "    model_pred_class = []\n",
        "    model_pred_prob = []\n",
        "\n",
        "    for i in image_path:\n",
        "          image_name, label = getlabel(i)  #画像の名前とラベルを取得\n",
        "          image_tensor = image_transform(i)  #予測のための画像下処理\n",
        "          model_pred, prob, pred = image_eval(image_tensor, label)  #予測結果を出力   \n",
        "          #print('Image: '+ image_name)\n",
        "          #print('Label: '+ label)\n",
        "          #print('Pred: '+ model_pred)\n",
        "          #showImage(i)  #画像を表示\n",
        "          #print() #空白行を入れる\n",
        "          time.sleep(0.1)\n",
        "\n",
        "          image_name_list.append(image_name)\n",
        "          label_list.append(label)\n",
        "          model_pred_list.append(model_pred)\n",
        "\n",
        "          model_pred_class.append(int(pred))\n",
        "          model_pred_prob.append(float(prob))\n",
        "\n",
        "          if label == class_names[0]:\n",
        "              if model_pred == class_names[0]:\n",
        "                  TN += 1\n",
        "              else:\n",
        "                  FP += 1\n",
        "          elif label == class_names[1]:\n",
        "              if model_pred == class_names[1]:\n",
        "                  TP += 1\n",
        "              else:\n",
        "                  FN += 1     \n",
        "\n",
        "    print(TP, FN, TN, FP)\n",
        "\n",
        "    #Accuracyを計算\n",
        "    accuracy, precision, recall, specificity, f_value = calculateAccuracy (TP, TN, FP, FN)\n",
        "    print('Accuracy: ' + str(accuracy))\n",
        "    print('Precision (positive predictive value): ' + str(precision))\n",
        "    print('Recall (sensitivity): ' + str(recall))\n",
        "    print('Specificity: ' + str(specificity))\n",
        "    print('F_value: ' + str(f_value))\n",
        "\n",
        "    #print(model_pred_class)\n",
        "    #print(model_pred_prob)\n",
        "\n",
        "    return TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, label_list, model_pred_prob\n",
        "\n",
        "\n",
        "def make_csv():\n",
        "    #csvのdata tableを作成\n",
        "    pd.set_option('display.max_rows', 800)  # 省略なしで表示\n",
        "    columns1 = [\"EfficientNet_32\", \"EfficientNet_64\", \"EfficientNet_128\", \"EfficientNet_256\", \"EfficientNet_512\", \"EfficientNet_558\"]\n",
        "    index1 = [\"TP\",\"TN\",\"FP\",\"FN\",\"Accuracy\",\"Positive predictive value\",\"sensitity\",\"specificity\",\"F-value\",\"roc_auc\"]\n",
        "    df = pd.DataFrame(index=index1, columns=columns1)\n",
        "    return df\n",
        "\n",
        "def write_csv(df, col, TP, TN, FP, FN, accuracy, precision, recall, specificity, f_value,roc_auc):\n",
        "    df.iloc[0:10, col] = TP, TN, FP, FN, accuracy, precision, recall, specificity, f_value,roc_auc \n",
        "    #print(df)\n",
        "\n",
        "    # CSVとして出力\n",
        "    #df2.to_csv(\"/content/drive/My Drive/Grav_bootcamp/Posttrain_model_eval_result.csv\",encoding=\"shift_jis\")\n",
        "    return df\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == 'cont':\n",
        "                  y_true.append(0)\n",
        "            elif i == 'grav':\n",
        "                  y_true.append(1)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_auc(label_list, model_pred_prob):\n",
        "    y_true, y_score = [], []\n",
        "    for i in label_list:\n",
        "        if i == 'cont':\n",
        "              y_true.append(0)\n",
        "        elif i == 'grav':\n",
        "              y_true.append(1)\n",
        "            \n",
        "    #それぞれの画像における陽性の確率についてリストを作成\n",
        "    y_score = model_pred_prob\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc: \" +str(roc_auc))\n",
        "    return(roc_auc)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USGfUwQXv6Jc",
        "colab_type": "text"
      },
      "source": [
        "#**まとめて解析**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM2VMXltwBs5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dadc1796539e45fc902be88a25007b74",
            "3145945c6244464b8561b7f2e90d06c2",
            "b77b6b1aa1564111977e11f804168cf7",
            "179f5bb8070f481a969427f0321b42fb",
            "d961bdcd70f742789d2b6d63fd2b7ce9",
            "e6470675c69241b4ba4c36f9ae77589e",
            "1d3f573821f3415cb0705bf4966bb195",
            "38a827321fef4715935b74ec0bfbeac5"
          ]
        },
        "outputId": "8e1f2efa-5392-4537-b27e-12707d1ffa1d"
      },
      "source": [
        "data_dir_list = ['/content/drive/My Drive/Grav_bootcamp/PrePlusTrain_32','/content/drive/My Drive/Grav_bootcamp/PrePlusTrain_64','/content/drive/My Drive/Grav_bootcamp/PrePlusTrain_128','/content/drive/My Drive/Grav_bootcamp/PrePlusTrain_256','/content/drive/My Drive/Grav_bootcamp/PrePlusTrain_512','/content/drive/My Drive/Grav_bootcamp/PrePlusTrain_558']\n",
        "roc_label_list = ['n=32', 'n=64', 'n=128', 'n=256','n=512','n=558']\n",
        "\n",
        "df = make_csv()\n",
        "\n",
        "label_list_list, model_pred_prob_list = [],[]\n",
        "\n",
        "for i, t in enumerate(zip(data_dir_list, roc_label_list)):\n",
        "    image_datasets, dataloaders, dataset_sizes, class_names, device = pre_process(t[0]) #path\n",
        "    inputs, classes = getBatch(dataloaders)\n",
        "    model_ft, criterion, optimizer_ft = convnet()\n",
        "    training(model_ft, criterion, optimizer_ft,  patience=15, num_epochs=50)  \n",
        "    TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, label_list, model_pred_prob = evaluation(model_ft)\n",
        "    roc_auc = calculate_auc(label_list, model_pred_prob)\n",
        "    df = write_csv(df, i,TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, roc_auc) #numberをcsvの行として指定\n",
        "\n",
        "\n",
        "    label_list_list.append(label_list)\n",
        "    model_pred_prob_list.append(model_pred_prob)\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "\n",
        "#Draw ROC curve\n",
        "fig = Draw_roc_curve(label_list_list, model_pred_prob_list, roc_label_list, len(label_list_list))\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns', 100)\n",
        "print(df)\n",
        "\n",
        "\n",
        "# CSVとして出力\n",
        "df.to_csv(\"/content/drive/My Drive/Grav_bootcamp/Posttrain_model_eval_result.csv\",encoding=\"shift_jis\")\n",
        "\n",
        "#ROC_curveを保存\n",
        "fig.savefig(\"/content/drive/My Drive/Grav_bootcamp/img.png\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cont', 'grav']\n",
            "cont_train:12\n",
            "grav_train:12\n",
            "cont_val:4\n",
            "grav_val:4\n",
            "training data set_total：24\n",
            "validating data set_total：8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b4-6ed6700e.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dadc1796539e45fc902be88a25007b74",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=77999237.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded pretrained weights for efficientnet-b4\n",
            "Epoch 0/49\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch_optimizer/adabound.py:142: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.6834 Acc: 0.5417\n",
            "val Loss: 0.6990 Acc: 0.3750\n",
            "Validation loss decreased (inf --> 0.698970).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.5897 Acc: 0.6667\n",
            "val Loss: 0.7139 Acc: 0.5000\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.3848 Acc: 0.8750\n",
            "val Loss: 0.6684 Acc: 0.5000\n",
            "Validation loss decreased (0.698970 --> 0.668445).  Saving model ...\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.3778 Acc: 0.7917\n",
            "val Loss: 0.6322 Acc: 0.5000\n",
            "Validation loss decreased (0.668445 --> 0.632223).  Saving model ...\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.2325 Acc: 0.8333\n",
            "val Loss: 0.6924 Acc: 0.5000\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.1854 Acc: 0.9167\n",
            "val Loss: 0.6622 Acc: 0.6250\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.1240 Acc: 0.9583\n",
            "val Loss: 0.4123 Acc: 0.7500\n",
            "Validation loss decreased (0.632223 --> 0.412318).  Saving model ...\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.1228 Acc: 0.9583\n",
            "val Loss: 0.2881 Acc: 0.8750\n",
            "Validation loss decreased (0.412318 --> 0.288134).  Saving model ...\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.2666 Acc: 0.9167\n",
            "val Loss: 0.2219 Acc: 0.8750\n",
            "Validation loss decreased (0.288134 --> 0.221887).  Saving model ...\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.1727 Acc: 0.9167\n",
            "val Loss: 0.3136 Acc: 0.8750\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0922 Acc: 0.9583\n",
            "val Loss: 0.8395 Acc: 0.6250\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.2554 Acc: 0.9167\n",
            "val Loss: 1.6733 Acc: 0.5000\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.1287 Acc: 0.9583\n",
            "val Loss: 2.2432 Acc: 0.5000\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.1885 Acc: 0.9167\n",
            "val Loss: 1.9642 Acc: 0.5000\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0600 Acc: 1.0000\n",
            "val Loss: 1.2480 Acc: 0.5000\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0521 Acc: 1.0000\n",
            "val Loss: 0.9036 Acc: 0.5000\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.1021 Acc: 1.0000\n",
            "val Loss: 0.7694 Acc: 0.6250\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.2781 Acc: 0.9167\n",
            "val Loss: 0.6357 Acc: 0.6250\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.0514 Acc: 1.0000\n",
            "val Loss: 0.5429 Acc: 0.8750\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0891 Acc: 1.0000\n",
            "val Loss: 0.5968 Acc: 0.7500\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.1233 Acc: 0.9583\n",
            "val Loss: 0.6475 Acc: 0.6250\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.1042 Acc: 1.0000\n",
            "val Loss: 0.6393 Acc: 0.6250\n",
            "EarlyStopping counter: 13 out of 15\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.0918 Acc: 1.0000\n",
            "val Loss: 0.4805 Acc: 0.8750\n",
            "EarlyStopping counter: 14 out of 15\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.0745 Acc: 1.0000\n",
            "val Loss: 0.4264 Acc: 0.7500\n",
            "EarlyStopping counter: 15 out of 15\n",
            "Early stopping\n",
            "Training complete in 0m 29s\n",
            "Best val Acc: 0.875000\n",
            "number of images: 108\n",
            "31 23 32 22\n",
            "Accuracy: 0.5833333333333334\n",
            "Precision (positive predictive value): 0.5849056603773585\n",
            "Recall (sensitivity): 0.5740740740740741\n",
            "Specificity: 0.5925925925925926\n",
            "F_value: 0.5794392523364486\n",
            "roc_auc: 0.6327160493827162\n",
            "\n",
            "\n",
            "['cont', 'grav']\n",
            "cont_train:25\n",
            "grav_train:25\n",
            "cont_val:7\n",
            "grav_val:7\n",
            "training data set_total：50\n",
            "validating data set_total：14\n",
            "Loaded pretrained weights for efficientnet-b4\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.6489 Acc: 0.6200\n",
            "val Loss: 0.7180 Acc: 0.5000\n",
            "Validation loss decreased (inf --> 0.717972).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.4191 Acc: 0.8600\n",
            "val Loss: 0.7196 Acc: 0.5714\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.1482 Acc: 0.9800\n",
            "val Loss: 1.3428 Acc: 0.5000\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.1619 Acc: 0.9200\n",
            "val Loss: 3.0163 Acc: 0.5000\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.0947 Acc: 0.9600\n",
            "val Loss: 3.1284 Acc: 0.5000\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.2523 Acc: 0.9600\n",
            "val Loss: 3.1636 Acc: 0.4286\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.1823 Acc: 0.9200\n",
            "val Loss: 2.0247 Acc: 0.5000\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.0896 Acc: 0.9600\n",
            "val Loss: 1.3992 Acc: 0.5714\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.1999 Acc: 0.9000\n",
            "val Loss: 1.8524 Acc: 0.4286\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.1087 Acc: 0.9600\n",
            "val Loss: 2.2360 Acc: 0.4286\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.1041 Acc: 0.9800\n",
            "val Loss: 2.0707 Acc: 0.5000\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.2290 Acc: 0.9000\n",
            "val Loss: 1.6115 Acc: 0.5000\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.0497 Acc: 0.9800\n",
            "val Loss: 1.8768 Acc: 0.6429\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0583 Acc: 0.9800\n",
            "val Loss: 3.3238 Acc: 0.6429\n",
            "EarlyStopping counter: 13 out of 15\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0688 Acc: 1.0000\n",
            "val Loss: 3.0978 Acc: 0.6429\n",
            "EarlyStopping counter: 14 out of 15\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0632 Acc: 0.9600\n",
            "val Loss: 2.3455 Acc: 0.7143\n",
            "EarlyStopping counter: 15 out of 15\n",
            "Early stopping\n",
            "Training complete in 0m 26s\n",
            "Best val Acc: 0.714286\n",
            "number of images: 108\n",
            "26 28 43 11\n",
            "Accuracy: 0.6388888888888888\n",
            "Precision (positive predictive value): 0.7027027027027027\n",
            "Recall (sensitivity): 0.48148148148148145\n",
            "Specificity: 0.7962962962962963\n",
            "F_value: 0.5714285714285714\n",
            "roc_auc: 0.7066186556927299\n",
            "\n",
            "\n",
            "['cont', 'grav']\n",
            "cont_train:51\n",
            "grav_train:51\n",
            "cont_val:13\n",
            "grav_val:13\n",
            "training data set_total：102\n",
            "validating data set_total：26\n",
            "Loaded pretrained weights for efficientnet-b4\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.6759 Acc: 0.5588\n",
            "val Loss: 0.6554 Acc: 0.6538\n",
            "Validation loss decreased (inf --> 0.655449).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.3723 Acc: 0.8824\n",
            "val Loss: 0.6027 Acc: 0.6923\n",
            "Validation loss decreased (0.655449 --> 0.602685).  Saving model ...\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.3225 Acc: 0.8725\n",
            "val Loss: 1.3253 Acc: 0.5000\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.3621 Acc: 0.8235\n",
            "val Loss: 0.7019 Acc: 0.4231\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.3106 Acc: 0.9020\n",
            "val Loss: 1.1257 Acc: 0.7692\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.1895 Acc: 0.9314\n",
            "val Loss: 2.3782 Acc: 0.6923\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.1805 Acc: 0.9412\n",
            "val Loss: 3.0003 Acc: 0.5769\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.1151 Acc: 0.9706\n",
            "val Loss: 2.6983 Acc: 0.5769\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.1012 Acc: 0.9706\n",
            "val Loss: 1.5160 Acc: 0.6538\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.0644 Acc: 0.9804\n",
            "val Loss: 4.4682 Acc: 0.5769\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.2793 Acc: 0.9216\n",
            "val Loss: 5.4544 Acc: 0.5000\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.1429 Acc: 0.9706\n",
            "val Loss: 3.7408 Acc: 0.5385\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.2561 Acc: 0.9412\n",
            "val Loss: 1.8353 Acc: 0.5769\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.3134 Acc: 0.9216\n",
            "val Loss: 0.7858 Acc: 0.7308\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.1642 Acc: 0.9608\n",
            "val Loss: 1.2867 Acc: 0.6538\n",
            "EarlyStopping counter: 13 out of 15\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.1232 Acc: 0.9706\n",
            "val Loss: 1.3888 Acc: 0.6154\n",
            "EarlyStopping counter: 14 out of 15\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.1192 Acc: 0.9706\n",
            "val Loss: 1.3901 Acc: 0.6154\n",
            "EarlyStopping counter: 15 out of 15\n",
            "Early stopping\n",
            "Training complete in 0m 46s\n",
            "Best val Acc: 0.769231\n",
            "number of images: 108\n",
            "28 26 53 1\n",
            "Accuracy: 0.75\n",
            "Precision (positive predictive value): 0.9655172413793104\n",
            "Recall (sensitivity): 0.5185185185185185\n",
            "Specificity: 0.9814814814814815\n",
            "F_value: 0.6746987951807228\n",
            "roc_auc: 0.855281207133059\n",
            "\n",
            "\n",
            "['cont', 'grav']\n",
            "cont_train:102\n",
            "grav_train:102\n",
            "cont_val:26\n",
            "grav_val:26\n",
            "training data set_total：204\n",
            "validating data set_total：52\n",
            "Loaded pretrained weights for efficientnet-b4\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.6896 Acc: 0.6078\n",
            "val Loss: 0.6503 Acc: 0.6154\n",
            "Validation loss decreased (inf --> 0.650251).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.4512 Acc: 0.7745\n",
            "val Loss: 1.4942 Acc: 0.5192\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.4025 Acc: 0.8529\n",
            "val Loss: 0.4142 Acc: 0.8077\n",
            "Validation loss decreased (0.650251 --> 0.414158).  Saving model ...\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.3272 Acc: 0.8775\n",
            "val Loss: 0.8384 Acc: 0.6538\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.3041 Acc: 0.8775\n",
            "val Loss: 0.2575 Acc: 0.9038\n",
            "Validation loss decreased (0.414158 --> 0.257508).  Saving model ...\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.2357 Acc: 0.8922\n",
            "val Loss: 0.7914 Acc: 0.7885\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.1421 Acc: 0.9412\n",
            "val Loss: 1.2466 Acc: 0.8269\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.2661 Acc: 0.9069\n",
            "val Loss: 2.1527 Acc: 0.6154\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.2828 Acc: 0.9020\n",
            "val Loss: 0.6097 Acc: 0.8269\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.2263 Acc: 0.9265\n",
            "val Loss: 0.8203 Acc: 0.7500\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.1585 Acc: 0.9461\n",
            "val Loss: 0.5777 Acc: 0.8654\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0862 Acc: 0.9755\n",
            "val Loss: 0.6304 Acc: 0.8654\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.0763 Acc: 0.9804\n",
            "val Loss: 1.1085 Acc: 0.8077\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0971 Acc: 0.9804\n",
            "val Loss: 1.4263 Acc: 0.7692\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.1248 Acc: 0.9559\n",
            "val Loss: 1.4039 Acc: 0.7885\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.1493 Acc: 0.9461\n",
            "val Loss: 0.9225 Acc: 0.8077\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0691 Acc: 0.9706\n",
            "val Loss: 0.8033 Acc: 0.8077\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0706 Acc: 0.9706\n",
            "val Loss: 0.6800 Acc: 0.7885\n",
            "EarlyStopping counter: 13 out of 15\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.1491 Acc: 0.9363\n",
            "val Loss: 0.6571 Acc: 0.8269\n",
            "EarlyStopping counter: 14 out of 15\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.1173 Acc: 0.9657\n",
            "val Loss: 0.7746 Acc: 0.7500\n",
            "EarlyStopping counter: 15 out of 15\n",
            "Early stopping\n",
            "Training complete in 1m 32s\n",
            "Best val Acc: 0.903846\n",
            "number of images: 108\n",
            "39 15 50 4\n",
            "Accuracy: 0.8240740740740741\n",
            "Precision (positive predictive value): 0.9069767441860465\n",
            "Recall (sensitivity): 0.7222222222222222\n",
            "Specificity: 0.9259259259259259\n",
            "F_value: 0.8041237113402061\n",
            "roc_auc: 0.8700274348422496\n",
            "\n",
            "\n",
            "['cont', 'grav']\n",
            "cont_train:204\n",
            "grav_train:204\n",
            "cont_val:52\n",
            "grav_val:52\n",
            "training data set_total：408\n",
            "validating data set_total：104\n",
            "Loaded pretrained weights for efficientnet-b4\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.6029 Acc: 0.6985\n",
            "val Loss: 1.1531 Acc: 0.5673\n",
            "Validation loss decreased (inf --> 1.153142).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.4445 Acc: 0.7990\n",
            "val Loss: 0.4922 Acc: 0.7981\n",
            "Validation loss decreased (1.153142 --> 0.492194).  Saving model ...\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.3691 Acc: 0.8333\n",
            "val Loss: 2.7876 Acc: 0.7692\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.2185 Acc: 0.9044\n",
            "val Loss: 0.7510 Acc: 0.7885\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.1952 Acc: 0.9314\n",
            "val Loss: 0.7172 Acc: 0.7500\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.1799 Acc: 0.9216\n",
            "val Loss: 0.8565 Acc: 0.6923\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.1285 Acc: 0.9534\n",
            "val Loss: 0.7406 Acc: 0.7115\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.1568 Acc: 0.9461\n",
            "val Loss: 1.0232 Acc: 0.6635\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.1285 Acc: 0.9559\n",
            "val Loss: 1.9362 Acc: 0.7019\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.1013 Acc: 0.9559\n",
            "val Loss: 0.8186 Acc: 0.7692\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.1129 Acc: 0.9632\n",
            "val Loss: 1.0251 Acc: 0.7500\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.1013 Acc: 0.9583\n",
            "val Loss: 1.1613 Acc: 0.7308\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.0707 Acc: 0.9755\n",
            "val Loss: 0.8191 Acc: 0.7308\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0532 Acc: 0.9779\n",
            "val Loss: 1.0077 Acc: 0.7212\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0244 Acc: 0.9926\n",
            "val Loss: 0.8781 Acc: 0.7981\n",
            "EarlyStopping counter: 13 out of 15\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0091 Acc: 1.0000\n",
            "val Loss: 0.9495 Acc: 0.8077\n",
            "EarlyStopping counter: 14 out of 15\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0266 Acc: 0.9877\n",
            "val Loss: 0.9057 Acc: 0.7788\n",
            "EarlyStopping counter: 15 out of 15\n",
            "Early stopping\n",
            "Training complete in 2m 23s\n",
            "Best val Acc: 0.807692\n",
            "number of images: 108\n",
            "45 9 42 12\n",
            "Accuracy: 0.8055555555555556\n",
            "Precision (positive predictive value): 0.7894736842105263\n",
            "Recall (sensitivity): 0.8333333333333334\n",
            "Specificity: 0.7777777777777778\n",
            "F_value: 0.8108108108108109\n",
            "roc_auc: 0.8954046639231824\n",
            "\n",
            "\n",
            "['cont', 'grav']\n",
            "cont_train:223\n",
            "grav_train:223\n",
            "cont_val:56\n",
            "grav_val:56\n",
            "training data set_total：446\n",
            "validating data set_total：112\n",
            "Loaded pretrained weights for efficientnet-b4\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.5965 Acc: 0.6749\n",
            "val Loss: 0.4828 Acc: 0.7857\n",
            "Validation loss decreased (inf --> 0.482834).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.3981 Acc: 0.8386\n",
            "val Loss: 0.7558 Acc: 0.7321\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.3131 Acc: 0.8587\n",
            "val Loss: 0.7391 Acc: 0.7857\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.3384 Acc: 0.8700\n",
            "val Loss: 0.5187 Acc: 0.8393\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.2836 Acc: 0.8924\n",
            "val Loss: 1.1219 Acc: 0.7946\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.1766 Acc: 0.9417\n",
            "val Loss: 0.7530 Acc: 0.8125\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.0964 Acc: 0.9641\n",
            "val Loss: 0.7409 Acc: 0.7946\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.2483 Acc: 0.9103\n",
            "val Loss: 1.4126 Acc: 0.7232\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.1268 Acc: 0.9507\n",
            "val Loss: 1.4612 Acc: 0.7768\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.0690 Acc: 0.9753\n",
            "val Loss: 0.6117 Acc: 0.8393\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0899 Acc: 0.9798\n",
            "val Loss: 1.1752 Acc: 0.7679\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0890 Acc: 0.9686\n",
            "val Loss: 0.6029 Acc: 0.7500\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.0727 Acc: 0.9731\n",
            "val Loss: 0.3709 Acc: 0.8750\n",
            "Validation loss decreased (0.482834 --> 0.370870).  Saving model ...\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0905 Acc: 0.9753\n",
            "val Loss: 0.4709 Acc: 0.8304\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.1076 Acc: 0.9596\n",
            "val Loss: 0.5603 Acc: 0.7857\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0518 Acc: 0.9821\n",
            "val Loss: 0.6128 Acc: 0.7857\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0493 Acc: 0.9910\n",
            "val Loss: 0.6438 Acc: 0.7946\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0344 Acc: 0.9910\n",
            "val Loss: 0.6102 Acc: 0.8304\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.0294 Acc: 0.9888\n",
            "val Loss: 0.5995 Acc: 0.8214\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0403 Acc: 0.9888\n",
            "val Loss: 0.9016 Acc: 0.7232\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.0184 Acc: 0.9955\n",
            "val Loss: 0.8271 Acc: 0.8036\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.0153 Acc: 0.9933\n",
            "val Loss: 0.9267 Acc: 0.7946\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.0224 Acc: 0.9888\n",
            "val Loss: 0.6460 Acc: 0.8482\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.0156 Acc: 0.9910\n",
            "val Loss: 0.7498 Acc: 0.8214\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.0049 Acc: 1.0000\n",
            "val Loss: 0.5786 Acc: 0.8571\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.0045 Acc: 1.0000\n",
            "val Loss: 0.6444 Acc: 0.8482\n",
            "EarlyStopping counter: 13 out of 15\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.0240 Acc: 0.9933\n",
            "val Loss: 1.0655 Acc: 0.7679\n",
            "EarlyStopping counter: 14 out of 15\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.0308 Acc: 0.9865\n",
            "val Loss: 0.9163 Acc: 0.7946\n",
            "EarlyStopping counter: 15 out of 15\n",
            "Early stopping\n",
            "Training complete in 4m 7s\n",
            "Best val Acc: 0.875000\n",
            "number of images: 108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "44 10 46 8\n",
            "Accuracy: 0.8333333333333334\n",
            "Precision (positive predictive value): 0.8461538461538461\n",
            "Recall (sensitivity): 0.8148148148148148\n",
            "Specificity: 0.8518518518518519\n",
            "F_value: 0.830188679245283\n",
            "roc_auc: 0.913923182441701\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "                          EfficientNet_32 EfficientNet_64 EfficientNet_128  \\\n",
            "TP                                     31              26               28   \n",
            "TN                                     32              43               53   \n",
            "FP                                     22              11                1   \n",
            "FN                                     23              28               26   \n",
            "Accuracy                         0.583333        0.638889             0.75   \n",
            "Positive predictive value        0.584906        0.702703         0.965517   \n",
            "sensitity                        0.574074        0.481481         0.518519   \n",
            "specificity                      0.592593        0.796296         0.981481   \n",
            "F-value                          0.579439        0.571429         0.674699   \n",
            "roc_auc                          0.632716        0.706619         0.855281   \n",
            "\n",
            "                          EfficientNet_256 EfficientNet_512 EfficientNet_558  \n",
            "TP                                      39               45               44  \n",
            "TN                                      50               42               46  \n",
            "FP                                       4               12                8  \n",
            "FN                                      15                9               10  \n",
            "Accuracy                          0.824074         0.805556         0.833333  \n",
            "Positive predictive value         0.906977         0.789474         0.846154  \n",
            "sensitity                         0.722222         0.833333         0.814815  \n",
            "specificity                       0.925926         0.777778         0.851852  \n",
            "F-value                           0.804124         0.810811         0.830189  \n",
            "roc_auc                           0.870027         0.895405         0.913923  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPO-b2cAT0yF",
        "colab_type": "text"
      },
      "source": [
        "#**ネットワークの保存と読み込み**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMYyFQ6ATzyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ネットワークの保存\n",
        "PATH = '/content/drive/My Drive/Grav_bootcamp/GravCont_EfficientNet-b4_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "torch.save(model_ft.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c744XUtfT6xW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73a923de-e875-4e71-b4b5-1ae266557981"
      },
      "source": [
        "#ネットワークの読み込み\n",
        "PATH = '/content/drive/My Drive/Grav_bootcamp/GravCont_EfficientNet-b4_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "torch.save(model_ft.state_dict(), PATH)\n",
        "model_ft.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}