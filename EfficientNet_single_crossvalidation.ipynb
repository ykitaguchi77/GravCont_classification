{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled71.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO7UqWwoDNhSdmiKcr7Ruqp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/EfficientNet_single_crossvalidation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XH0N7e0Y8Ou",
        "outputId": "2546bcf6-54ec-479f-89dd-5dedf6006783"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnJHyFPBhEAN"
      },
      "source": [
        "#**Evaluator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTp1hx1bhCm4"
      },
      "source": [
        "import os\r\n",
        "import random\r\n",
        "import glob\r\n",
        "import torch\r\n",
        "from PIL import Image\r\n",
        "from sklearn.metrics import roc_curve, auc\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "class Evaluator:\r\n",
        "    def __init__(self, model, classes, val_folder_path, val_transform, device, print_round_num=2) -> None:\r\n",
        "        super().__init__()\r\n",
        "        self.model = model\r\n",
        "        self.val_folder_path = val_folder_path\r\n",
        "        self.val_transform = val_transform\r\n",
        "        self.device = device\r\n",
        "        self.print_round_num = print_round_num\r\n",
        "\r\n",
        "        self.class_names = classes\r\n",
        "        self.image_paths = glob.glob(self.val_folder_path + \"/*/*\")\r\n",
        "        print('eval number of classes: ' +str(len(self.class_names)))\r\n",
        "        print('eval number of images: ' +str(len(self.image_paths)))\r\n",
        "        random.shuffle(self.image_paths) \r\n",
        "\r\n",
        "        self.max_accuracy = 0\r\n",
        "        # to update self.max_accuracy\r\n",
        "        self.evaluate()\r\n",
        "        print(\"initial accuracy: \" + str(self.max_accuracy))\r\n",
        "\r\n",
        "    def evaluate(self):\r\n",
        "        TP = FP = TN = FN = TP = FP = TN = FN = 0\r\n",
        "        image_name_list = []\r\n",
        "        label_list = []\r\n",
        "        model_pred_list = []\r\n",
        "\r\n",
        "        model_pred_class = []\r\n",
        "        model_pred_prob = []\r\n",
        "\r\n",
        "        for image_path in self.image_paths:\r\n",
        "            image_name, label = self.get_label(image_path)\r\n",
        "            image_tensor = self.get_image_tensor(image_path)\r\n",
        "\r\n",
        "            is_training = self.model.training\r\n",
        "            self.model.eval()\r\n",
        "            with torch.no_grad():\r\n",
        "                output = self.model(image_tensor)\r\n",
        "            if is_training:\r\n",
        "                self.model.train()\r\n",
        "                          \r\n",
        "            #model_pred:クラス名前、prob:確率、pred:クラス番号\r\n",
        "            prob, pred = torch.topk(torch.nn.Softmax(dim=1)(output), 1)\r\n",
        "            model_pred = self.class_names[pred]\r\n",
        "            #甲状腺眼症のprobabilityを計算（classが0なら1から減算、classが1ならそのまま）\r\n",
        "            prob = abs(1-float(prob)-float(pred))\r\n",
        "            \r\n",
        "            image_name_list.append(image_name)\r\n",
        "            label_list.append(label)\r\n",
        "            model_pred_list.append(model_pred)\r\n",
        "\r\n",
        "            model_pred_class.append(int(pred))\r\n",
        "            model_pred_prob.append(float(prob))\r\n",
        "\r\n",
        "            if label == self.class_names[0]:\r\n",
        "                if model_pred == self.class_names[0]:\r\n",
        "                    TN += 1\r\n",
        "                else:\r\n",
        "                    FP += 1\r\n",
        "            elif label == self.class_names[1]:\r\n",
        "                if model_pred == self.class_names[1]:\r\n",
        "                    TP += 1\r\n",
        "                else:\r\n",
        "                    FN += 1\r\n",
        "\r\n",
        "        accuracy, precision, recall, specificity, f_value = self.calculate_accuracy(TP, TN, FP, FN)\r\n",
        "        is_best = self.max_accuracy < accuracy\r\n",
        "        if is_best:\r\n",
        "            self.max_accuracy = accuracy\r\n",
        "\r\n",
        "        return is_best, (round(accuracy, self.print_round_num), \r\n",
        "            round(precision, self.print_round_num), \r\n",
        "            round(recall, self.print_round_num), \r\n",
        "            round(specificity, self.print_round_num), \r\n",
        "            round(f_value, self.print_round_num))\r\n",
        "        \r\n",
        "    def draw_roc(self, output_path):\r\n",
        "        label_list = []\r\n",
        "        model_pred_prob = []\r\n",
        "\r\n",
        "        for image_path in self.image_paths:\r\n",
        "            image_name, label = self.get_label(image_path)\r\n",
        "            image_tensor = self.get_image_tensor(image_path)\r\n",
        "\r\n",
        "            is_training = self.model.training\r\n",
        "            self.model.eval()\r\n",
        "            with torch.no_grad():\r\n",
        "                output = self.model(image_tensor)\r\n",
        "            if is_training:\r\n",
        "                self.model.train()\r\n",
        "                \r\n",
        "            #model_pred:クラス名前、prob:確率、pred:クラス番号\r\n",
        "            prob, pred = torch.topk(torch.nn.Softmax(dim=1)(output), 1)\r\n",
        "            #甲状腺眼症のprobabilityを計算（classが0なら1から減算、classが1ならそのまま）\r\n",
        "            prob = abs(1-float(prob)-float(pred))\r\n",
        "\r\n",
        "            label_list.append(label)\r\n",
        "            model_pred_prob.append(float(prob))\r\n",
        "\r\n",
        "        y_score = []\r\n",
        "        y_true = []\r\n",
        "\r\n",
        "        k=0\r\n",
        "        for i in label_list:\r\n",
        "            if label_list[k] == 'cont':\r\n",
        "                y_true.append(0)\r\n",
        "            elif label_list[k] == 'grav':\r\n",
        "                y_true.append(1)\r\n",
        "            k+=1\r\n",
        "\r\n",
        "        #健康な状態を「0」、病気を「1」としてラベルよりリストを作成\r\n",
        "        y_true = y_true\r\n",
        "        #それぞれの画像における陽性の確率についてリストを作成\r\n",
        "        y_score = model_pred_prob\r\n",
        "\r\n",
        "        fpr, tpr, thred = roc_curve(y_true, y_score)\r\n",
        "        roc_auc = auc(fpr, tpr)\r\n",
        "\r\n",
        "        plt.figure()\r\n",
        "        lw = 2\r\n",
        "        plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\r\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\r\n",
        "        plt.xlabel('False Positive Rate')\r\n",
        "        plt.ylabel('True Positive Rate')\r\n",
        "        plt.title('Receiver operating characteristic example')\r\n",
        "        plt.legend(loc=\"lower right\")\r\n",
        "        plt.savefig(output_path)\r\n",
        "\r\n",
        "    #対象のパスからラベルを抜き出す\r\n",
        "    def get_label(self, image_path):\r\n",
        "        image_name = os.path.basename(image_path)\r\n",
        "        label = os.path.basename(os.path.dirname(image_path))\r\n",
        "        return(image_name, label)\r\n",
        "\r\n",
        "    def get_image_tensor(self, image_path):    \r\n",
        "        image = Image.open(image_path).convert(\"RGB\")\r\n",
        "        image_tensor = self.val_transform(image)\r\n",
        "        image_tensor.unsqueeze_(0)\r\n",
        "        image_tensor = image_tensor.to(self.device) \r\n",
        "        return(image_tensor)\r\n",
        "        \r\n",
        "    def calculate_accuracy(self, TP, TN, FP, FN):\r\n",
        "        try:\r\n",
        "            accuracy = (TP + TN)/ (TP + TN + FP + FN)\r\n",
        "            precision  = TP/(FP + TP)\r\n",
        "            recall = TP/(TP + FN)\r\n",
        "            specificity = TN/(FP + TN)\r\n",
        "            f_value = (2*recall*precision)/(recall+precision)\r\n",
        "        except:\r\n",
        "            accuracy = -1\r\n",
        "            precision  = -1\r\n",
        "            recall = -1\r\n",
        "            specificity = -1\r\n",
        "            f_value = -1\r\n",
        "        return(accuracy, precision, recall, specificity, f_value)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvbamPHehLtt"
      },
      "source": [
        "#**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4FcKHIfNvOR",
        "outputId": "b9c08825-b4c4-4588-b36c-81084726ec7c"
      },
      "source": [
        "##########\n",
        "# Usage\n",
        "#   python train_grav.py\n",
        "##########\n",
        "# ├─gravcont_250px\n",
        "# │   ├─train\n",
        "# │   │  ├─cont\n",
        "# │   │  └─grav\n",
        "# │   └─val\n",
        "# │       ├─cont\n",
        "# │       └─grav\n",
        "# ├──train_grav.py\n",
        "# └──evaluator_grav.py\n",
        "\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from efficientnet_pytorch import EfficientNet \n",
        "\n",
        "# change working directory\n",
        "path = '/content/drive/MyDrive/Deep_learning/666mai_dataset'\n",
        "os.chdir(path)\n",
        "\n",
        "# grav or cont\n",
        "NUM_CLASSES = 2\n",
        "# contains train, val\n",
        "DATASET_PATH = r\"./crossvalidation_250px/0/\"\n",
        "TEST_PATH = r\"./crossvalidation_250px/test/\"\n",
        "TRAIN_FOLDER_NAME = \"train\"\n",
        "VAL_FOLDER_NAME = \"val\"\n",
        "EFFICIENT_NET_NAME = \"efficientnet-b0\"\n",
        "MODEL_PATH = \"./model.pth\"\n",
        "OPTIMIZER_PATH = \"./optimizer.pth\"\n",
        "LOG_PATH = \"./log.txt\"\n",
        "ROC_PATH = \"./roc.png\"\n",
        "CHECKPOINT_COUNT = 10\n",
        "EPOCH = 100\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# transforms param\n",
        "PX = 224\n",
        "TRAIN_NORMALIZE_PARAM = [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]\n",
        "TRAIN_CROP_SCALE =(0.75,1.0)\n",
        "TRAIN_BRIGHTNESS_PARAM = 0.2\n",
        "TRAIN_CONTRAST_PARAM = 0.1\n",
        "TRAIN_SATURATION_PARAM = 0.1\n",
        "TRAIN_HUE_PARAM = 0.02\n",
        "VAL_NORMALIZE_PARAM = [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]\n",
        "VAL_CROP_SCALE =(0.75,1.0)\n",
        "\n",
        "#######\n",
        "# Set random seem for reproducibility\n",
        "manualSeed = 1234\n",
        "# print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.cuda.manual_seed(manualSeed)\n",
        "#######\n",
        "\n",
        "torch.torch.backends.cudnn.benchmark = True\n",
        "torch.torch.backends.cudnn.enabled = True\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def get_dataloader(root, name, transform, batch_size=BATCH_SIZE, shuffle=True):\n",
        "        dataset = datasets.ImageFolder(os.path.join(root,name), transform=transform)\n",
        "        dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = shuffle)\n",
        "        print(name + \"_dataset_size：\"+str(len(dataset)))\n",
        "        return dataloader\n",
        "        \n",
        "if __name__ == \"__main__\":\n",
        "        if os.path.exists(MODEL_PATH):\n",
        "                model = EfficientNet.from_pretrained(EFFICIENT_NET_NAME, MODEL_PATH, num_classes=NUM_CLASSES)\n",
        "        else:\n",
        "                model = EfficientNet.from_pretrained(EFFICIENT_NET_NAME, num_classes=NUM_CLASSES)\n",
        "        model.train()\n",
        "        model.to(device)\n",
        "\n",
        "        # transforms自体を定数として上に記述しても良いかもしれません\n",
        "        train_data_transforms = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ColorJitter(brightness=TRAIN_BRIGHTNESS_PARAM, contrast=TRAIN_CONTRAST_PARAM,\n",
        "                 saturation=TRAIN_SATURATION_PARAM, hue=TRAIN_HUE_PARAM),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(TRAIN_NORMALIZE_PARAM[0], TRAIN_NORMALIZE_PARAM[1])])\n",
        "        val_data_transforms = transforms.Compose([\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(VAL_NORMALIZE_PARAM[0], VAL_NORMALIZE_PARAM[1])])                \n",
        "        train_dataloader = get_dataloader(DATASET_PATH, TRAIN_FOLDER_NAME, train_data_transforms)\n",
        "\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), 0.0002)\n",
        "        if os.path.exists(OPTIMIZER_PATH):\n",
        "                optimizer.load_state_dict(torch.load(OPTIMIZER_PATH))\n",
        "\n",
        "        loss_func = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        val_folder_path = os.path.join(DATASET_PATH, VAL_FOLDER_NAME)\n",
        "        evaluator = Evaluator(model, train_dataloader.dataset.classes, val_folder_path, val_data_transforms, device)\n",
        "        evaluator.draw_roc(ROC_PATH)\n",
        "\n",
        "        for epoch in range(EPOCH):\n",
        "                for (i, batch) in enumerate(train_dataloader):\n",
        "                        optimizer.zero_grad()\n",
        "\n",
        "                        inputs, labels = batch\n",
        "                        inputs = inputs.to(device)\n",
        "                        labels = labels.to(device)\n",
        "\n",
        "                        outputs = model(inputs)\n",
        "\n",
        "                        loss = loss_func(outputs, labels)\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                        if i % CHECKPOINT_COUNT == 0:\n",
        "                                is_best, score = evaluator.evaluate()\n",
        "                                if is_best:\n",
        "                                        evaluator.draw_roc(ROC_PATH)\n",
        "                                        torch.save(model.state_dict(), MODEL_PATH)\n",
        "                                        torch.save(optimizer.state_dict(), OPTIMIZER_PATH)\n",
        "\n",
        "                                # write log to file\n",
        "                                with open(LOG_PATH, 'a') as f:\n",
        "                                        f.write(\"-----\")\n",
        "                                        f.write(\"\\n\")\n",
        "                                        f.write(\"batch_size: \" + str(BATCH_SIZE))\n",
        "                                        f.write(\"\\n\")\n",
        "                                        f.write(\"iter: \" + str(epoch * len(train_dataloader) + i))\n",
        "                                        f.write(str(score))\n",
        "                                        f.write(\"\\n\")\n",
        "\n",
        "                                # print log\n",
        "                                print(\"-----\")\n",
        "                                print(score)\n",
        "                                print(\"max_accuracy: \" + str(evaluator.max_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n",
            "train_dataset_size：464\n",
            "eval number of classes: 2\n",
            "eval number of images: 116\n",
            "initial accuracy: 0.5\n",
            "-----\n",
            "(0.53, 0.51, 0.98, 0.07, 0.67)\n",
            "max_accuracy: 0.5258620689655172\n",
            "-----\n",
            "(0.53, 0.52, 0.98, 0.09, 0.68)\n",
            "max_accuracy: 0.5344827586206896\n",
            "-----\n",
            "(0.53, 0.51, 0.97, 0.09, 0.67)\n",
            "max_accuracy: 0.5344827586206896\n",
            "-----\n",
            "(0.52, 0.51, 0.93, 0.1, 0.66)\n",
            "max_accuracy: 0.5344827586206896\n",
            "-----\n",
            "(0.66, 0.62, 0.84, 0.48, 0.72)\n",
            "max_accuracy: 0.6637931034482759\n",
            "-----\n",
            "(0.7, 0.68, 0.76, 0.64, 0.72)\n",
            "max_accuracy: 0.6982758620689655\n",
            "-----\n",
            "(0.73, 0.69, 0.84, 0.62, 0.76)\n",
            "max_accuracy: 0.7327586206896551\n",
            "-----\n",
            "(0.72, 0.67, 0.84, 0.59, 0.75)\n",
            "max_accuracy: 0.7327586206896551\n",
            "-----\n",
            "(0.73, 0.7, 0.83, 0.64, 0.76)\n",
            "max_accuracy: 0.7327586206896551\n",
            "-----\n",
            "(0.75, 0.72, 0.81, 0.69, 0.76)\n",
            "max_accuracy: 0.75\n",
            "-----\n",
            "(0.78, 0.81, 0.74, 0.83, 0.77)\n",
            "max_accuracy: 0.7844827586206896\n",
            "-----\n",
            "(0.74, 0.89, 0.55, 0.93, 0.68)\n",
            "max_accuracy: 0.7844827586206896\n",
            "-----\n",
            "(0.72, 0.9, 0.48, 0.95, 0.63)\n",
            "max_accuracy: 0.7844827586206896\n",
            "-----\n",
            "(0.75, 0.91, 0.55, 0.95, 0.69)\n",
            "max_accuracy: 0.7844827586206896\n",
            "-----\n",
            "(0.73, 0.89, 0.53, 0.93, 0.67)\n",
            "max_accuracy: 0.7844827586206896\n",
            "-----\n",
            "(0.72, 0.91, 0.5, 0.95, 0.64)\n",
            "max_accuracy: 0.7844827586206896\n",
            "-----\n",
            "(0.78, 0.85, 0.69, 0.88, 0.76)\n",
            "max_accuracy: 0.7844827586206896\n",
            "-----\n",
            "(0.79, 0.77, 0.84, 0.74, 0.8)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.73, 0.79, 0.64, 0.83, 0.7)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.74, 0.79, 0.66, 0.83, 0.72)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.78, 0.74, 0.86, 0.69, 0.79)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.73, 0.86, 0.55, 0.91, 0.67)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.71, 0.93, 0.45, 0.97, 0.6)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.71, 0.83, 0.52, 0.9, 0.64)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.71, 0.79, 0.57, 0.84, 0.66)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.69, 0.68, 0.72, 0.66, 0.7)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.74, 0.73, 0.78, 0.71, 0.75)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.78, 0.81, 0.72, 0.83, 0.76)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.76, 0.66, 0.79, 0.7)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.75, 0.66, 0.78, 0.7)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.77, 0.64, 0.81, 0.7)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.76, 0.64, 0.79, 0.69)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.69, 0.72, 0.62, 0.76, 0.67)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.64, 0.64, 0.64, 0.64, 0.64)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.7, 0.73, 0.64, 0.76, 0.68)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.73, 0.8, 0.62, 0.84, 0.7)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.73, 0.75, 0.69, 0.78, 0.72)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.74, 0.85, 0.59, 0.9, 0.69)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.7, 0.83, 0.5, 0.9, 0.62)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.82, 0.55, 0.88, 0.66)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.73, 0.83, 0.59, 0.88, 0.69)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.67, 0.7, 0.6, 0.74, 0.65)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.78, 0.62, 0.83, 0.69)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.75, 0.81, 0.66, 0.84, 0.72)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.74, 0.77, 0.69, 0.79, 0.73)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.74, 0.78, 0.67, 0.81, 0.72)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.74, 0.8, 0.64, 0.84, 0.71)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.77, 0.88, 0.62, 0.91, 0.73)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.76, 0.86, 0.62, 0.9, 0.72)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.77, 0.86, 0.64, 0.9, 0.73)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.76, 0.81, 0.67, 0.84, 0.74)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.61, 0.65, 0.48, 0.74, 0.55)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.6, 0.67, 0.41, 0.79, 0.51)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.6, 0.67, 0.41, 0.79, 0.51)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.63, 0.73, 0.41, 0.84, 0.53)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.65, 0.72, 0.48, 0.81, 0.58)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.6, 0.68, 0.4, 0.81, 0.5)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.6, 0.7, 0.36, 0.84, 0.48)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.61, 0.69, 0.41, 0.81, 0.52)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.64, 0.71, 0.47, 0.81, 0.56)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.71, 0.74, 0.64, 0.78, 0.69)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.75, 0.85, 0.6, 0.9, 0.71)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.71, 0.9, 0.47, 0.95, 0.61)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.74, 0.8, 0.64, 0.84, 0.71)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.67, 0.72, 0.57, 0.78, 0.63)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.66, 0.81, 0.43, 0.9, 0.56)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.65, 0.67, 0.59, 0.71, 0.62)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.76, 0.66, 0.79, 0.7)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.9, 0.48, 0.95, 0.63)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.74, 0.85, 0.59, 0.9, 0.69)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.67, 0.88, 0.57, 0.76)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.71, 0.66, 0.84, 0.57, 0.74)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.68, 0.68, 0.69, 0.67, 0.68)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.67, 0.73, 0.55, 0.79, 0.63)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.65, 0.76, 0.43, 0.86, 0.55)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.66, 0.8, 0.41, 0.9, 0.55)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.66, 0.79, 0.45, 0.88, 0.57)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.67, 0.81, 0.45, 0.9, 0.58)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.69, 0.75, 0.57, 0.81, 0.65)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.68, 0.71, 0.62, 0.74, 0.66)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.67, 0.69, 0.64, 0.71, 0.66)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.64, 0.69, 0.5, 0.78, 0.58)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.67, 0.69, 0.62, 0.72, 0.65)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.69, 0.69, 0.69, 0.69, 0.69)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.75, 0.82, 0.64, 0.86, 0.72)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.78, 0.85, 0.69, 0.88, 0.76)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.78, 0.78, 0.78, 0.78, 0.78)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.75, 0.75, 0.76, 0.74, 0.75)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.75, 0.82, 0.64, 0.86, 0.72)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.65, 0.64, 0.66, 0.64, 0.65)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.65, 0.63, 0.71, 0.59, 0.67)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.65, 0.63, 0.71, 0.59, 0.67)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.71, 0.74, 0.64, 0.78, 0.69)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.8, 0.6, 0.84, 0.69)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.79, 0.59, 0.84, 0.67)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.71, 0.77, 0.59, 0.83, 0.67)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.79, 0.59, 0.84, 0.67)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.7, 0.73, 0.64, 0.76, 0.68)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.74, 0.8, 0.64, 0.84, 0.71)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.76, 0.66, 0.79, 0.7)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.67, 0.64, 0.78, 0.57, 0.7)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.64, 0.6, 0.84, 0.43, 0.7)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.73, 0.75, 0.71, 0.76, 0.73)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.82, 0.57, 0.88, 0.67)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.77, 0.62, 0.81, 0.69)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.71, 0.74, 0.64, 0.78, 0.69)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.74, 0.87, 0.57, 0.91, 0.69)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.66, 0.69, 0.57, 0.74, 0.62)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.62, 0.62, 0.6, 0.64, 0.61)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.64, 0.63, 0.66, 0.62, 0.64)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.63, 0.65, 0.57, 0.69, 0.61)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.67, 0.72, 0.57, 0.78, 0.63)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.7, 0.85, 0.48, 0.91, 0.62)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.82, 0.57, 0.88, 0.67)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.75, 0.67, 0.78, 0.71)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.73, 0.69, 0.74, 0.71)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.71, 0.88, 0.48, 0.93, 0.62)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.71, 1.0, 0.41, 1.0, 0.59)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.77, 0.92, 0.59, 0.95, 0.72)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.73, 0.72, 0.76, 0.71, 0.74)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.71, 0.76, 0.69, 0.73)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.73, 0.72, 0.76, 0.71, 0.74)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.74, 0.73, 0.76, 0.72, 0.75)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.78, 0.8, 0.74, 0.81, 0.77)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.78, 0.87, 0.67, 0.9, 0.76)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.75, 0.8, 0.67, 0.83, 0.73)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.75, 0.76, 0.72, 0.78, 0.74)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.76, 0.8, 0.69, 0.83, 0.74)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.77, 0.84, 0.66, 0.88, 0.74)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.77, 0.84, 0.66, 0.88, 0.74)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.76, 0.84, 0.64, 0.88, 0.73)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.77, 0.86, 0.64, 0.9, 0.73)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.73, 0.83, 0.59, 0.88, 0.69)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.73, 0.81, 0.6, 0.86, 0.69)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.75, 0.84, 0.62, 0.88, 0.71)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.75, 0.87, 0.59, 0.91, 0.7)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.77, 0.97, 0.55, 0.98, 0.7)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.82, 0.57, 0.88, 0.67)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.68, 0.67, 0.72, 0.64, 0.69)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.72, 0.72, 0.72, 0.72)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.76, 0.89, 0.59, 0.93, 0.71)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.75, 0.82, 0.64, 0.86, 0.72)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.75, 0.78, 0.69, 0.81, 0.73)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.74, 0.77, 0.69, 0.79, 0.73)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.73, 0.75, 0.69, 0.78, 0.72)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.76, 0.66, 0.79, 0.7)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.72, 0.8, 0.6, 0.84, 0.69)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.74, 0.82, 0.62, 0.86, 0.71)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.75, 0.82, 0.64, 0.86, 0.72)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.77, 0.82, 0.69, 0.84, 0.75)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.78, 0.81, 0.74, 0.83, 0.77)\n",
            "max_accuracy: 0.7931034482758621\n",
            "-----\n",
            "(0.8, 0.81, 0.79, 0.81, 0.8)\n",
            "max_accuracy: 0.8017241379310345\n",
            "-----\n",
            "(0.8, 0.81, 0.79, 0.81, 0.8)\n",
            "max_accuracy: 0.8017241379310345\n",
            "-----\n",
            "(0.79, 0.8, 0.78, 0.81, 0.79)\n",
            "max_accuracy: 0.8017241379310345\n",
            "-----\n",
            "(0.78, 0.79, 0.78, 0.79, 0.78)\n",
            "max_accuracy: 0.8017241379310345\n",
            "-----\n",
            "(0.78, 0.82, 0.72, 0.84, 0.77)\n",
            "max_accuracy: 0.8017241379310345\n",
            "-----\n",
            "(0.76, 0.75, 0.78, 0.74, 0.76)\n",
            "max_accuracy: 0.8017241379310345\n",
            "-----\n",
            "(0.72, 0.73, 0.71, 0.74, 0.72)\n",
            "max_accuracy: 0.8017241379310345\n",
            "-----\n",
            "(0.66, 0.78, 0.43, 0.88, 0.56)\n",
            "max_accuracy: 0.8017241379310345\n",
            "-----\n",
            "(0.66, 0.81, 0.43, 0.9, 0.56)\n",
            "max_accuracy: 0.8017241379310345\n",
            "-----\n",
            "(0.68, 0.8, 0.48, 0.88, 0.6)\n",
            "max_accuracy: 0.8017241379310345\n",
            "-----\n",
            "(0.72, 0.75, 0.67, 0.78, 0.71)\n",
            "max_accuracy: 0.8017241379310345\n",
            "-----\n",
            "(0.66, 0.64, 0.74, 0.59, 0.69)\n",
            "max_accuracy: 0.8017241379310345\n",
            "-----\n",
            "(0.71, 0.72, 0.67, 0.74, 0.7)\n",
            "max_accuracy: 0.8017241379310345\n",
            "-----\n",
            "(0.73, 0.75, 0.71, 0.76, 0.73)\n",
            "max_accuracy: 0.8017241379310345\n",
            "-----\n",
            "(0.78, 0.82, 0.72, 0.84, 0.77)\n",
            "max_accuracy: 0.8017241379310345\n",
            "-----\n",
            "(0.82, 0.82, 0.81, 0.83, 0.82)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.78, 0.77, 0.81, 0.76, 0.79)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.79, 0.78, 0.81, 0.78, 0.8)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.73, 0.73, 0.74, 0.72, 0.74)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.7, 0.69, 0.72, 0.67, 0.71)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.7, 0.69, 0.72, 0.67, 0.71)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.69, 0.78, 0.66, 0.73)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.7, 0.68, 0.76, 0.64, 0.72)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.7, 0.69, 0.72, 0.67, 0.71)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.71, 0.71, 0.69, 0.72, 0.7)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.73, 0.69, 0.74, 0.71)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.73, 0.72, 0.76, 0.71, 0.74)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.71, 0.76, 0.69, 0.73)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.71, 0.76, 0.69, 0.73)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.75, 0.74, 0.78, 0.72, 0.76)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.74, 0.73, 0.78, 0.71, 0.75)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.74, 0.71, 0.81, 0.67, 0.76)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.74, 0.73, 0.76, 0.72, 0.75)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.73, 0.75, 0.71, 0.76, 0.73)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.76, 0.66, 0.79, 0.7)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.76, 0.64, 0.79, 0.69)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.76, 0.64, 0.79, 0.69)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.76, 0.64, 0.79, 0.69)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.77, 0.64, 0.81, 0.7)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.73, 0.79, 0.64, 0.83, 0.7)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.73, 0.79, 0.64, 0.83, 0.7)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.75, 0.8, 0.67, 0.83, 0.73)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.75, 0.8, 0.67, 0.83, 0.73)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.73, 0.81, 0.6, 0.86, 0.69)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.78, 0.6, 0.83, 0.68)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.7, 0.79, 0.53, 0.86, 0.64)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.66, 0.88, 0.38, 0.95, 0.53)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.74, 0.94, 0.52, 0.97, 0.67)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.74, 0.85, 0.59, 0.9, 0.69)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.76, 0.72, 0.84, 0.67, 0.78)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.75, 0.77, 0.71, 0.79, 0.74)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.67, 0.74, 0.53, 0.81, 0.62)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.77, 0.62, 0.81, 0.69)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.71, 0.76, 0.69, 0.73)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.78, 0.88, 0.64, 0.91, 0.74)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.73, 0.91, 0.52, 0.95, 0.66)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.74, 0.89, 0.55, 0.93, 0.68)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.75, 0.82, 0.64, 0.86, 0.72)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.68, 0.76, 0.53, 0.83, 0.63)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.64, 0.72, 0.45, 0.83, 0.55)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.64, 0.72, 0.45, 0.83, 0.55)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.64, 0.7, 0.48, 0.79, 0.57)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.64, 0.7, 0.48, 0.79, 0.57)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.68, 0.71, 0.6, 0.76, 0.65)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.65, 0.72, 0.48, 0.81, 0.58)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.66, 0.78, 0.43, 0.88, 0.56)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.63, 0.76, 0.38, 0.88, 0.51)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.64, 0.75, 0.41, 0.86, 0.53)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.66, 0.83, 0.41, 0.91, 0.55)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.68, 0.86, 0.43, 0.93, 0.57)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.68, 0.86, 0.43, 0.93, 0.57)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.68, 0.86, 0.43, 0.93, 0.57)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.67, 0.76, 0.5, 0.84, 0.6)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.66, 0.71, 0.55, 0.78, 0.62)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.67, 0.73, 0.55, 0.79, 0.63)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.69, 0.76, 0.55, 0.83, 0.64)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.7, 0.79, 0.53, 0.86, 0.64)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.82, 0.55, 0.88, 0.66)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.71, 0.82, 0.53, 0.88, 0.65)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.82, 0.55, 0.88, 0.66)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.74, 0.67, 0.76, 0.7)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.69, 0.71, 0.64, 0.74, 0.67)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.69, 0.76, 0.55, 0.83, 0.64)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.68, 0.77, 0.52, 0.84, 0.62)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.71, 0.79, 0.57, 0.84, 0.66)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.71, 0.79, 0.57, 0.84, 0.66)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.67, 0.69, 0.62, 0.72, 0.65)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.7, 0.74, 0.69, 0.72)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.7, 0.74, 0.69, 0.72)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.68, 0.7, 0.64, 0.72, 0.67)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.75, 0.67, 0.78, 0.71)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.72, 0.71, 0.72, 0.71)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.73, 0.69, 0.74, 0.71)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.74, 0.77, 0.69, 0.79, 0.73)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.73, 0.76, 0.67, 0.79, 0.72)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.76, 0.66, 0.79, 0.7)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.76, 0.64, 0.79, 0.69)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.7, 0.74, 0.6, 0.79, 0.67)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.71, 0.76, 0.6, 0.81, 0.67)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.69, 0.73, 0.6, 0.78, 0.66)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.68, 0.71, 0.6, 0.76, 0.65)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.69, 0.73, 0.6, 0.78, 0.66)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.7, 0.73, 0.64, 0.76, 0.68)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.68, 0.72, 0.59, 0.78, 0.65)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.68, 0.73, 0.57, 0.79, 0.64)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.69, 0.75, 0.57, 0.81, 0.65)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.69, 0.75, 0.57, 0.81, 0.65)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.67, 0.72, 0.57, 0.78, 0.63)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.69, 0.74, 0.59, 0.79, 0.65)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.7, 0.78, 0.55, 0.84, 0.65)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.71, 0.75, 0.62, 0.79, 0.68)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.76, 0.66, 0.79, 0.7)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.73, 0.75, 0.69, 0.78, 0.72)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.73, 0.76, 0.67, 0.79, 0.72)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.74, 0.78, 0.67, 0.81, 0.72)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.74, 0.76, 0.71, 0.78, 0.73)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.76, 0.81, 0.67, 0.84, 0.74)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.76, 0.83, 0.66, 0.86, 0.73)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.78, 0.8, 0.74, 0.81, 0.77)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.75, 0.73, 0.79, 0.71, 0.76)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.74, 0.74, 0.74, 0.74, 0.74)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.76, 0.79, 0.71, 0.81, 0.75)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.76, 0.83, 0.66, 0.86, 0.73)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.66, 0.77, 0.47, 0.86, 0.58)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.67, 0.78, 0.48, 0.86, 0.6)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.73, 0.85, 0.57, 0.9, 0.68)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.76, 0.79, 0.71, 0.81, 0.75)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.75, 0.75, 0.74, 0.76, 0.75)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.74, 0.73, 0.76, 0.72, 0.75)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.73, 0.72, 0.76, 0.71, 0.74)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.73, 0.75, 0.69, 0.78, 0.72)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.75, 0.67, 0.78, 0.71)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.72, 0.74, 0.69, 0.76, 0.71)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.75, 0.77, 0.71, 0.79, 0.74)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.77, 0.8, 0.71, 0.83, 0.75)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.78, 0.84, 0.71, 0.86, 0.77)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.74, 0.75, 0.72, 0.76, 0.74)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.69, 0.71, 0.64, 0.74, 0.67)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.71, 0.75, 0.62, 0.79, 0.68)\n",
            "max_accuracy: 0.8189655172413793\n",
            "-----\n",
            "(0.74, 0.91, 0.53, 0.95, 0.67)\n",
            "max_accuracy: 0.8189655172413793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUMMe6H86fM7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "9d638afc-49df-4677-e05a-41d2812b96ee"
      },
      "source": [
        "        #ここからevaluation (accuracy, precision, recall, specificity, f_value)                        \r\n",
        "        model.eval()\r\n",
        "\r\n",
        "        test_dataset = SimpleImageDataset(TEST_PATH, age_dict, sex_dict, train_data_transforms)\r\n",
        "        test_dataloader = DataLoader(test_dataset, batch_size = 1, shuffle = False)\r\n",
        "\r\n",
        "        test_folder_path = TEST_PATH\r\n",
        "        evaluator = Evaluator(model, test_dataset.class_names, age_dict, sex_dict, test_folder_path, val_data_transforms, device)\r\n",
        "        \r\n",
        "        _ ,score =evaluator.evaluate()\r\n",
        "        print(score)\r\n",
        "\r\n",
        "        evaluator.draw_roc(ROC_PATH)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eval number of classes: 2\n",
            "eval number of images: 86\n",
            "initial accuracy: 0.8235294117647058\n",
            "(0.82, 0.89, 0.74, 0.91, 0.81)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}