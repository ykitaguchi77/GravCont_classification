{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled31.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_colab/blob/master/EfficientNet_b4_ImageNet_adabound_crossvalidation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-a4ZBlqPNdU",
        "colab_type": "text"
      },
      "source": [
        "#**GravCont: EfficientNet_b4_ImageNet**\n",
        "ValidationとTestに分けて解析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgM-Y7SVPNkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "8d8c16a9-220f-43fe-8f2a-317d7561d7a6"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "#Advanced Pytorchから\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set random seem for reproducibility\n",
        "manualSeed = 1234\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.cuda.manual_seed(manualSeed)\n",
        "\n",
        "torch.torch.backends.cudnn.benchmark = True\n",
        "torch.torch.backends.cudnn.enabled = True\n",
        "\n",
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet \n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "'''\n",
        "grav: 甲状腺眼症\n",
        "cont: コントロール\n",
        "黒の空白を挿入することにより225px*225pxの画像を生成、EfficientNetを用いて転移学習\n",
        "－－－－－－－－－－－－－－\n",
        "データの構造\n",
        "gravcont.zip ------grav\n",
        "               |---cont\n",
        "'''                                     \n",
        "\n",
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_optimizer in /usr/local/lib/python3.6/dist-packages (0.0.1a15)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torch_optimizer) (1.6.0+cu101)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from torch_optimizer) (0.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (0.16.0)\n",
            "Random Seed:  1234\n",
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzp_09fWPNoU",
        "colab_type": "text"
      },
      "source": [
        "#**モジュール群**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7sJV06qPNsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_process(data_dir):\n",
        "    # 入力画像の前処理をするクラス\n",
        "    # 訓練時と推論時で処理が異なる\n",
        "\n",
        "    \"\"\"\n",
        "        画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "        画像のサイズをリサイズし、色を標準化する。\n",
        "        訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n",
        "\n",
        "\n",
        "        Attributes\n",
        "        ----------\n",
        "        resize : int\n",
        "            リサイズ先の画像の大きさ。\n",
        "        mean : (R, G, B)\n",
        "            各色チャネルの平均値。\n",
        "        std : (R, G, B)\n",
        "            各色チャネルの標準偏差。\n",
        "    \"\"\"\n",
        "\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224, scale=(0.75,1.0)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    data_dir = data_dir\n",
        "    n_samples = len(data_dir)\n",
        "\n",
        "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                              data_transforms[x])\n",
        "                      for x in ['train', 'val']}\n",
        "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=20,\n",
        "                                                shuffle=True, num_workers=4)\n",
        "                  for x in ['train', 'val']}\n",
        "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "    class_names = image_datasets['train'].classes\n",
        "\n",
        "\n",
        "    print(class_names)\n",
        "    k=0\n",
        "    for i in class_names:\n",
        "        print(class_names[k]+\"_train:\"+str(len(os.listdir(path=data_dir + '/train/'+class_names[k]))))\n",
        "        k+=1\n",
        "    k=0\n",
        "    for i in class_names:\n",
        "        print(class_names[k]+\"_val:\"+str(len(os.listdir(path=data_dir + '/val/'+class_names[k]))))\n",
        "        k+=1\n",
        "\n",
        "    print(\"training data set_total：\"+ str(len(image_datasets['train'])))\n",
        "    print(\"validating data set_total：\"+str(len(image_datasets['val'])))\n",
        "    \n",
        "    return image_datasets, dataloaders, dataset_sizes, class_names, device\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "def getBatch(dataloaders):    \n",
        "    # Get a batch of training data\n",
        "    inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "    # Make a grid from batch\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "    #imshow(out, title=[class_names[x] for x in classes])\n",
        "    return(inputs, classes)\n",
        "\n",
        "#Defining early stopping class\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_loss = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_loss = []\n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase] \n",
        "            \n",
        "            # record train_loss and valid_loss\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "            if phase == 'val':\n",
        "                valid_loss.append(epoch_loss)\n",
        "            #print(train_loss)\n",
        "            #print(valid_loss)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "      \n",
        "      # early_stopping needs the validation loss to check if it has decresed, \n",
        "      # and if it has, it will make a checkpoint of the current model\n",
        "        if phase == 'val':    \n",
        "            early_stopping(epoch_loss, model)\n",
        "                \n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "        print()\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_loss, valid_loss\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "def convnet():\n",
        "    model_ft = EfficientNet.from_pretrained('efficientnet-b4')\n",
        "    num_ftrs = model_ft._fc.in_features\n",
        "    model_ft._fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    #https://blog.knjcode.com/adabound-memo/\n",
        "    #https://pypi.org/project/torch-optimizer/\n",
        "    optimizer_ft = optim.AdaBound(\n",
        "        model_ft.parameters(),\n",
        "        lr= 1e-3,\n",
        "        betas= (0.9, 0.999),\n",
        "        final_lr = 0.1,\n",
        "        gamma=1e-3,\n",
        "        eps= 1e-8,\n",
        "        weight_decay=0,\n",
        "        amsbound=False,\n",
        "    )\n",
        "    return (model_ft, criterion, optimizer_ft)\n",
        "\n",
        "\n",
        "def training(model_ft, criterion, optimizer_ft,  patience=15, num_epochs=50):\n",
        "    model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=patience, num_epochs=num_epochs)\n",
        "\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      return(image_name, label)\n",
        "\n",
        "'''\n",
        "#変形後の画像を表示\n",
        "def image_transform(image_path):\n",
        "\n",
        "    image=Image.open(image_path)\n",
        "\n",
        "    \n",
        "    #変形した画像を表示する\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224)])\n",
        "    image_transformed = transform(image)\n",
        "    plt.imshow(np.array(image_transformed))\n",
        "'''\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を表示\n",
        "def image_eval(image_tensor, label):\n",
        "    output = model_ft(image_tensor)\n",
        "    #print(output.size())  # torch.Size([1, 1000])\n",
        "    #print(output)\n",
        "\n",
        "    #model_pred:クラス名前、prob:確率、pred:クラス番号\n",
        "    prob, pred = torch.topk(nn.Softmax(dim=1)(output), 1)\n",
        "    model_pred = class_names[pred]\n",
        "    \n",
        "    #甲状腺眼症のprobabilityを計算（classが0なら1から減算、classが1ならそのまま）\n",
        "    prob = abs(1-float(prob)-float(pred))\n",
        " \n",
        "    return model_pred, prob, pred\n",
        "\n",
        "    \"\"\"\n",
        "    #probalilityを計算する\n",
        "    pred_prob = torch.topk(nn.Softmax(dim=1)(output), 1)[0]\n",
        "    pred_class = torch.topk(nn.Softmax(dim=1)(output), 1)[1]\n",
        "    if pred_class == 1:\n",
        "        pred_prob = pred_prob\n",
        "    elif pred_class == 0:\n",
        "        pred_prob = 1- pred_prob\n",
        "    return(model_pred, pred_prob)  #class_nameの番号で出力される\n",
        "    \"\"\"\n",
        "\n",
        "def showImage(image_path):\n",
        "    #画像のインポート\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    #画像のリサイズ\n",
        "    height = img.shape[0]\n",
        "    width = img.shape[1]\n",
        "    resized_img = cv2.resize(img, (int(width*300/height), 300))\n",
        "    cv2_imshow(resized_img)\n",
        "\n",
        "def calculateAccuracy (TP, TN, FP, FN):\n",
        "    accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "    precision  = TP/(FP + TP)\n",
        "    recall = TP/(TP + FN)\n",
        "    specificity = TN/(FP + TN)\n",
        "    f_value = (2*recall*precision)/(recall+precision)\n",
        "    return(accuracy, precision, recall, specificity, f_value)\n",
        "\n",
        "\"\"\"\n",
        "・True positive (TN)\n",
        "・False positive (FP)\n",
        "・True negative (TN)\n",
        "・False negative (FN)\n",
        "Accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "Precision = TP/(FP + TP) ※positive predictive value\n",
        "Recall = TP/(TP + FN)　※sensitivity\n",
        "Specificity = TN/(FP + TN)\n",
        "F_value = (2RecallPrecision)/(Recall+Precision)\n",
        "\"\"\"\n",
        "\n",
        "def evaluation(model_ft, testset_dir):\n",
        "    #評価モードにする\n",
        "    model_ft.eval()\n",
        "\n",
        "    #testデータセット内のファイル名を取得\n",
        "    image_path = glob.glob(testset_dir + \"/*/*\")\n",
        "    #random.shuffle(image_path)  #表示順をランダムにする\n",
        "    print('number of images: ' +str(len(image_path)))\n",
        "\n",
        "\n",
        "    TP, FP, TN, FN, TP, FP, TN, FN = [0,0,0,0,0,0,0,0]\n",
        "    image_name_list = []\n",
        "    label_list = []\n",
        "    model_pred_list = []\n",
        "    hum_pred_list = []\n",
        "\n",
        "    model_pred_class = []\n",
        "    model_pred_prob = []\n",
        "\n",
        "    for i in image_path:\n",
        "          image_name, label = getlabel(i)  #画像の名前とラベルを取得\n",
        "          image_tensor = image_transform(i)  #予測のための画像下処理\n",
        "          model_pred, prob, pred = image_eval(image_tensor, label)  #予測結果を出力   \n",
        "          #print('Image: '+ image_name)\n",
        "          #print('Label: '+ label)\n",
        "          #print('Pred: '+ model_pred)\n",
        "          #showImage(i)  #画像を表示\n",
        "          #print() #空白行を入れる\n",
        "          time.sleep(0.1)\n",
        "\n",
        "          image_name_list.append(image_name)\n",
        "          label_list.append(label)\n",
        "          model_pred_list.append(model_pred)\n",
        "\n",
        "          model_pred_class.append(int(pred))\n",
        "          model_pred_prob.append(float(prob))\n",
        "\n",
        "          if label == class_names[0]:\n",
        "              if model_pred == class_names[0]:\n",
        "                  TN += 1\n",
        "              else:\n",
        "                  FP += 1\n",
        "          elif label == class_names[1]:\n",
        "              if model_pred == class_names[1]:\n",
        "                  TP += 1\n",
        "              else:\n",
        "                  FN += 1     \n",
        "\n",
        "    print(TP, FN, TN, FP)\n",
        "\n",
        "    #Accuracyを計算\n",
        "    accuracy, precision, recall, specificity, f_value = calculateAccuracy (TP, TN, FP, FN)\n",
        "    print('Accuracy: ' + str(accuracy))\n",
        "    print('Precision (positive predictive value): ' + str(precision))\n",
        "    print('Recall (sensitivity): ' + str(recall))\n",
        "    print('Specificity: ' + str(specificity))\n",
        "    print('F_value: ' + str(f_value))\n",
        "\n",
        "    #print(model_pred_class)\n",
        "    #print(model_pred_prob)\n",
        "\n",
        "    return TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, label_list, model_pred_prob\n",
        "\n",
        "\n",
        "def make_csv(roc_label_list):\n",
        "    #csvのdata tableを作成\n",
        "    pd.set_option('display.max_rows', 800)  # 省略なしで表示\n",
        "    #columns1 = [\"EfficientNet_32\", \"EfficientNet_64\", \"EfficientNet_128\", \"EfficientNet_256\", \"EfficientNet_512\", \"EfficientNet_558\"]\n",
        "    columns1 = roc_label_list\n",
        "    index1 = [\"TP\",\"TN\",\"FP\",\"FN\",\"Accuracy\",\"Positive predictive value\",\"sensitity\",\"specificity\",\"F-value\",\"roc_auc\"]\n",
        "    df = pd.DataFrame(index=index1, columns=columns1)\n",
        "    return df\n",
        "\n",
        "def write_csv(df, col, TP, TN, FP, FN, accuracy, precision, recall, specificity, f_value,roc_auc):\n",
        "    df.iloc[0:10, col] = TP, TN, FP, FN, accuracy, precision, recall, specificity, f_value,roc_auc \n",
        "    #print(df)\n",
        "\n",
        "    # CSVとして出力\n",
        "    #df2.to_csv(\"/content/drive/My Drive/Grav_bootcamp/Posttrain_model_eval_result.csv\",encoding=\"shift_jis\")\n",
        "    return df\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == 'cont':\n",
        "                  y_true.append(0)\n",
        "            elif i == 'grav':\n",
        "                  y_true.append(1)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_auc(label_list, model_pred_prob):\n",
        "    y_true, y_score = [], []\n",
        "    for i in label_list:\n",
        "        if i == 'cont':\n",
        "              y_true.append(0)\n",
        "        elif i == 'grav':\n",
        "              y_true.append(1)\n",
        "            \n",
        "    #それぞれの画像における陽性の確率についてリストを作成\n",
        "    y_score = model_pred_prob\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc: \" +str(roc_auc))\n",
        "    return(roc_auc)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USGfUwQXv6Jc",
        "colab_type": "text"
      },
      "source": [
        "#**まとめて解析**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObCZwRvYCPTI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "ac6e594e-6886-4279-a8ed-610d45e659a5"
      },
      "source": [
        "fold = 10 #データフォルダの個数\n",
        "\n",
        "#create data_dir_list\n",
        "data_dir = '/content/drive/My Drive/gravcont_crossvalidation'\n",
        "data_dir_list = [0]*fold\n",
        "\n",
        "for i in range(fold):\n",
        "    data_dir_list[i] = data_dir + '/' + str(i)\n",
        "    print(data_dir_list[i])\n",
        "\n",
        "#create roc_label_list\n",
        "roc_label_list = [0]*fold\n",
        "roc_label_list = list(range(fold))\n",
        "print(roc_label_list)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/gravcont_crossvalidation/0\n",
            "/content/drive/My Drive/gravcont_crossvalidation/1\n",
            "/content/drive/My Drive/gravcont_crossvalidation/2\n",
            "/content/drive/My Drive/gravcont_crossvalidation/3\n",
            "/content/drive/My Drive/gravcont_crossvalidation/4\n",
            "/content/drive/My Drive/gravcont_crossvalidation/5\n",
            "/content/drive/My Drive/gravcont_crossvalidation/6\n",
            "/content/drive/My Drive/gravcont_crossvalidation/7\n",
            "/content/drive/My Drive/gravcont_crossvalidation/8\n",
            "/content/drive/My Drive/gravcont_crossvalidation/9\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM2VMXltwBs5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aaea68d5-04da-4b56-9fa5-7c824baa13a3"
      },
      "source": [
        "df = make_csv(roc_label_list)\n",
        "\n",
        "label_list_list, model_pred_prob_list = [],[]\n",
        "\n",
        "print(data_dir_list)\n",
        "print(roc_label_list)\n",
        "\n",
        "for i, t in enumerate(zip(data_dir_list, roc_label_list)):\n",
        "\n",
        "    image_datasets, dataloaders, dataset_sizes, class_names, device = pre_process(t[0]) #path\n",
        "    inputs, classes = getBatch(dataloaders)\n",
        "    model_ft, criterion, optimizer_ft = convnet()\n",
        "    training(model_ft, criterion, optimizer_ft,  patience=15, num_epochs=50)  \n",
        "    TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, label_list, model_pred_prob = evaluation(model_ft, t[0]+'/test')\n",
        "    roc_auc = calculate_auc(label_list, model_pred_prob)\n",
        "    df = write_csv(df, i,TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, roc_auc) #numberをcsvの行として指定\n",
        "\n",
        "\n",
        "    label_list_list.append(label_list)\n",
        "    model_pred_prob_list.append(model_pred_prob)\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "\n",
        "#Draw ROC curve\n",
        "fig = Draw_roc_curve(label_list_list, model_pred_prob_list, roc_label_list, len(label_list_list))\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns', 100)\n",
        "print(df)\n",
        "\n",
        "\n",
        "# CSVとして出力\n",
        "df.to_csv(\"/content/drive/My Drive/Grav_bootcamp/crossvaridation_efficientNet_ImageNet.csv\",encoding=\"shift_jis\")\n",
        "\n",
        "#ROC_curveを保存\n",
        "fig.savefig(\"/content/drive/My Drive/Grav_bootcamp/img.png\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/gravcont_crossvalidation/0', '/content/drive/My Drive/gravcont_crossvalidation/1', '/content/drive/My Drive/gravcont_crossvalidation/2', '/content/drive/My Drive/gravcont_crossvalidation/3', '/content/drive/My Drive/gravcont_crossvalidation/4', '/content/drive/My Drive/gravcont_crossvalidation/5', '/content/drive/My Drive/gravcont_crossvalidation/6', '/content/drive/My Drive/gravcont_crossvalidation/7', '/content/drive/My Drive/gravcont_crossvalidation/8', '/content/drive/My Drive/gravcont_crossvalidation/9']\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "['cont', 'grav']\n",
            "cont_train:239\n",
            "grav_train:239\n",
            "cont_val:60\n",
            "grav_val:60\n",
            "training data set_total：478\n",
            "validating data set_total：120\n",
            "Loaded pretrained weights for efficientnet-b4\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.5658 Acc: 0.6925\n",
            "val Loss: 1.8729 Acc: 0.5000\n",
            "Validation loss decreased (inf --> 1.872924).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.4266 Acc: 0.8096\n",
            "val Loss: 1.1269 Acc: 0.8167\n",
            "Validation loss decreased (1.872924 --> 1.126868).  Saving model ...\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.3377 Acc: 0.8724\n",
            "val Loss: 0.6016 Acc: 0.7750\n",
            "Validation loss decreased (1.126868 --> 0.601579).  Saving model ...\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.2267 Acc: 0.9038\n",
            "val Loss: 1.2771 Acc: 0.7250\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.2778 Acc: 0.8828\n",
            "val Loss: 0.5695 Acc: 0.8917\n",
            "Validation loss decreased (0.601579 --> 0.569549).  Saving model ...\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.1900 Acc: 0.9121\n",
            "val Loss: 0.9333 Acc: 0.7833\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.0838 Acc: 0.9770\n",
            "val Loss: 1.3639 Acc: 0.7917\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.1526 Acc: 0.9477\n",
            "val Loss: 0.7082 Acc: 0.8500\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.1010 Acc: 0.9603\n",
            "val Loss: 0.7263 Acc: 0.8167\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.0510 Acc: 0.9812\n",
            "val Loss: 0.8562 Acc: 0.8333\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0684 Acc: 0.9707\n",
            "val Loss: 0.7542 Acc: 0.8500\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0356 Acc: 0.9874\n",
            "val Loss: 0.5937 Acc: 0.8250\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.0846 Acc: 0.9686\n",
            "val Loss: 0.4173 Acc: 0.8500\n",
            "Validation loss decreased (0.569549 --> 0.417251).  Saving model ...\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0508 Acc: 0.9833\n",
            "val Loss: 0.4233 Acc: 0.8417\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0711 Acc: 0.9833\n",
            "val Loss: 0.4662 Acc: 0.8583\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0476 Acc: 0.9812\n",
            "val Loss: 0.6055 Acc: 0.8667\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0755 Acc: 0.9728\n",
            "val Loss: 0.5387 Acc: 0.8500\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0222 Acc: 0.9937\n",
            "val Loss: 0.4975 Acc: 0.8333\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.0320 Acc: 0.9854\n",
            "val Loss: 0.5148 Acc: 0.8750\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0357 Acc: 0.9916\n",
            "val Loss: 0.4321 Acc: 0.8500\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.0196 Acc: 0.9916\n",
            "val Loss: 0.5487 Acc: 0.8417\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.0134 Acc: 0.9979\n",
            "val Loss: 0.5135 Acc: 0.8417\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.0115 Acc: 0.9958\n",
            "val Loss: 0.5844 Acc: 0.8333\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.0094 Acc: 0.9958\n",
            "val Loss: 0.5641 Acc: 0.8500\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.0070 Acc: 0.9979\n",
            "val Loss: 0.5594 Acc: 0.8500\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.0092 Acc: 0.9958\n",
            "val Loss: 0.5974 Acc: 0.8583\n",
            "EarlyStopping counter: 13 out of 15\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.0081 Acc: 0.9958\n",
            "val Loss: 0.5739 Acc: 0.8583\n",
            "EarlyStopping counter: 14 out of 15\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.0065 Acc: 0.9958\n",
            "val Loss: 0.5223 Acc: 0.8667\n",
            "EarlyStopping counter: 15 out of 15\n",
            "Early stopping\n",
            "Training complete in 6m 6s\n",
            "Best val Acc: 0.891667\n",
            "number of images: 68\n",
            "26 8 25 9\n",
            "Accuracy: 0.75\n",
            "Precision (positive predictive value): 0.7428571428571429\n",
            "Recall (sensitivity): 0.7647058823529411\n",
            "Specificity: 0.7352941176470589\n",
            "F_value: 0.7536231884057971\n",
            "roc_auc: 0.8269896193771628\n",
            "\n",
            "\n",
            "['cont', 'grav']\n",
            "cont_train:239\n",
            "grav_train:239\n",
            "cont_val:60\n",
            "grav_val:60\n",
            "training data set_total：478\n",
            "validating data set_total：120\n",
            "Loaded pretrained weights for efficientnet-b4\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.5401 Acc: 0.7322\n",
            "val Loss: 0.3091 Acc: 0.8500\n",
            "Validation loss decreased (inf --> 0.309149).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.4401 Acc: 0.8180\n",
            "val Loss: 0.7647 Acc: 0.8417\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.2743 Acc: 0.8933\n",
            "val Loss: 0.4416 Acc: 0.8750\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.2777 Acc: 0.8808\n",
            "val Loss: 0.8590 Acc: 0.8250\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.2711 Acc: 0.8954\n",
            "val Loss: 0.5368 Acc: 0.8417\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.1770 Acc: 0.9205\n",
            "val Loss: 0.3116 Acc: 0.9250\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.1528 Acc: 0.9331\n",
            "val Loss: 0.5533 Acc: 0.8583\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.1142 Acc: 0.9582\n",
            "val Loss: 1.5356 Acc: 0.6917\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.0805 Acc: 0.9791\n",
            "val Loss: 0.8931 Acc: 0.8000\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.1233 Acc: 0.9519\n",
            "val Loss: 0.4114 Acc: 0.8833\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0863 Acc: 0.9749\n",
            "val Loss: 0.4755 Acc: 0.8750\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0537 Acc: 0.9833\n",
            "val Loss: 0.6553 Acc: 0.8167\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.0602 Acc: 0.9728\n",
            "val Loss: 0.5052 Acc: 0.8833\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0292 Acc: 0.9916\n",
            "val Loss: 0.4862 Acc: 0.8667\n",
            "EarlyStopping counter: 13 out of 15\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0220 Acc: 0.9937\n",
            "val Loss: 0.4738 Acc: 0.8833\n",
            "EarlyStopping counter: 14 out of 15\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0188 Acc: 0.9958\n",
            "val Loss: 0.4480 Acc: 0.8917\n",
            "EarlyStopping counter: 15 out of 15\n",
            "Early stopping\n",
            "Training complete in 3m 45s\n",
            "Best val Acc: 0.925000\n",
            "number of images: 68\n",
            "30 4 23 11\n",
            "Accuracy: 0.7794117647058824\n",
            "Precision (positive predictive value): 0.7317073170731707\n",
            "Recall (sensitivity): 0.8823529411764706\n",
            "Specificity: 0.6764705882352942\n",
            "F_value: 0.8\n",
            "roc_auc: 0.8633217993079585\n",
            "\n",
            "\n",
            "['cont', 'grav']\n",
            "cont_train:239\n",
            "grav_train:239\n",
            "cont_val:60\n",
            "grav_val:60\n",
            "training data set_total：478\n",
            "validating data set_total：120\n",
            "Loaded pretrained weights for efficientnet-b4\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.6411 Acc: 0.6360\n",
            "val Loss: 0.5037 Acc: 0.7250\n",
            "Validation loss decreased (inf --> 0.503747).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.4387 Acc: 0.7950\n",
            "val Loss: 0.6481 Acc: 0.7833\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.3113 Acc: 0.8787\n",
            "val Loss: 0.4875 Acc: 0.8500\n",
            "Validation loss decreased (0.503747 --> 0.487496).  Saving model ...\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.2468 Acc: 0.8933\n",
            "val Loss: 0.9634 Acc: 0.7750\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.2378 Acc: 0.9059\n",
            "val Loss: 0.3321 Acc: 0.8583\n",
            "Validation loss decreased (0.487496 --> 0.332120).  Saving model ...\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.1942 Acc: 0.9205\n",
            "val Loss: 0.3878 Acc: 0.8583\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.1517 Acc: 0.9435\n",
            "val Loss: 0.6135 Acc: 0.8250\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.1418 Acc: 0.9456\n",
            "val Loss: 0.5846 Acc: 0.8583\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.1059 Acc: 0.9707\n",
            "val Loss: 0.3692 Acc: 0.8667\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.0564 Acc: 0.9812\n",
            "val Loss: 0.3375 Acc: 0.9000\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0614 Acc: 0.9686\n",
            "val Loss: 0.6444 Acc: 0.8417\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.1033 Acc: 0.9728\n",
            "val Loss: 0.4356 Acc: 0.8750\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.0828 Acc: 0.9791\n",
            "val Loss: 0.5668 Acc: 0.8500\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0506 Acc: 0.9770\n",
            "val Loss: 0.4099 Acc: 0.8917\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0652 Acc: 0.9728\n",
            "val Loss: 0.6082 Acc: 0.8500\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0291 Acc: 0.9916\n",
            "val Loss: 0.4154 Acc: 0.9083\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0107 Acc: 1.0000\n",
            "val Loss: 0.3538 Acc: 0.8917\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0600 Acc: 0.9770\n",
            "val Loss: 0.4138 Acc: 0.9083\n",
            "EarlyStopping counter: 13 out of 15\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.0517 Acc: 0.9833\n",
            "val Loss: 0.5665 Acc: 0.8583\n",
            "EarlyStopping counter: 14 out of 15\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0238 Acc: 0.9937\n",
            "val Loss: 0.4989 Acc: 0.8667\n",
            "EarlyStopping counter: 15 out of 15\n",
            "Early stopping\n",
            "Training complete in 4m 45s\n",
            "Best val Acc: 0.908333\n",
            "number of images: 68\n",
            "26 8 30 4\n",
            "Accuracy: 0.8235294117647058\n",
            "Precision (positive predictive value): 0.8666666666666667\n",
            "Recall (sensitivity): 0.7647058823529411\n",
            "Specificity: 0.8823529411764706\n",
            "F_value: 0.8125\n",
            "roc_auc: 0.9342560553633219\n",
            "\n",
            "\n",
            "['cont', 'grav']\n",
            "cont_train:240\n",
            "grav_train:240\n",
            "cont_val:60\n",
            "grav_val:60\n",
            "training data set_total：480\n",
            "validating data set_total：120\n",
            "Loaded pretrained weights for efficientnet-b4\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.6287 Acc: 0.6771\n",
            "val Loss: 0.6147 Acc: 0.6167\n",
            "Validation loss decreased (inf --> 0.614661).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.4604 Acc: 0.8187\n",
            "val Loss: 0.5032 Acc: 0.8083\n",
            "Validation loss decreased (0.614661 --> 0.503180).  Saving model ...\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.3497 Acc: 0.8542\n",
            "val Loss: 1.4124 Acc: 0.7583\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.2471 Acc: 0.9083\n",
            "val Loss: 0.9071 Acc: 0.8583\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.1953 Acc: 0.9313\n",
            "val Loss: 0.7122 Acc: 0.8333\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.1639 Acc: 0.9354\n",
            "val Loss: 0.5777 Acc: 0.8333\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.1489 Acc: 0.9375\n",
            "val Loss: 0.3795 Acc: 0.9000\n",
            "Validation loss decreased (0.503180 --> 0.379526).  Saving model ...\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.0720 Acc: 0.9688\n",
            "val Loss: 0.5004 Acc: 0.8583\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.0545 Acc: 0.9854\n",
            "val Loss: 0.7458 Acc: 0.8083\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.0876 Acc: 0.9708\n",
            "val Loss: 0.4761 Acc: 0.8583\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0385 Acc: 0.9917\n",
            "val Loss: 0.3957 Acc: 0.9000\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0447 Acc: 0.9833\n",
            "val Loss: 0.7910 Acc: 0.8000\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.1000 Acc: 0.9646\n",
            "val Loss: 1.0959 Acc: 0.7667\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0826 Acc: 0.9646\n",
            "val Loss: 0.4218 Acc: 0.9167\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0268 Acc: 0.9958\n",
            "val Loss: 0.3867 Acc: 0.8833\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0235 Acc: 0.9938\n",
            "val Loss: 0.4220 Acc: 0.8583\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0125 Acc: 0.9979\n",
            "val Loss: 0.5733 Acc: 0.8750\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0201 Acc: 0.9958\n",
            "val Loss: 0.6531 Acc: 0.8250\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.0569 Acc: 0.9812\n",
            "val Loss: 0.5949 Acc: 0.8417\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0166 Acc: 0.9979\n",
            "val Loss: 0.6057 Acc: 0.8750\n",
            "EarlyStopping counter: 13 out of 15\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.0295 Acc: 0.9875\n",
            "val Loss: 0.8321 Acc: 0.8250\n",
            "EarlyStopping counter: 14 out of 15\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.0490 Acc: 0.9812\n",
            "val Loss: 0.7008 Acc: 0.8583\n",
            "EarlyStopping counter: 15 out of 15\n",
            "Early stopping\n",
            "Training complete in 5m 4s\n",
            "Best val Acc: 0.916667\n",
            "number of images: 66\n",
            "23 10 30 3\n",
            "Accuracy: 0.803030303030303\n",
            "Precision (positive predictive value): 0.8846153846153846\n",
            "Recall (sensitivity): 0.696969696969697\n",
            "Specificity: 0.9090909090909091\n",
            "F_value: 0.7796610169491526\n",
            "roc_auc: 0.8953168044077136\n",
            "\n",
            "\n",
            "['cont', 'grav']\n",
            "cont_train:240\n",
            "grav_train:240\n",
            "cont_val:60\n",
            "grav_val:60\n",
            "training data set_total：480\n",
            "validating data set_total：120\n",
            "Loaded pretrained weights for efficientnet-b4\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.6191 Acc: 0.6854\n",
            "val Loss: 0.5008 Acc: 0.7833\n",
            "Validation loss decreased (inf --> 0.500769).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.3605 Acc: 0.8479\n",
            "val Loss: 4.0465 Acc: 0.6750\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.3004 Acc: 0.8625\n",
            "val Loss: 0.3802 Acc: 0.8667\n",
            "Validation loss decreased (0.500769 --> 0.380179).  Saving model ...\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.2647 Acc: 0.8896\n",
            "val Loss: 0.8107 Acc: 0.7167\n",
            "EarlyStopping counter: 1 out of 15\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.2009 Acc: 0.9042\n",
            "val Loss: 0.4151 Acc: 0.8083\n",
            "EarlyStopping counter: 2 out of 15\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.1464 Acc: 0.9396\n",
            "val Loss: 0.5535 Acc: 0.8667\n",
            "EarlyStopping counter: 3 out of 15\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.1164 Acc: 0.9562\n",
            "val Loss: 0.4819 Acc: 0.8417\n",
            "EarlyStopping counter: 4 out of 15\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.1027 Acc: 0.9729\n",
            "val Loss: 0.4188 Acc: 0.8583\n",
            "EarlyStopping counter: 5 out of 15\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.0753 Acc: 0.9750\n",
            "val Loss: 0.5025 Acc: 0.8583\n",
            "EarlyStopping counter: 6 out of 15\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.0549 Acc: 0.9792\n",
            "val Loss: 0.6226 Acc: 0.8333\n",
            "EarlyStopping counter: 7 out of 15\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0559 Acc: 0.9750\n",
            "val Loss: 0.6381 Acc: 0.8333\n",
            "EarlyStopping counter: 8 out of 15\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0412 Acc: 0.9875\n",
            "val Loss: 0.6104 Acc: 0.8833\n",
            "EarlyStopping counter: 9 out of 15\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.0667 Acc: 0.9750\n",
            "val Loss: 0.6538 Acc: 0.7833\n",
            "EarlyStopping counter: 10 out of 15\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0386 Acc: 0.9833\n",
            "val Loss: 1.2500 Acc: 0.7250\n",
            "EarlyStopping counter: 11 out of 15\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0440 Acc: 0.9792\n",
            "val Loss: 0.5005 Acc: 0.8333\n",
            "EarlyStopping counter: 12 out of 15\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8a8q2pcQPWJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "3ff8e8ea-f889-4cfa-a1e6-c46fc066994f"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          EfficientNet_32  ... EfficientNet_558\n",
            "TP                                    NaN  ...              NaN\n",
            "TN                                    NaN  ...              NaN\n",
            "FP                                    NaN  ...              NaN\n",
            "FN                                    NaN  ...              NaN\n",
            "Accuracy                              NaN  ...              NaN\n",
            "Positive predictive value             NaN  ...              NaN\n",
            "sensitity                             NaN  ...              NaN\n",
            "specificity                           NaN  ...              NaN\n",
            "F-value                               NaN  ...              NaN\n",
            "roc_auc                               NaN  ...              NaN\n",
            "\n",
            "[10 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPO-b2cAT0yF",
        "colab_type": "text"
      },
      "source": [
        "#**ネットワークの保存と読み込み**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMYyFQ6ATzyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ネットワークの保存\n",
        "PATH = '/content/drive/My Drive/Grav_bootcamp/GravCont_EfficientNet-b4_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "torch.save(model_ft.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c744XUtfT6xW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73a923de-e875-4e71-b4b5-1ae266557981"
      },
      "source": [
        "#ネットワークの読み込み\n",
        "PATH = '/content/drive/My Drive/Grav_bootcamp/GravCont_EfficientNet-b4_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "torch.save(model_ft.state_dict(), PATH)\n",
        "model_ft.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}